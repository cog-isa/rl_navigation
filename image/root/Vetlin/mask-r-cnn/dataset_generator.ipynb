{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/green-tea/miniconda3/envs/habitat/lib/python3.6/site-packages/numba-0.46.0-py3.6-linux-x86_64.egg/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import uuid\n",
    "import os\n",
    "from typing import Any\n",
    "import quaternion\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentPosition:\n",
    "    angle_weight = 12\n",
    "    coordinate_weight = 4\n",
    "    min_diff = 2\n",
    "    \n",
    "    def __init__(self, position, rotation):\n",
    "        self.position = position\n",
    "        self.rotation = rotation\n",
    "        \n",
    "    def get_position(self):\n",
    "        return self.position\n",
    "    \n",
    "    def get_rotation(self):\n",
    "        return self.rotation\n",
    "        \n",
    "    def radian_to_grade(self, angle):\n",
    "        return angle / 2 / math.pi * 360 + 180\n",
    "        \n",
    "    def print(self):\n",
    "        print('Position= ', self.position, sep='')\n",
    "        print('Rotation=', self.rotation, sep='')\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_difference_position(p1, p2):\n",
    "        return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2 + (p1[2] - p2[2])**2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_difference_rotation(r1, r2):\n",
    "        f1 = quaternion.as_float_array(r1)[0]\n",
    "        f2 = quaternion.as_float_array(r1)[2]\n",
    "        \n",
    "        s1 = quaternion.as_float_array(r2)[0]\n",
    "        s2 = quaternion.as_float_array(r2)[2]\n",
    "        return math.sqrt((f1 - s1) ** 2 + (f2 - s2) ** 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_diff(p1, p2):\n",
    "        position1 = p1.get_position()\n",
    "        position2 = p2.get_position()\n",
    "        position_diff = AgentPosition.get_difference_position(position1, position2)\n",
    "        \n",
    "        rotation1 = p1.get_rotation()\n",
    "        rotation2 = p2.get_rotation()\n",
    "        \n",
    "        rotation_diff = AgentPosition.get_difference_rotation(rotation1, rotation2)\n",
    "        \n",
    "        return position_diff * AgentPosition.coordinate_weight + rotation_diff * AgentPosition.angle_weight\n",
    "        \n",
    "    @staticmethod\n",
    "    def is_close(p1, p2):\n",
    "        \n",
    "        diff = AgentPosition.get_diff(p1, p2)\n",
    "        \n",
    "#         print(diff)\n",
    "        \n",
    "        return AgentPosition.min_diff > diff\n",
    "    \n",
    "    def create_np_array(self):\n",
    "        return np.array([\n",
    "            self.position[0] * AgentPosition.coordinate_weight,\n",
    "            self.position[1] * AgentPosition.coordinate_weight,\n",
    "            self.position[2] * AgentPosition.coordinate_weight,\n",
    "            quaternion.as_float_array(self.rotation)[0] * AgentPosition.angle_weight,\n",
    "            quaternion.as_float_array(self.rotation)[2] * AgentPosition.angle_weight\n",
    "        ])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the sensor and register it with habitat\n",
    "# For the sensor, we will register it with a custom name\n",
    "@habitat.registry.register_sensor(name=\"my_supercool_sensor\")\n",
    "class AgentPositionSensor(habitat.Sensor):\n",
    "    def __init__(self, sim, config, **kwargs: Any):\n",
    "        super().__init__(config=config)\n",
    "\n",
    "        self._sim = sim\n",
    "        # Prints out the answer to life on init\n",
    "        print(\"The answer to life is\", self.config.ANSWER_TO_LIFE)\n",
    "\n",
    "    # Defines the name of the sensor in the sensor suite dictionary\n",
    "    def _get_uuid(self, *args: Any, **kwargs: Any):\n",
    "        return \"agent_position\"\n",
    "\n",
    "    # Defines the type of the sensor\n",
    "    def _get_sensor_type(self, *args: Any, **kwargs: Any):\n",
    "        return habitat.SensorTypes.POSITION\n",
    "\n",
    "    # Defines the size and range of the observations of the sensor\n",
    "    def _get_observation_space(self, *args: Any, **kwargs: Any):\n",
    "        return 5\n",
    "\n",
    "    # This is called whenver reset is called or an action is taken\n",
    "    def get_observation(\n",
    "        self, observations, *args: Any, episode, **kwargs: Any\n",
    "    ):\n",
    "        return AgentPosition(self._sim.get_agent_state().position, self._sim.get_agent_state().rotation).create_np_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = habitat.get_config(\"/home/green-tea/all_projects/habitat/segmentation/configs/challenge_objectnav2020.local.rgbd.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.defrost()\n",
    "\n",
    "config.DATASET.DATA_PATH = \"/home/green-tea/all_stash/matterport3D/data/val_mini.json.gz\"\n",
    "config.DATASET.SCENES_DIR = \"/home/green-tea/all_stash/matterport3D/data4/v1/tasks\"\n",
    "\n",
    "config.SIMULATOR.AGENT_0.SENSORS.append('SEMANTIC_SENSOR')\n",
    "\n",
    "config.TASK.AGENT_POSITION_SENSOR = habitat.Config()\n",
    "config.TASK.AGENT_POSITION_SENSOR.TYPE = \"my_supercool_sensor\"\n",
    "config.TASK.AGENT_POSITION_SENSOR.ANSWER_TO_LIFE = 42\n",
    "config.TASK.SENSORS.append(\"AGENT_POSITION_SENSOR\")\n",
    "\n",
    "config.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-09 11:11:53,022 Initializing dataset ObjectNav-v1\n",
      "2020-04-09 11:11:53,067 initializing sim Sim-v0\n",
      "I0409 11:11:58.318681 28314 simulator.py:143] Loaded navmesh /home/green-tea/all_stash/matterport3D/data4/v1/tasks/mp3d/x8F5xyUWy9e/x8F5xyUWy9e.navmesh\n",
      "I0409 11:11:58.319488 28314 simulator.py:155] Recomputing navmesh for agent's height 0.88 and radius 0.18.\n",
      "2020-04-09 11:11:58,413 Initializing task ObjectNav-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to life is 42\n"
     ]
    }
   ],
   "source": [
    "env = habitat.Env(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY_X = '/home/green-tea/all_projects/habitat/mask-r-cnn/X'\n",
    "DATASET_DIRECTORY_Y = '/home/green-tea/all_projects/habitat/mask-r-cnn/Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_semantic_observation(observations):\n",
    "    scene = env.sim.semantic_annotations()\n",
    "    instance_id_to_label_id = {int(obj.id.split(\"_\")[-1]): obj.category.index() for obj in scene.objects}\n",
    "    mapping = np.array([ instance_id_to_label_id[i] for i in range(len(instance_id_to_label_id)) ])\n",
    "\n",
    "    return np.take(mapping, observations['semantic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'wall', 40: 'misc', 16: 'stairs', 4: 'door', 2: 'floor', 39: 'objects', 17: 'ceiling', 0: 'void', 14: 'plant', 24: 'column', -1: 'nope', 5: 'table', 21: 'mirror', 15: 'sink', 7: 'cabinet', 28: 'lighting', 34: 'seating', 20: 'towel', 12: 'curtain', 9: 'window', 23: 'shower', 38: 'clothes', 11: 'bed', 35: 'board_panel', 37: 'appliances', 31: 'shelving', 26: 'counter', 22: 'tv_monitor', 3: 'chair'}\n"
     ]
    }
   ],
   "source": [
    "scene = env.sim.semantic_annotations()\n",
    "index_to_title_map = {obj.category.index(): obj.category.name() for obj in scene.objects }\n",
    "index_to_title_map[-1] = 'nope'\n",
    "print(index_to_title_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_for_dataset(observations):\n",
    "    rgb = observations['rgb']\n",
    "    \n",
    "    image = Image.fromarray(rgb)\n",
    "    u = uuid.uuid1()\n",
    "    \n",
    "    image.save(DATASET_DIRECTORY_X + \"/\" + str(u) + '.png')\n",
    "    \n",
    "#     semantic = prepare_semantic_observation(observations)\n",
    "    semantic = observations['semantic']\n",
    "    \n",
    "    unique_values = np.unique(semantic)\n",
    "    objects = []\n",
    "    \n",
    "    os.mkdir(DATASET_DIRECTORY_Y + \"/\" + str(u))\n",
    "    \n",
    "    for value in unique_values:\n",
    "        obj = (semantic == value)\n",
    "        \n",
    "        title = str(value)\n",
    "        \n",
    "        image = Image.fromarray(obj)\n",
    "        image.save(DATASET_DIRECTORY_Y + \"/\" + str(u) + \"/\" + title + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17 17 17 ...  1  1  1]\n",
      " [17 17 17 ...  1  1  1]\n",
      " [31 31 31 ...  1  1  1]\n",
      " ...\n",
      " [ 2  2  2 ...  1  1  1]\n",
      " [ 2  2  2 ...  1  1  1]\n",
      " [ 2  2  2 ...  1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "print(prepare_semantic_observation(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_for_dataset(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_action(cur_action, last_action, is_bump):\n",
    "    if is_bump and cur_action == 'MOVE_FORWARD':\n",
    "        return False\n",
    "    \n",
    "    if cur_action == 'TURN_LEFT' and last_action == 'TURN_RIGHT':\n",
    "        return False\n",
    "    if cur_action == 'TURN_RIGHT' and last_action == 'TURN_LEFT':\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_action(last, is_bump):\n",
    "    action = random.choice(list(action_mapping))\n",
    "\n",
    "    while not(check_action(action, last, is_bump)):\n",
    "        action = random.choice(list(action_mapping))\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Saver:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.path = 'images'\n",
    "        self.all_positions = {}\n",
    "        \n",
    "    def save_image(self, observations, env):\n",
    "        cur_scene = env.current_episode.scene_id\n",
    "        \n",
    "        if self.check_exist_image(observations, cur_scene):\n",
    "            return;\n",
    "\n",
    "        save_image_for_dataset(observations)\n",
    "\n",
    "        self.count += 1\n",
    "        \n",
    "        if cur_scene in self.all_positions:\n",
    "            self.all_positions[cur_scene] = np.append(self.all_positions[cur_scene], [observations['agent_position']], axis=0)\n",
    "        else:\n",
    "            self.all_positions[cur_scene] = np.array([observations['agent_position']])\n",
    "        \n",
    "    def check_exist_image(self, observations, cur_scene):\n",
    "        cur_position = observations['agent_position']\n",
    "        \n",
    "        if not(cur_scene in self.all_positions):\n",
    "            return False\n",
    "        \n",
    "        min_diff = np.sqrt(np.square(self.all_positions[cur_scene] - cur_position).sum(axis=1).min())\n",
    "        \n",
    "        return min_diff <= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bump(last_observations, observations):\n",
    "    return np.sqrt(np.square(last_observations['agent_position'] - observations['agent_position']).sum()) <= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_mapping = {\n",
    "    1: 'MOVE_FORWARD',\n",
    "    2: 'TURN_LEFT',\n",
    "    3: 'TURN_RIGHT'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e6718468cc85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlast_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mis_bump\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/all_projects/habitat/habitat-api/habitat/core/env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         self._task.measurements.update_measures(\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mepisode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_episode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         )\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/all_projects/habitat/habitat-api/habitat/core/embodied_task.py\u001b[0m in \u001b[0;36mupdate_measures\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_measures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmeasure\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/all_projects/habitat/habitat-api/habitat/tasks/nav/nav.py\u001b[0m in \u001b[0;36mupdate_metric\u001b[0;34m(self, episode, *args, **kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISTANCE_TO\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"VIEW_POINTS\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             distance_to_target = self._sim.geodesic_distance(\n\u001b[0;32m--> 875\u001b[0;31m                 \u001b[0mcurrent_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_view_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m             )\n\u001b[1;32m    877\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/all_projects/habitat/habitat-api/habitat/sims/habitat_simulator/habitat_simulator.py\u001b[0m in \u001b[0;36mgeodesic_distance\u001b[0;34m(self, position_a, position_b)\u001b[0m\n\u001b[1;32m    313\u001b[0m             )\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathfinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeodesic_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saver = Saver()\n",
    "\n",
    "index = 0\n",
    "for i in range(len(env.episodes)):\n",
    "    observations = env.reset()\n",
    "\n",
    "    last = ''\n",
    "    is_bump = False\n",
    "\n",
    "    for i in range(300):\n",
    "        action = get_random_action(last, is_bump)\n",
    "        last = action\n",
    "\n",
    "        last_observations = observations\n",
    "        observations = env.step(action)\n",
    "\n",
    "        is_bump = check_bump(last_observations, observations)\n",
    "        \n",
    "        if index == 1000:\n",
    "            break\n",
    "            \n",
    "        index += 1\n",
    "\n",
    "        saver.save_image(observations, env)\n",
    "        \n",
    "    if index == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = observations['rgb'].reshape([320, 240, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 12), |u1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2713\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 12), '|u1')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-fa94b74a4b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkek\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2714\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2716\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2717\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 12), |u1"
     ]
    }
   ],
   "source": [
    "kek.shape\n",
    "img = Image.fromarray(kek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "habitat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
