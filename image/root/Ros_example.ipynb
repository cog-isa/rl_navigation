{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "!ln -s /data /habitat-api/data\n",
    "!ln -s /data ./data\n",
    "sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import habitat\n",
    "from habitat.sims.habitat_simulator.actions import HabitatSimActions\n",
    "import rospy\n",
    "import rosgraph\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from nav_msgs.msg import Path, Odometry\n",
    "from geometry_msgs.msg import Pose, PoseStamped\n",
    "from cv_bridge import CvBridge\n",
    "import numpy as np\n",
    "import keyboard\n",
    "import argparse\n",
    "import transformations as tf\n",
    "from typing import Any\n",
    "from gym import spaces\n",
    "from habitat.utils.visualizations import maps\n",
    "from skimage.io import imsave\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 20\n",
    "D = [0, 0, 0, 0, 0]\n",
    "K = [160, 0.0, 160.5, 0.0, 160, 120.5, 0.0, 0.0, 1.0]\n",
    "R = [1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
    "P = [160, 0.0, 160.5, 0.0, 0.0, 160, 120.5, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
    "MAX_DEPTH = 100\n",
    "\n",
    "def inverse_transform(x, y, start_x, start_y, start_angle):\n",
    "    new_x = (x - start_x) * np.cos(start_angle) + (y - start_y) * np.sin(start_angle)\n",
    "    new_y = -(x - start_x) * np.sin(start_angle) + (y - start_y) * np.cos(start_angle)\n",
    "    return new_x, new_y\n",
    "\n",
    "def get_local_pointcloud(rgb, depth, fov=90):\n",
    "    fov = fov / (180 / np.pi)\n",
    "    H, W, _ = rgb.shape\n",
    "    idx_h = np.tile(np.arange(H), W).reshape((W, H)).T.astype(np.float32) - 120\n",
    "    idx_w = np.tile(np.arange(W), H).reshape((H, W)).astype(np.float32) - 160\n",
    "    print(W, (W / 2 * np.tan(fov / 2)))\n",
    "    idx_h /= (W / 2 * np.tan(fov / 2))\n",
    "    idx_w /= (W / 2 * np.tan(fov / 2))\n",
    "    points = np.array([np.ones((H, W)), -idx_w, -idx_h])\n",
    "    points = np.transpose(points, [1, 2, 0])\n",
    "    points_dist = np.sqrt(np.sum(points ** 2, axis=2))\n",
    "    #points = points / points_dist[:, :, np.newaxis] * depth * 10.0\n",
    "    points = points * depth * MAX_DEPTH\n",
    "    points = np.array([points[:, :, 0].ravel(), points[:, :, 1].ravel(), points[:, :, 2].ravel()]).T\n",
    "    return points\n",
    "\n",
    "# Define the sensor and register it with habitat\n",
    "# For the sensor, we will register it with a custom name\n",
    "@habitat.registry.register_sensor(name=\"position_sensor\")\n",
    "class AgentPositionSensor(habitat.Sensor):\n",
    "    def __init__(self, sim, config, **kwargs: Any):\n",
    "        super().__init__(config=config)\n",
    "\n",
    "        self._sim = sim\n",
    "\n",
    "    # Defines the name of the sensor in the sensor suite dictionary\n",
    "    def _get_uuid(self, *args: Any, **kwargs: Any):\n",
    "        return \"agent_position\"\n",
    "\n",
    "    # Defines the type of the sensor\n",
    "    def _get_sensor_type(self, *args: Any, **kwargs: Any):\n",
    "        return habitat.SensorTypes.POSITION\n",
    "\n",
    "    # Defines the size and range of the observations of the sensor\n",
    "    def _get_observation_space(self, *args: Any, **kwargs: Any):\n",
    "        return spaces.Box(\n",
    "            low=np.finfo(np.float32).min,\n",
    "            high=np.finfo(np.float32).max,\n",
    "            shape=(3,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    # This is called whenver reset is called or an action is taken\n",
    "    def get_observation(\n",
    "        self, observations, *args: Any, episode, **kwargs: Any\n",
    "    ):\n",
    "        sensor_states = self._sim.get_agent_state().sensor_states\n",
    "        return (sensor_states['rgb'].position, sensor_states['rgb'].rotation)\n",
    "\n",
    "\n",
    "class KeyboardAgent(habitat.Agent):\n",
    "    def __init__(self, \n",
    "                 save_observations=True,\n",
    "                 rgb_topic='/habitat/rgb/image',\n",
    "                 depth_topic='/habitat/depth/image',\n",
    "                 camera_info_topic='/habitat/rgb/camera_info',\n",
    "                 path_topic='/true_path',\n",
    "                 odometry_topic='/true_path',\n",
    "                 publish_odom=True):\n",
    "        rospy.init_node('agent')\n",
    "        self.save_observations = save_observations\n",
    "        self.image_publisher = rospy.Publisher(rgb_topic, Image, latch=True, queue_size=100)\n",
    "        self.depth_publisher = rospy.Publisher(depth_topic, Image, latch=True, queue_size=100)\n",
    "        self.camera_info_publisher = rospy.Publisher(camera_info_topic, CameraInfo, latch=True, queue_size=100)\n",
    "        self.true_path_publisher = rospy.Publisher(path_topic, Path, queue_size=100)\n",
    "        self.publish_odom = publish_odom\n",
    "        if self.publish_odom:\n",
    "            self.odom_publisher = rospy.Publisher(odometry_topic, Odometry, latch=True, queue_size=100)\n",
    "        self.image = Image()\n",
    "        self.image.height = 240\n",
    "        self.image.width = 320\n",
    "        self.image.encoding = 'rgb8'\n",
    "        self.image.is_bigendian = False\n",
    "        self.depth = Image()\n",
    "        self.depth.height = 240\n",
    "        self.depth.width = 320\n",
    "        self.depth.is_bigendian = True\n",
    "        self.depth.encoding = 'mono8'\n",
    "        self.camera_info = CameraInfo(width=320, height=240, D=D, K=K, R=R, P=P) \n",
    "        self.cvbridge = CvBridge()\n",
    "        self.trajectory = []\n",
    "        self.map_path_subscriber = rospy.Subscriber('mapPath', Path, self.mappath_callback)\n",
    "        self.slam_start_time = -1000\n",
    "        self.slam_update_time = -1000\n",
    "        self.is_started = False\n",
    "        self.points = []\n",
    "        self.positions = []\n",
    "        self.rotations = []\n",
    "        self.rgbs = []\n",
    "        self.depths = []\n",
    "        self.actions = []\n",
    "        self.timestamps = []\n",
    "\n",
    "    def mappath_callback(self, data):\n",
    "        mappath_pose = data.poses[-1].pose\n",
    "        x, y, z = mappath_pose.position.x, mappath_pose.position.y, mappath_pose.position.z\n",
    "        xx, yy, zz, w = mappath_pose.orientation.x, mappath_pose.orientation.y, mappath_pose.orientation.z, mappath_pose.orientation.w\n",
    "        cur_time = rospy.Time.now().secs + rospy.Time.now().nsecs * 1e-9\n",
    "        eps = 1e-5\n",
    "        if cur_time - self.slam_update_time > 30:\n",
    "            self.slam_start_time = cur_time\n",
    "            start_orientation = self.trajectory[-1].pose.orientation\n",
    "            start_position = self.trajectory[-1].pose.position\n",
    "            x_angle, z_angle, y_angle = tf.euler_from_quaternion([start_orientation.x, start_orientation.y, start_orientation.z, start_orientation.w])\n",
    "            self.slam_start_angle = z_angle\n",
    "            self.slam_start_x = start_position.x\n",
    "            self.slam_start_y = start_position.y\n",
    "            self.slam_start_z = start_position.z\n",
    "            self.trajectory = []\n",
    "        self.slam_update_time = cur_time\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def get_actions_from_keyboard(self):\n",
    "        keyboard_commands = []\n",
    "        if keyboard.is_pressed('left'):\n",
    "            keyboard_commands.append(HabitatSimActions.TURN_LEFT)\n",
    "        if keyboard.is_pressed('right'):\n",
    "            keyboard_commands.append(HabitatSimActions.TURN_RIGHT)\n",
    "        if keyboard.is_pressed('up'):\n",
    "            keyboard_commands.append(HabitatSimActions.MOVE_FORWARD)\n",
    "        return keyboard_commands\n",
    "\n",
    "    def publish_rgb(self, image):\n",
    "        start_time = rospy.Time.now()\n",
    "        self.image = self.cvbridge.cv2_to_imgmsg(image)\n",
    "        self.image.encoding = 'rgb8'\n",
    "        self.image.header.stamp = start_time\n",
    "        self.image.header.frame_id = 'camera_link'\n",
    "        self.image_publisher.publish(self.image)\n",
    "\n",
    "    def publish_depth(self, depth):\n",
    "        start_time = rospy.Time.now()\n",
    "        self.depth = self.cvbridge.cv2_to_imgmsg(depth * MAX_DEPTH)\n",
    "        self.depth.header.stamp = start_time\n",
    "        self.depth.header.frame_id = 'base_scan'\n",
    "        self.depth_publisher.publish(self.depth)\n",
    "\n",
    "    def publish_camera_info(self):\n",
    "        start_time = rospy.Time.now()\n",
    "        self.camera_info.header.stamp = start_time\n",
    "        self.camera_info_publisher.publish(self.camera_info)\n",
    "\n",
    "    def publish_true_path(self, pose, publish_odom):\n",
    "        # count current coordinates and direction in global coords\n",
    "        start_time = rospy.Time.now()\n",
    "        position, rotation = pose\n",
    "        y, z, x = position\n",
    "        cur_orientation = rotation\n",
    "        cur_euler_angles = tf.euler_from_quaternion([cur_orientation.w, cur_orientation.x, cur_orientation.z, cur_orientation.y])\n",
    "        cur_x_angle, cur_y_angle, cur_z_angle = cur_euler_angles\n",
    "        cur_z_angle += np.pi\n",
    "        print('Source position:', y, z, x)\n",
    "        print('Source quat:', cur_orientation.x, cur_orientation.y, cur_orientation.z, cur_orientation.w)\n",
    "        print('Euler angles:', cur_x_angle, cur_y_angle, cur_z_angle)\n",
    "        #print('After tf:', tf.quaternion_from_euler(cur_x_angle, cur_y_angle, cur_z_angle))\n",
    "        if self.publish_odom:\n",
    "            self.slam_update_time = start_time.secs + 1e-9 * start_time.nsecs\n",
    "            if not self.is_started:\n",
    "                self.is_started = True\n",
    "                self.slam_start_angle = cur_z_angle\n",
    "                print(\"SLAM START ANGLE:\", self.slam_start_angle)\n",
    "                self.slam_start_x = x\n",
    "                self.slam_start_y = y\n",
    "                self.slam_start_z = z\n",
    "        # if SLAM is running, transform global coords to RViz coords\n",
    "        if self.publish_odom or (start_time.secs + start_time.nsecs * 1e-9) - self.slam_update_time < 30:\n",
    "            rviz_x, rviz_y = inverse_transform(x, y, self.slam_start_x, self.slam_start_y, self.slam_start_angle)\n",
    "            rviz_z = z - self.slam_start_z\n",
    "            cur_quaternion = tf.quaternion_from_euler(0, 0, cur_z_angle - self.slam_start_angle)\n",
    "            print('Rotated quat:', cur_quaternion)\n",
    "            cur_orientation.w = cur_quaternion[0]\n",
    "            cur_orientation.x = cur_quaternion[1]\n",
    "            cur_orientation.y = cur_quaternion[2]\n",
    "            cur_orientation.z = cur_quaternion[3]\n",
    "            x, y, z = rviz_x, rviz_y, rviz_z\n",
    "        self.positions.append(np.array([x, y, z]))\n",
    "        self.rotations.append(tf.quaternion_matrix(cur_quaternion))\n",
    "        # add current point to path\n",
    "        cur_pose = PoseStamped()\n",
    "        cur_pose.header.stamp = start_time\n",
    "        cur_pose.pose.position.x = x\n",
    "        cur_pose.pose.position.y = y\n",
    "        cur_pose.pose.position.z = z\n",
    "        cur_pose.pose.orientation = cur_orientation\n",
    "        self.trajectory.append(cur_pose)\n",
    "        # publish the path\n",
    "        true_path = Path()\n",
    "        true_path.header.stamp = start_time\n",
    "        true_path.header.frame_id = 'map'\n",
    "        true_path.poses = self.trajectory\n",
    "        self.true_path_publisher.publish(true_path)\n",
    "        # publish odometry\n",
    "        if self.publish_odom:\n",
    "            odom = Odometry()\n",
    "            odom.header.stamp = start_time\n",
    "            odom.header.frame_id = 'odom'\n",
    "            odom.child_frame_id = 'base_link'\n",
    "            odom.pose.pose = cur_pose.pose\n",
    "            self.odom_publisher.publish(odom)\n",
    "\n",
    "    def act(self, observations):\n",
    "        # publish all observations to ROS\n",
    "        start_time = rospy.Time.now()\n",
    "        pcd = get_local_pointcloud(observations['rgb'], observations['depth'])\n",
    "        print(pcd.shape)\n",
    "        if self.save_observations:\n",
    "            self.points.append(pcd)\n",
    "            self.rgbs.append(observations['rgb'].reshape((240 * 320, 3)))\n",
    "            self.depths.append(observations['depth'])\n",
    "            cur_time = rospy.Time.now()\n",
    "            self.timestamps.append(cur_time.secs + 1e-9 * cur_time.nsecs)\n",
    "        #self.positions.append(observations['agent_position'][0])\n",
    "        #quaternion = observations['agent_position'][1]\n",
    "        #rotation_matrix = [quaternion.w, quaternion.x, quaternion.y, quaternion.z]\n",
    "        #self.rotations.append(rotation_matrix)\n",
    "        self.publish_rgb(observations['rgb'])\n",
    "        self.publish_depth(observations['depth'])\n",
    "        self.publish_camera_info()\n",
    "        self.publish_true_path(observations['agent_position'], self.publish_odom)\n",
    "        # receive command from keyboard and move\n",
    "        actions = self.get_actions_from_keyboard()\n",
    "        start_time_seconds = start_time.secs + start_time.nsecs * 1e-9\n",
    "        cur_time = rospy.Time.now()\n",
    "        cur_time_seconds = cur_time.secs + cur_time.nsecs * 1e-9\n",
    "        # make act time (1/rate) seconds\n",
    "        time_left = cur_time_seconds - start_time_seconds\n",
    "        if len(actions) > 0:\n",
    "            rospy.sleep(1. / (rate * len(actions)) - time_left)\n",
    "            action = np.random.choice(actions)\n",
    "        else:\n",
    "            rospy.sleep(1. / rate)\n",
    "            action = HabitatSimActions.STOP\n",
    "        self.actions.append(str(action))\n",
    "        return action\n",
    "\n",
    "\n",
    "def build_pointcloud(sim, discretization=0.05, grid_size=500, num_samples=20000):\n",
    "    range_x = (np.inf, -np.inf)\n",
    "    range_y = (np.inf, -np.inf)\n",
    "    range_z = (np.inf, -np.inf)\n",
    "    pointcloud = set()\n",
    "    for i in range(num_samples):\n",
    "        point = sim.sample_navigable_point()\n",
    "        x, z, y = point\n",
    "        z = np.random.random() * 3\n",
    "        range_x = (min(range_x[0], x), max(range_x[1], x))\n",
    "        range_y = (min(range_y[0], y), max(range_y[1], y))\n",
    "        range_z = (min(range_z[0], z), max(range_z[1], z))\n",
    "    for x in tqdm(np.linspace(range_x[0], range_x[1], grid_size)):\n",
    "        for y in np.linspace(range_y[0], range_y[1], grid_size):\n",
    "            for z in np.linspace(range_z[0], range_z[1], 100):\n",
    "                closest_obstacle_point = sim._sim.pathfinder.closest_obstacle_surface_point(np.array([x, z, y])).hit_pos\n",
    "                x_, z_, y_ = closest_obstacle_point\n",
    "                x_ = np.round(x_ / discretization) * discretization\n",
    "                y_ = np.round(y_ / discretization) * discretization\n",
    "                z_ = np.round(z_ / discretization) * discretization\n",
    "                pointcloud.add((x_, y_, z_))\n",
    "    return np.array(list(pointcloud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--task-config\", type=str, default=\"configs/tasks/pointnav.yaml\")\n",
    "parser.add_argument(\"--publish-odom\", type=bool, default=True)\n",
    "parser.add_argument(\"--create-map\", type=bool, default=False)\n",
    "parser.add_argument(\"--save-observations\", type=bool, default=False)\n",
    "parser.add_argument(\"--preset-trajectory\", type=bool, default=False)\n",
    "args = parser.parse_args(\"\")\n",
    "# Now define the config for the sensor\n",
    "config = habitat.get_config(config_paths=\"../habitat-api/configs/tasks/pointnav.yaml\")\n",
    "config.defrost()\n",
    "config.TASK.MEASUREMENTS.append(\"TOP_DOWN_MAP\")\n",
    "config.TASK.SENSORS.append(\"HEADING_SENSOR\")\n",
    "config.SIMULATOR.SCENE = 'data/scene_datasets/gibson/Aldrich.glb'\n",
    "config.freeze()\n",
    "max_depth = config.SIMULATOR.DEPTH_SENSOR.MAX_DEPTH\n",
    "print(args.create_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-19 12:02:35,414 Initializing dataset PointNav-v1\n",
      "2020-02-19 12:02:35,757 initializing sim Sim-v0\n",
      "I0219 12:02:37.179933 441 simulator.py:142] Loaded navmesh data/scene_datasets/habitat-test-scenes/skokloster-castle.navmesh\n",
      "2020-02-19 12:02:37,191 Initializing task Nav-v0\n"
     ]
    }
   ],
   "source": [
    "agent = KeyboardAgent(args.save_observations)\n",
    "env = habitat.Env(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create map\n",
      "0 0.00988748 2\n"
     ]
    }
   ],
   "source": [
    "print('create map')\n",
    "top_down_map = maps.get_topdown_map(env.sim, map_resolution=(5000, 5000))\n",
    "print(top_down_map.min(), top_down_map.mean(), top_down_map.max())\n",
    "recolor_map = np.array([[0, 0, 0], [128, 128, 128], [255, 255, 255]], dtype=np.uint8)\n",
    "range_x = np.where(np.any(top_down_map, axis=1))[0]\n",
    "range_y = np.where(np.any(top_down_map, axis=0))[0]\n",
    "padding = int(np.ceil(top_down_map.shape[0] / 125))\n",
    "range_x = (\n",
    "    max(range_x[0] - padding, 0),\n",
    "    min(range_x[-1] + padding + 1, top_down_map.shape[0]),\n",
    ")\n",
    "range_y = (\n",
    "    max(range_y[0] - padding, 0),\n",
    "    min(range_y[-1] + padding + 1, top_down_map.shape[1]),\n",
    ")\n",
    "top_down_map = top_down_map[\n",
    "    range_x[0] : range_x[1], range_y[0] : range_y[1]\n",
    "]\n",
    "top_down_map = recolor_map[top_down_map]\n",
    "imsave('top_down_map.png', top_down_map)\n",
    "observations = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ROSInitException",
     "evalue": "time is not initialized. Have you called init_node()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mROSInitException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7bb9d45822d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-7d0a3512a94c>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# publish all observations to ROS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0mpcd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_pointcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rgb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/rostime.py\u001b[0m in \u001b[0;36mnow\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mTime\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_rostime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/kinetic/lib/python2.7/dist-packages/rospy/rostime.py\u001b[0m in \u001b[0;36mget_rostime\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_rostime_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROSInitException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time is not initialized. Have you called init_node()?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_rostime_current\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# initialize with sim time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mROSInitException\u001b[0m: time is not initialized. Have you called init_node()?"
     ]
    }
   ],
   "source": [
    "action = agent.act(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
