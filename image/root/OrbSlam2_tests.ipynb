{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "import numpy as np\n",
    "import orbslam2\n",
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import habitat\n",
    "from habitat.config.default import get_config\n",
    "from habitat.sims.habitat_simulator.actions import HabitatSimActions\n",
    "from habitat_baselines.config.default import get_config as cfg_baseline\n",
    "from habitat_baselines.slambased.mappers import DirectDepthMapper\n",
    "from habitat_baselines.slambased.monodepth import MonoDepthEstimator\n",
    "from habitat_baselines.slambased.path_planners import DifferentiableStarPlanner\n",
    "from habitat_baselines.slambased.reprojection import (\n",
    "    angle_to_pi_2_minus_pi_2 as norm_ang,\n",
    ")\n",
    "from habitat_baselines.slambased.reprojection import (\n",
    "    get_direction,\n",
    "    get_distance,\n",
    "    habitat_goalpos_to_mapgoal_pos,\n",
    "    homogenize_p,\n",
    "    planned_path2tps,\n",
    "    project_tps_into_worldmap,\n",
    ")\n",
    "from habitat_baselines.slambased.utils import generate_2dgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/habitat-api/data/data': File exists\n",
      "ln: failed to create symbolic link './data/data': File exists\n"
     ]
    }
   ],
   "source": [
    "!ln -s /data /habitat-api/data\n",
    "!ln -s /data ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOAL_SENSOR_UUID = \"pointgoal_with_gps_compass\"\n",
    "\n",
    "def download(url, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        response = requests.get(url, stream=True)\n",
    "        total = response.headers.get(\"content-length\")\n",
    "        if total is None:\n",
    "            f.write(response.content)\n",
    "        else:\n",
    "            downloaded = 0\n",
    "            total = int(total)\n",
    "            for data in response.iter_content(\n",
    "                chunk_size=max(int(total / 1000), 1024 * 1024)\n",
    "            ):\n",
    "                downloaded += len(data)\n",
    "                f.write(data)\n",
    "                done = int(50 * downloaded / total)\n",
    "                sys.stdout.write(\n",
    "                    \"\\r[{}{}]\".format(\"â–ˆ\" * done, \".\" * (50 - done))\n",
    "                )\n",
    "                sys.stdout.flush()\n",
    "    sys.stdout.write(\"\\n\")\n",
    "\n",
    "\n",
    "def ResizePIL2(np_img, size=256):\n",
    "    im1 = PIL.Image.fromarray(np_img)\n",
    "    return np.array(im1.resize((size, size)))\n",
    "\n",
    "\n",
    "def make_good_config_for_orbslam2(config):\n",
    "    config.SIMULATOR.AGENT_0.SENSORS = [\"RGB_SENSOR\", \"DEPTH_SENSOR\"]\n",
    "    config.SIMULATOR.RGB_SENSOR.WIDTH = 256\n",
    "    config.SIMULATOR.RGB_SENSOR.HEIGHT = 256\n",
    "    config.SIMULATOR.DEPTH_SENSOR.WIDTH = 256\n",
    "    config.SIMULATOR.DEPTH_SENSOR.HEIGHT = 256\n",
    "    config.ORBSLAM2.CAMERA_HEIGHT = config.SIMULATOR.DEPTH_SENSOR.POSITION[1]\n",
    "    config.ORBSLAM2.H_OBSTACLE_MIN = (0.3 * config.ORBSLAM2.CAMERA_HEIGHT)\n",
    "    config.ORBSLAM2.H_OBSTACLE_MAX = (1.0 * config.ORBSLAM2.CAMERA_HEIGHT)\n",
    "    config.ORBSLAM2.MIN_PTS_IN_OBSTACLE = (config.SIMULATOR.DEPTH_SENSOR.WIDTH / 2.0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from habitat_baselines.slambased.reprojection import angle_to_pi_2_minus_pi_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from habitat_baselines.agents.slam_agents import RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORBSLAM2Agent(RandomAgent):\n",
    "    def __init__(self, config, device=torch.device(\"cuda:0\")):\n",
    "        self.num_actions = config.NUM_ACTIONS\n",
    "        self.dist_threshold_to_stop = config.DIST_TO_STOP\n",
    "        self.slam_vocab_path = config.SLAM_VOCAB_PATH\n",
    "        assert os.path.isfile(self.slam_vocab_path)\n",
    "        self.slam_settings_path = config.SLAM_SETTINGS_PATH\n",
    "        assert os.path.isfile(self.slam_settings_path)\n",
    "        self.slam = orbslam2.System(\n",
    "            self.slam_vocab_path, self.slam_settings_path, orbslam2.Sensor.RGBD\n",
    "        )\n",
    "        self.slam.set_use_viewer(False)\n",
    "        self.slam.initialize()\n",
    "        self.device = device\n",
    "        self.map_size_meters = config.MAP_SIZE\n",
    "        self.map_cell_size = config.MAP_CELL_SIZE\n",
    "        self.pos_th = config.DIST_REACHED_TH\n",
    "        self.next_wp_th = config.NEXT_WAYPOINT_TH\n",
    "        self.angle_th = config.ANGLE_TH\n",
    "        self.obstacle_th = config.MIN_PTS_IN_OBSTACLE\n",
    "        self.depth_denorm = config.DEPTH_DENORM\n",
    "        self.planned_waypoints = []\n",
    "        self.mapper = DirectDepthMapper(\n",
    "            camera_height=config.CAMERA_HEIGHT,\n",
    "            near_th=config.D_OBSTACLE_MIN,\n",
    "            far_th=config.D_OBSTACLE_MAX,\n",
    "            h_min=config.H_OBSTACLE_MIN,\n",
    "            h_max=config.H_OBSTACLE_MAX,\n",
    "            map_size=config.MAP_SIZE,\n",
    "            map_cell_size=config.MAP_CELL_SIZE,\n",
    "            device=device,\n",
    "        )\n",
    "        self.planner = DifferentiableStarPlanner(\n",
    "            max_steps=config.PLANNER_MAX_STEPS,\n",
    "            preprocess=config.PREPROCESS_MAP,\n",
    "            beta=config.BETA,\n",
    "            device=device,\n",
    "        )\n",
    "        self.slam_to_world = 1.0\n",
    "        self.timestep = 0.1\n",
    "        self.timing = False\n",
    "        self.reset()\n",
    "        return\n",
    "\n",
    "    def reset(self):\n",
    "        super(ORBSLAM2Agent, self).reset()\n",
    "        self.offset_to_goal = None\n",
    "        self.tracking_is_OK = False\n",
    "        self.waypointPose6D = None\n",
    "        self.unseen_obstacle = False\n",
    "        self.action_history = []\n",
    "        self.planned_waypoints = []\n",
    "        self.map2DObstacles = self.init_map2d()\n",
    "        n, ch, height, width = self.map2DObstacles.size()\n",
    "        self.coordinatesGrid = generate_2dgrid(height, width, False).to(\n",
    "            self.device\n",
    "        )\n",
    "        self.pose6D = self.init_pose6d()\n",
    "        self.action_history = []\n",
    "        self.pose6D_history = []\n",
    "        self.position_history = []\n",
    "        self.planned2Dpath = torch.zeros((0))\n",
    "        self.slam.reset()\n",
    "        self.cur_time = 0\n",
    "        self.toDoList = []\n",
    "        self.waypoint_id = 0\n",
    "        if self.device != torch.device(\"cpu\"):\n",
    "            torch.cuda.empty_cache()\n",
    "        return\n",
    "\n",
    "    def update_internal_state(self, habitat_observation):\n",
    "        super(ORBSLAM2Agent, self).update_internal_state(habitat_observation)\n",
    "        self.cur_time += self.timestep\n",
    "        rgb, depth = self.rgb_d_from_observation(habitat_observation)\n",
    "        t = time.time()\n",
    "        try:\n",
    "            self.slam.process_image_rgbd(rgb, depth, self.cur_time)\n",
    "            if self.timing:\n",
    "                print(time.time() - t, \"ORB_SLAM2\")\n",
    "            self.tracking_is_OK = str(self.slam.get_tracking_state()) == \"OK\"\n",
    "        except BaseException:\n",
    "            print(\"Warning!!!! ORBSLAM processing frame error\")\n",
    "            self.tracking_is_OK = False\n",
    "        if not self.tracking_is_OK:\n",
    "            self.reset()\n",
    "        t = time.time()\n",
    "        self.set_offset_to_goal(habitat_observation)\n",
    "        if self.tracking_is_OK:\n",
    "            trajectory_history = np.array(self.slam.get_trajectory_points())\n",
    "            self.pose6D = homogenize_p(\n",
    "                torch.from_numpy(trajectory_history[-1])[1:]\n",
    "                .view(3, 4)\n",
    "                .to(self.device)\n",
    "            ).view(1, 4, 4)\n",
    "            self.trajectory_history = trajectory_history\n",
    "            if len(self.position_history) > 1:\n",
    "                previous_step = get_distance(\n",
    "                    self.pose6D.view(4, 4),\n",
    "                    torch.from_numpy(self.position_history[-1])\n",
    "                    .view(4, 4)\n",
    "                    .to(self.device),\n",
    "                )\n",
    "                if self.action_history[-1] == HabitatSimActions.MOVE_FORWARD:\n",
    "                    self.unseen_obstacle = (\n",
    "                        previous_step.item() <= 0.001\n",
    "                    )  # hardcoded threshold for not moving\n",
    "        current_obstacles = self.mapper(\n",
    "            torch.from_numpy(depth).to(self.device).squeeze(), self.pose6D\n",
    "        ).to(self.device)\n",
    "        self.current_obstacles = current_obstacles\n",
    "        self.map2DObstacles = torch.max(\n",
    "            self.map2DObstacles, current_obstacles.unsqueeze(0).unsqueeze(0)\n",
    "        )\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \"Mapping\")\n",
    "        return True\n",
    "\n",
    "    def init_pose6d(self):\n",
    "        return torch.eye(4).float().to(self.device)\n",
    "\n",
    "    def map_size_in_cells(self):\n",
    "        return int(self.map_size_meters / self.map_cell_size)\n",
    "\n",
    "    def init_map2d(self):\n",
    "        return (\n",
    "            torch.zeros(\n",
    "                1, 1, self.map_size_in_cells(), self.map_size_in_cells()\n",
    "            )\n",
    "            .float()\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "    def get_orientation_on_map(self):\n",
    "        self.pose6D = self.pose6D.view(1, 4, 4)\n",
    "        return torch.tensor(\n",
    "            [\n",
    "                [self.pose6D[0, 0, 0], self.pose6D[0, 0, 2]],\n",
    "                [self.pose6D[0, 2, 0], self.pose6D[0, 2, 2]],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def get_position_on_map(self, do_floor=True):\n",
    "        return project_tps_into_worldmap(\n",
    "            self.pose6D.view(1, 4, 4),\n",
    "            self.map_cell_size,\n",
    "            self.map_size_meters,\n",
    "            do_floor,\n",
    "        )\n",
    "\n",
    "    def act(self, habitat_observation, random_prob=0.1):\n",
    "        # Update internal state\n",
    "        t = time.time()\n",
    "        cc = 0\n",
    "        update_is_ok = self.update_internal_state(habitat_observation)\n",
    "        while not update_is_ok:\n",
    "            update_is_ok = self.update_internal_state(habitat_observation)\n",
    "            cc += 1\n",
    "            if cc > 2:\n",
    "                break\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \" s, update internal state\")\n",
    "        self.position_history.append(\n",
    "            self.pose6D.detach().cpu().numpy().reshape(1, 4, 4)\n",
    "        )\n",
    "        success = self.is_goal_reached()\n",
    "        if success:\n",
    "            action = HabitatSimActions.STOP\n",
    "            self.action_history.append(action)\n",
    "            return {\"action\": action}\n",
    "        # Plan action\n",
    "        t = time.time()\n",
    "        self.planned2Dpath, self.planned_waypoints = self.plan_path()\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \" s, Planning\")\n",
    "        t = time.time()\n",
    "        # Act\n",
    "        if self.waypointPose6D is None:\n",
    "            self.waypointPose6D = self.get_valid_waypoint_pose6d()\n",
    "        if (\n",
    "            self.is_waypoint_reached(self.waypointPose6D)\n",
    "            or not self.tracking_is_OK\n",
    "        ):\n",
    "            self.waypointPose6D = self.get_valid_waypoint_pose6d()\n",
    "            self.waypoint_id += 1\n",
    "        action = self.decide_what_to_do()\n",
    "        # May be random?\n",
    "        random_action = random.randint(0, self.num_actions - 1)\n",
    "        what_to_do = np.random.uniform(0, 1, 1)\n",
    "        if what_to_do < random_prob:\n",
    "            action = random_action\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \" s, get action\")\n",
    "        self.action_history.append(action)\n",
    "        return {\"action\": action}\n",
    "\n",
    "    def is_waypoint_good(self, pose6d):\n",
    "        p_init = self.pose6D.squeeze()\n",
    "        dist_diff = get_distance(p_init, pose6d)\n",
    "        valid = dist_diff > self.next_wp_th\n",
    "        return valid.item()\n",
    "\n",
    "    def is_waypoint_reached(self, pose6d):\n",
    "        p_init = self.pose6D.squeeze()\n",
    "        dist_diff = get_distance(p_init, pose6d)\n",
    "        reached = dist_diff <= self.pos_th\n",
    "        return reached.item()\n",
    "\n",
    "    def get_waypoint_dist_dir(self):\n",
    "        angle = get_direction(\n",
    "            self.pose6D.squeeze(), self.waypointPose6D.squeeze(), 0, 0\n",
    "        )\n",
    "        dist = get_distance(\n",
    "            self.pose6D.squeeze(), self.waypointPose6D.squeeze()\n",
    "        )\n",
    "        return torch.cat(\n",
    "            [\n",
    "                dist.view(1, 1),\n",
    "                torch.sin(angle).view(1, 1),\n",
    "                torch.cos(angle).view(1, 1),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "    def get_valid_waypoint_pose6d(self):\n",
    "        p_next = self.planned_waypoints[0]\n",
    "        while not self.is_waypoint_good(p_next):\n",
    "            if len(self.planned_waypoints) > 1:\n",
    "                self.planned_waypoints = self.planned_waypoints[1:]\n",
    "                p_next = self.planned_waypoints[0]\n",
    "            else:\n",
    "                p_next = self.estimatedGoalPos6D.squeeze()\n",
    "                break\n",
    "        return p_next\n",
    "\n",
    "    def set_offset_to_goal(self, observation):\n",
    "        self.offset_to_goal = (\n",
    "            torch.from_numpy(observation[GOAL_SENSOR_UUID])\n",
    "            .float()\n",
    "            .to(self.device)\n",
    "        )\n",
    "        self.estimatedGoalPos2D = habitat_goalpos_to_mapgoal_pos(\n",
    "            self.offset_to_goal,\n",
    "            self.pose6D.squeeze(),\n",
    "            self.map_cell_size,\n",
    "            self.map_size_meters,\n",
    "        )\n",
    "        self.estimatedGoalPos6D = planned_path2tps(\n",
    "            [self.estimatedGoalPos2D],\n",
    "            self.map_cell_size,\n",
    "            self.map_size_meters,\n",
    "            1.0,\n",
    "        ).to(self.device)[0]\n",
    "        return\n",
    "\n",
    "    def rgb_d_from_observation(self, habitat_observation):\n",
    "        rgb = habitat_observation[\"rgb\"]\n",
    "        depth = None\n",
    "        if \"depth\" in habitat_observation:\n",
    "            depth = self.depth_denorm * habitat_observation[\"depth\"]\n",
    "        return rgb, depth\n",
    "\n",
    "    def prev_plan_is_not_valid(self):\n",
    "        if len(self.planned2Dpath) == 0:\n",
    "            return True\n",
    "        pp = torch.cat(self.planned2Dpath).detach().cpu().view(-1, 2)\n",
    "        binary_map = self.map2DObstacles.squeeze().detach() >= self.obstacle_th\n",
    "        obstacles_on_path = (\n",
    "            binary_map[pp[:, 0].long(), pp[:, 1].long()]\n",
    "        ).long().sum().item() > 0\n",
    "        return obstacles_on_path  # obstacles_nearby or  obstacles_on_path\n",
    "\n",
    "    def rawmap2_planner_ready(self, rawmap, start_map, goal_map):\n",
    "        map1 = (rawmap / float(self.obstacle_th)) ** 2\n",
    "        map1 = (\n",
    "            torch.clamp(map1, min=0, max=1.0)\n",
    "            - start_map\n",
    "            - F.max_pool2d(goal_map, 3, stride=1, padding=1)\n",
    "        )\n",
    "        return torch.relu(map1)\n",
    "\n",
    "    def plan_path(self, overwrite=False):\n",
    "        t = time.time()\n",
    "        if (\n",
    "            (not self.prev_plan_is_not_valid())\n",
    "            and (not overwrite)\n",
    "            and (len(self.planned_waypoints) > 0)\n",
    "        ):\n",
    "            return self.planned2Dpath, self.planned_waypoints\n",
    "        self.waypointPose6D = None\n",
    "        current_pos = self.get_position_on_map()\n",
    "        start_map = torch.zeros_like(self.map2DObstacles).to(self.device)\n",
    "        start_map[\n",
    "            0, 0, current_pos[0, 0].long(), current_pos[0, 1].long()\n",
    "        ] = 1.0\n",
    "        goal_map = torch.zeros_like(self.map2DObstacles).to(self.device)\n",
    "        goal_map[\n",
    "            0,\n",
    "            0,\n",
    "            self.estimatedGoalPos2D[0, 0].long(),\n",
    "            self.estimatedGoalPos2D[0, 1].long(),\n",
    "        ] = 1.0\n",
    "        path, cost = self.planner(\n",
    "            self.rawmap2_planner_ready(\n",
    "                self.map2DObstacles, start_map, goal_map\n",
    "            ).to(self.device),\n",
    "            self.coordinatesGrid.to(self.device),\n",
    "            goal_map.to(self.device),\n",
    "            start_map.to(self.device),\n",
    "        )\n",
    "        if len(path) == 0:\n",
    "            return path, []\n",
    "        if self.timing:\n",
    "            print(time.time() - t, \" s, Planning\")\n",
    "        t = time.time()\n",
    "        planned_waypoints = planned_path2tps(\n",
    "            path, self.map_cell_size, self.map_size_meters, 1.0, False\n",
    "        ).to(self.device)\n",
    "        return path, planned_waypoints\n",
    "\n",
    "    def planner_prediction_to_command(self, p_next):\n",
    "        command = HabitatSimActions.STOP\n",
    "        p_init = self.pose6D.squeeze()\n",
    "        d_angle_rot_th = self.angle_th\n",
    "        pos_th = self.pos_th\n",
    "        if get_distance(p_init, p_next) <= pos_th:\n",
    "            return command\n",
    "        d_angle = angle_to_pi_2_minus_pi_2(\n",
    "            get_direction(p_init, p_next, ang_th=d_angle_rot_th, pos_th=pos_th)\n",
    "        )\n",
    "        if abs(d_angle) < d_angle_rot_th:\n",
    "            command = HabitatSimActions.MOVE_FORWARD\n",
    "        else:\n",
    "            if (d_angle > 0) and (d_angle < pi):\n",
    "                command = HabitatSimActions.TURN_LEFT\n",
    "            elif d_angle > pi:\n",
    "                command = HabitatSimActions.TURN_RIGHT\n",
    "            elif (d_angle < 0) and (d_angle > -pi):\n",
    "                command = HabitatSimActions.TURN_RIGHT\n",
    "            else:\n",
    "                command = HabitatSimActions.TURN_LEFT\n",
    "        return command\n",
    "\n",
    "    def decide_what_to_do(self):\n",
    "        action = None\n",
    "        if self.is_goal_reached():\n",
    "            action = HabitatSimActions.TURN_RIGHT\n",
    "            return {\"action\": action}\n",
    "        if self.unseen_obstacle:\n",
    "            command = HabitatSimActions.TURN_RIGHT\n",
    "            return command\n",
    "        command = HabitatSimActions.TURN_RIGHT\n",
    "        command = self.planner_prediction_to_command(self.waypointPose6D)\n",
    "        return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRLEnv(habitat.RLEnv):\n",
    "    def get_reward_range(self):\n",
    "        return [-1, 1]\n",
    "\n",
    "    def get_reward(self, observations):\n",
    "        return 0\n",
    "\n",
    "    def get_done(self, observations):\n",
    "        return self.habitat_env.episode_over\n",
    "\n",
    "    def get_info(self, observations):\n",
    "        return self.habitat_env.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_top_down_map(info, heading, output_size):\n",
    "    top_down_map = maps.colorize_topdown_map(\n",
    "        info[\"top_down_map\"][\"map\"], info[\"top_down_map\"][\"fog_of_war_mask\"]\n",
    "    )\n",
    "    original_map_size = top_down_map.shape[:2]\n",
    "    map_scale = np.array(\n",
    "        (1, original_map_size[1] * 1.0 / original_map_size[0])\n",
    "    )\n",
    "    new_map_size = np.round(output_size * map_scale).astype(np.int32)\n",
    "    # OpenCV expects w, h but map size is in h, w\n",
    "    top_down_map = cv2.resize(top_down_map, (new_map_size[1], new_map_size[0]))\n",
    "\n",
    "    map_agent_pos = info[\"top_down_map\"][\"agent_map_coord\"]\n",
    "    map_agent_pos = np.round(\n",
    "        map_agent_pos * new_map_size / original_map_size\n",
    "    ).astype(np.int32)\n",
    "    top_down_map = maps.draw_agent(\n",
    "        top_down_map,\n",
    "        map_agent_pos,\n",
    "        heading - np.pi / 2,\n",
    "        agent_radius_px=top_down_map.shape[0] / 40,\n",
    "    )\n",
    "    return top_down_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--agent-type\",\n",
    "    default=\"orbslam2-rgbd\",\n",
    "    choices=[\"blind\", \"orbslam2-rgbd\", \"orbslam2-rgb-monod\"],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--task-config\", type=str, default=\"/habitat-api/configs/tasks/pointnav_rgbd.yaml\"\n",
    ")\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "agent_config = cfg_baseline()\n",
    "config.defrost()\n",
    "agent_config.defrost()\n",
    "config.SIMULATOR.SCENE = 'data/scene_datasets/gibson/Aldrich.glb'\n",
    "config.ORBSLAM2 = agent_config.ORBSLAM2\n",
    "config.NUM_ACTIONS = 4\n",
    "config.DIST_TO_STOP = 0.5\n",
    "for i in list(agent_config.ORBSLAM2.keys()):\n",
    "    config[i] = agent_config['ORBSLAM2'][i]\n",
    "config.SLAM_VOCAB_PATH = '/root/3rdparty/ORB_SLAM2/Vocabulary/ORBvoc.txt'\n",
    "config.SLAM_SETTINGS_PATH = '/habitat-api/habitat_baselines/slambased/data/mp3d3_small1k.yaml'\n",
    "\n",
    "make_good_config_for_orbslam2(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ORBSLAM2Agent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-28 09:50:43,407 Initializing dataset PointNav-v1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'habitat-challenge-data/pointgoal_gibson.val_mini.json.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-495ba4a4ba02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconfig_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIMULATOR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCENE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/scene_datasets/gibson/Aldrich.glb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mconfig_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleRLEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/habitat-api/habitat/core/env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, dataset)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \"\"\"\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/habitat-api/habitat/core/env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, dataset)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             self._dataset = make_dataset(\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mid_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             )\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/habitat-api/habitat/datasets/registration.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(id_dataset, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0m_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Could not find dataset {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/habitat-api/habitat/datasets/pointnav/pointnav_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdatasetfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPLIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenes_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCENES_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'habitat-challenge-data/pointgoal_gibson.val_mini.json.gz'"
     ]
    }
   ],
   "source": [
    "#config_task = get_config(\"/habitat-api/configs/tasks/pointnav_rgbd.yaml\")\n",
    "config_task = get_config('challenge_pointnav2020.local.rgbd.yaml')\n",
    "config_task.defrost()\n",
    "config_task.TASK.MEASUREMENTS.append(\"TOP_DOWN_MAP\")\n",
    "config_task.TASK.SENSORS.append(\"HEADING_SENSOR\")\n",
    "config_task.TASK.SENSORS.append(\"POINTGOAL_WITH_GPS_COMPASS_SENSOR\")\n",
    "config_task.SIMULATOR.SCENE = 'data/scene_datasets/gibson/Aldrich.glb'\n",
    "config_task.freeze()\n",
    "env = SimpleRLEnv(config_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from habitat.utils.visualizations import maps\n",
    "def plott(observation,info,env,agent,ii):\n",
    "    f = plt.figure(figsize=(10,10))\n",
    "    ax = f.add_subplot(131)\n",
    "    ax2 = f.add_subplot(132)\n",
    "    ax3 = f.add_subplot(133)\n",
    "    ax.set_aspect('equal')\n",
    "    ax2.set_aspect('equal')\n",
    "    ax3.set_aspect('equal')\n",
    "\n",
    "    path_map = torch.zeros_like(agent.map2DObstacles[0][0])\n",
    "    mapp = torch.zeros((400,400,3)).cuda()\n",
    "    \n",
    "    current_pose = agent.get_position_on_map()\n",
    "    path, planned_path = agent.plan_path()\n",
    "    print(len(path))\n",
    "    for ip in path:\n",
    "        path_map[ip[0].long(),ip[1].long()] = torch.max(agent.map2DObstacles[0][0][:])\n",
    "    \n",
    "    mapp[:,:,1] += path_map\n",
    "    mapp[:,:,0] += agent.map2DObstacles[0][0]\n",
    "    mapp = mapp.permute(1,0,2)\n",
    "    shift = 100\n",
    "    shiftto = 300\n",
    "    if torch.nonzero(mapp).size()[0]>1:\n",
    "        shift = min(torch.nonzero(mapp)[:,:2].reshape(1,-1)[0])\n",
    "        shiftto = max(torch.nonzero(mapp)[:,:2].reshape(1,-1)[0])  \n",
    "        shift = max(0,shift-10)\n",
    "        shiftto = min(400,shiftto+10)\n",
    "    ax.imshow(mapp[:].cpu().numpy()[shift:shiftto,shift:shiftto,:]);\n",
    "    circ1 = Circle((agent.estimatedGoalPos2D[0,0].long()-shift,agent.estimatedGoalPos2D[0,1].long()-shift),3,color='yellow')\n",
    "    circ2 = Circle((current_pose[0,0].long()-shift,current_pose[0,1].long()-shift),3,color='white')\n",
    "    top_down_map = draw_top_down_map(info, observation[\"heading\"][0], observation[\"rgb\"].shape[0])\n",
    "    ax.add_patch(circ1)\n",
    "    ax.add_patch(circ2)\n",
    "    ax2.imshow(observation['depth'][:,:,0])\n",
    "    ax.set_title('Distance_to_goal '+str(info['distance_to_goal']))\n",
    "    ax2.set_title('Spl  '+str(info['spl']))\n",
    "    ax3.imshow(top_down_map)\n",
    "    #gray = cv2.normalize(observation['depth'][:,:,0], None, 255, 0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    #gray_3c = cv2.merge([gray, gray, gray])\n",
    "    folder = 'image_slam'\n",
    "    f.savefig(folder+\"/file%02d.png\" % ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./image_slam\n",
    "!mkdir ./image_slam\n",
    "agent.reset()\n",
    "observation = env.reset()\n",
    "done = False\n",
    "info = {}\n",
    "info['distance_to_goal'] = 0\n",
    "dones = []\n",
    "actions = []\n",
    "ii = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not done:\n",
    "    action = agent.act(observation)\n",
    "    print(action['action'])\n",
    "    if action['action']==0 and info['distance_to_goal']>0.3:\n",
    "        action['action']=3\n",
    "    # if env.get_metrics()['distance_to_goal']>0.02:\n",
    "    #     action['action']=3    \n",
    "    actions.append(action['action'])\n",
    "    dones.append(done)\n",
    "    if not done:\n",
    "        observation, reward, done, info = env.step(action['action'])\n",
    "    else:\n",
    "        print('EPISODE IS OVER')\n",
    "    ii+=1\n",
    "    plott(observation,info,env,agent,ii);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "!rm video_name.mp4\n",
    "os.chdir('/root/image_slam')\n",
    "subprocess.call([\n",
    "        'ffmpeg', '-framerate', '8', '-i', 'file%02d.png', '-r', '30', '-pix_fmt', 'yuv420p',\n",
    "        '../video_name.mp4'\n",
    "    ])\n",
    "os.chdir('/root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = agent.act(observation)\n",
    "print(action['action'])\n",
    "if action['action']==0 and env.get_metrics()['distance_to_goal']>0.2:\n",
    "    action['action']=3\n",
    "#if action['action']!=5:\n",
    "#    action['action']=3\n",
    "actions.append(action['action'])\n",
    "dones.append(env._episode_over)\n",
    "observation = env.step(action)\n",
    "print(actions[-2:],'\\t',dones[-2:])\n",
    "print(agent.get_position_on_map())\n",
    "print(env.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 100\n",
    "current_pose = agent.get_position_on_map()\n",
    "start_map = torch.zeros_like(agent.map2DObstacles[0][0])\n",
    "start_map[current_pose[0,0].long(),current_pose[0,1].long()] = torch.max(agent.map2DObstacles[0][0][:])\n",
    "path, planned_path = agent.plan_path()\n",
    "path_map = torch.zeros_like(agent.map2DObstacles[0][0])\n",
    "for i in path:\n",
    "    path_map[i[0].long(),i[1].long()] = torch.max(agent.map2DObstacles[0][0][:])\n",
    "mapp = torch.zeros((400,400,3)).cuda()\n",
    "mapp[:,:,1] += path_map\n",
    "mapp[:,:,0] += agent.map2DObstacles[0][0]\n",
    "f = plt.figure(figsize=(10,10))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "ax.set_aspect('equal')\n",
    "ax2.set_aspect('equal')\n",
    "ax.imshow(mapp[:].cpu().numpy()[shift:,shift:,:]);\n",
    "circ1 = Circle((agent.estimatedGoalPos2D[0,0].long()-shift,agent.estimatedGoalPos2D[0,1].long()-shift),3,color='yellow')\n",
    "circ2 = Circle((current_pose[0,0].long()-shift,current_pose[0,1].long()-shift),3,color='white')\n",
    "ax.add_patch(circ1)\n",
    "ax.add_patch(circ2)\n",
    "ax2.imshow(observation['depth'][:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(agent.map2DObstacles[0][0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
