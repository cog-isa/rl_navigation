<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic - Hyperspace by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<style>
		div.container {
		  display:inline-block;
		  margin-left: auto;
    	  margin-right: auto;
		  height: 400px; 
		  width: 600px; 
		  text-align:center;
		}

		div.container2 {
		  display:inline-block;
		  margin-left: auto;
    	  margin-right: auto;
		  height: 400px; 
		  width: 400px; 
		  text-align:center;
		}

		div.container3 {
		  display:inline-block;
		  margin-left: auto;
    	  margin-right: auto;
		  height: 400px; 
		  width: 1200px; 
		  text-align:center;
		}
	
		p {
		  text-align:left;
		}
	  </style>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">Existing approaches</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="generic.html" class="active">Overview</a></li>
					</ul>
				</nav>
			</header>
			

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">Vlocnet Architecture</h1>

								<div class="container3">
								<a href="#" class="image"><img src="images/vlocnet.png" alt="" data-position="top center" width="1000" height="500"/></a>
								<figcaption>Fig.3 - Vlocnet loss.</figcaption>
								</div>

							<h1 class="major">Visual Odometry (DF-VO)</h1>

								<div class="container2">
								<a href="#" class="image"><img src="images/dfvo1.png" alt="11" data-position="top left" width="300" height="300"/></a>
								<figcaption>Fig.1 - DF-VO localization module.</figcaption>
								</div>
								<div class="container2">
								<a href="#" class="image"><img src="images/dfvo2.png" alt="" data-position="top center" width="300" height="300"/></a>
								<figcaption>Fig.2 - DF-VO localization module.</figcaption>
								</div>
								<div class="container2">
								<a href="#" class="image"><img src="images/dfvo3.png" alt="" data-position="top right" width="300" height="300"/></a>
								<figcaption>Fig.3 - DF-VO localization module.</figcaption>
								</div>
								<br />

								<div class="container">
								<a href="#" class="image"><img src="images/dfvo_rtabmap1.png" alt="11" data-position="top left" width="500" height="200"/></a>
								<figcaption>Fig.4 - DF-VO vs RTAB-MAP.</figcaption>
								</div>
								<div class="container">
								<a href="#" class="image"><img src="images/dfvo_rtabmap2.png" alt="" data-position="top right" width="500" height="200"/></a>
								<figcaption>Fig.5 - DF-VO vs RTAB-MAP.</figcaption>
								</div>	

							<h1 class="major">Super-SloMo</h1>

								<div class="container">
								<a href="#" class="image"><img src="images/slomo1x1.gif" alt="11" data-position="top left" width="500" height="300"/></a>
								<figcaption>Fig.4 - Original video.</figcaption>
								</div>
								<div class="container">
								<a href="#" class="image"><img src="images/slomo10x1.gif" alt="" data-position="top right" width="500" height="300"/></a>
								<figcaption>Fig.5 - 10x Super-SloMo video.</figcaption>
								</div>	
								<br />

								<div class="container2">
								<a href="#" class="image"><img src="images/!10_0.25_Noise_0.01_0.05.png" alt="11" data-position="top left" width="300" height="300"/></a>
								<figcaption>Fig.1 - RTAB-MAP localization module with original video.</figcaption>
								</div>
								<div class="container2">
								<a href="#" class="image"><img src="images/!10_0.25_Noise_0.01_0.05(1).png" alt="" data-position="top center" width="300" height="300"/></a>
								<figcaption>Fig.2 - RTAB-MAP localization module with original video.</figcaption>
								</div>
								<div class="container2">
								<a href="#" class="image"><img src="images/!10_0.25_Noise_0.01_0.05(2).png" alt="" data-position="top right" width="300" height="300"/></a>
								<figcaption>Fig.3 - RTAB-MAP localization module with original video.</figcaption>
								</div>
								<br />

								<div class="container2">
								<a href="#" class="image"><img src="images/!10_0.25_Noise_0.01_0.05_SLOMO10.png" alt="11" data-position="top left" width="300" height="300"/></a>
								<figcaption>Fig.1 - RTAB-MAP localization module with 10x Super-SloMo video.</figcaption>
								</div>
								<div class="container2">
								<a href="#" class="image"><img src="images/!10_0.25_Noise_0.01_0.05_SLOMO10(1).png" alt="" data-position="top center" width="300" height="300"/></a>
								<figcaption>Fig.2 - RTAB-MAP localization module with 10x Super-SloMo video.</figcaption>
								</div>
								<div class="container2">
								<a href="#" class="image"><img src="images/!10_0.25_Noise_0.01_0.05_SLOMO10(2).png" alt="" data-position="top right" width="300" height="300"/></a>
								<figcaption>Fig.3 - RTAB-MAP localization module with 10x Super-SloMo video.</figcaption>
								</div>

							<h1 class="major">Mask R-CNN</h1>
							
							<p>To solve the search for a specific object in the room, it is necessary to distinguish between objects in the image, this can be solved through the instance 
								segmentation task. As the base agent, we also took ANM. The idea of ANM is very suitable for solving our problem. After all, the agent here is trained for the 
								greatest possible study of the area around him. To modernize the algorithm, we decided to add another layer for the map in the mapper. The new layer will contain 
								in each cell the probability of finding in it the object that the agent needs to find.</p><br />

							<div class="container3">
							<a href="#" class="image"><img src="images/semanticmap.png" alt="" data-position="top center" width="300" height="300"/></a>
							<figcaption>Fig.3 - DF-VO localization module.</figcaption>
							</div>

							<p>A new sensor for the agent has been added to make changes. This sensor receives an RGB image at the input, then passes it through a pre-trained mask R-CNN network 
								and receives a segmented mask of all objects in the image at the output. Further, the algorithm selects in the picture only segments of those objects that need to 
								be found in the task. After that, the algorithm replaces the values of the desired objects with the corresponding values from the depth map and replaces all the 
								values of the remaining objects with NaN. The sensor returns the matrix to the agent. Next, the output of the new semantic sensor is transmitted to the input of 
								the pre-trained ResNet network. After that, it goes through several convolutional layers and combines with the converted result of processing the RGB image. Further, 
								a map with three layers instead of two, as before, is created from the combined attribute tensor using several Up Sample layers. To train the mapper network and 
								compile a ground truth map, we took a cropped depth map from a semantic sensor and projected the data onto an ideal top-down map using the same algorithms that are 
								used in the article to generate a ground truth map for a layer with an obstacle map. In Global Policy, the changes affected the dimensions of convolutional layers 
								for processing the third channel of the map as well. In the glider, changes affected only the input layers so that it could process the map with a new dimension.</p>







						</div>
					</section>

			</div>

		<!-- Footer -->
		<footer id="footer" class="wrapper alt">
			<div class="inner">
				<ul class="menu">
					<li>&copy; All rights reserved.</li><li>Design: <a href="http://rairi.ru/structure/71-ids.html">Intelligent dynamical systems and cognitive research center</a></li>
				</ul>
			</div>
		</footer>

	<!-- Scripts -->
		<script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		</script>
		<script type="text/javascript"
		src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrollex.min.js"></script>
		<script src="assets/js/jquery.scrolly.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>

</body>
</html>