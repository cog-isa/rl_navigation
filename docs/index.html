<!DOCTYPE HTML>
<!--
	Story by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Learning embodied agents</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<style>
		div.container {
		  display:inline-block;
		  margin-left: auto;
    	  margin-right: auto;
		  height: 400; 
		  width: 400; 
		  text-align:center;
		}
		div.container1 {
		  display:inline-block;
		  margin-left: auto;
    	  margin-right: auto;
		  height: 200px; 
		  width: 200px; 
		  text-align:center;
		}
		div.container2 {
		  display:inline-block;
		  margin-left: auto;
    	  margin-right: auto;
		  height: 400px; 
		  width: 800px; 
		  text-align:center;
		}
		div.container3 {
		  display:inline-block;
		  margin-left: auto;
    	  margin-right: auto;
		  height: 300; 
		  width: 760; 
		  text-align:center;
		}
		p {
		  text-align:left;
		}
	  </style>

	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="divided">

				<!-- One -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<br/>
							<h1>Learning embodied agents with policy gradients to navigate in realistic environments</h1>
							<div class="major"><h3><br/><br/>Indoor navigation is one of the main tasks in robotic systems. Most decisions in this area rely on ideal 
								agent coordinates and a pre-known room map. However, the high accuracy of indoor localization cannot be achieved in 
								realistic scenarios. For example, the GPS has low accuracy in the room; odometry often gives much noise for accurate 
								positioning, etc. In this paper, we conducted a study of the navigation problem in the realistic Habitat simulator. 
								We proposed a method based on the neural network approach and reinforcement learning that takes into account these factors. 
								The most promising recent approaches were DDPPO and ANM for agent control and DF-VO for localization, during the analysis 
								of which a new approach was developed. This method takes into account the non-determinism of the robot's actions and the 
								noise level of data from its sensors.</h3></p>

							<br/>
								<div class="container1">
								<!--<img class="rounded" src="images/alstar.jpg"alt="" data-position="top right"/>-->
								<figcaption>Aleksei Staroverov <br />MIPT</figcaption>
								</div>
								<div class="container1">
								<!--<img class="rounded" src="images/alstar.jpg"alt="" data-position="top right"/>-->
								<figcaption>Vladislav Vetlin <br />HSE</figcaption>
								</div>
								<div class="container1">
								<!--<img class="rounded" src="images/alstar.jpg"alt="" data-position="top right"/>-->
								<figcaption>Stepan Makarenko <br />MIPT</figcaption>
								</div>
								<div class="container1">
								<!--<img class="rounded" src="images/alstar.jpg"alt="" data-position="top right"/>-->
								<figcaption>Anton Naumov <br />HSE</figcaption>
								</div>
								<div class="container1">
								<!--<img class="rounded" src="images/alstar.jpg"alt="" data-position="top right"/>-->
								<figcaption>Aleksandr I. Panov <br />MIPT</figcaption>
								</div>
								

							<!-- Buttons -->
							<section>
								<header>
									<h3>References</h3>
								</header>
								<div class="content">
									<ul class="actions fit">
										<li><a href=""class="button primary fit">Paper</a></li>
										<li><a href="https://github.com/cog-isa/rl_navigation" class="button primary fit">Code</a></li>
									</ul>	

								</div>
							</section>
						</div>
	
					</section>

				<!-- Six -->
				<section class="wrapper style1 align-center">
					<div class="inner">

						<h2>Task formulation</h2>
						<div class="container">
							<img src="images/ezgif.com-resize.gif" alt="" data-position="top center" width="400" height="400" />
						</div>

								<div class="content">
									<p>	The navigating task to the given coordinates initializes the agent at a random place on the map. The goal is the 
										target coordinates, which are set as ("Go 5 m to the north, 3 m to the west relative to the beginning"). The room 
										map is not available to the agent, and during the evaluation process, the agent can only use the input from the 
										RGB-D camera for navigation.
										<br/>
										The agent had four actions: forward, turn left, turn right, and stop. Evaluation occurs when the agent selects 
										the 'STOP' action. As a metric, SPL (Success weighted by Path Length) is used. The episode is 
										considered successful if, when calling 'STOP,' the agent is within 0.36 m (2x radius of the agent) from the 
										coordinates of the target.</p>
								</div>

						</div>
				</section>	

				
				<!-- Six -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Results</h2>
					


						<p>As the overall approach, we used DF-VO as a localization module and trained DDPPO with its coordinates. This approach gave 
							us SPL around 0.32 in normal condtions and 0.16 in noisy conditions. We evaluated these results at ten different maps and took the average. The 
							first experiment (zero pos) is to pass zero coordinates to DDPPO, the second experiment (ground truth pos) is to pass ideal 
							coordinates from the environment to the DDPPO. For the RTAB-MAP, turn angle was reduced from 10 degrees to 5, since RTAB-MAP 
							cannot track position with such a big difference between frames. With the presence of sensor noise, RTAB-MAP also fails, and 
							output zero position at every step, but in good conditions outperform DF-VO by far. The main reason why both RTAB-MAP and 
							DF-VO performance significantly worst than ground truth coordinates, it is hard to determine the final stopping place. 
							Especially if the goal is near the wall, an agent could reconstruct the goal coordinates on the other side of the wall due 
							to the localization error.<p>
						

						<div class="container">
							<img src="images/! 0_.png" alt="" data-position="top center" width="760" height="300" />
						</div>	
						
						<h3>Example of DDPPO agent trajectory with ground truth pos. Left trajectory with action and sensors noise, right without. 
							The green path is the ideal path with SPL=1; the blue path is a real agent path.</h3>
							
							<div class="items style1 medium onscroll-fade-in">
								<section>
									<a href="images/0_nonoise_new.png" class="image">
										<img src="images/0_nonoise_new.png" alt="" />
									</a>
								</section>
								<section>
									<a href="images/1_nonoise_new.png" class="image">
										<img src="images/1_nonoise_new.png" alt="" />
									</a></section>
								<section>
									<a href="images/2_nonoise_new.png" class="image">
										<img src="images/2_nonoise_new.png" alt="" />
									</a></section>
								<section>
									<a href="images/3_nonoise_new.png" class="image">
										<img src="images/3_nonoise_new.png" alt="" />
									</a></section>
								<section>
									<a href="images/4_nonoise_new.png" class="image">
										<img src="images/4_nonoise_new.png" alt="" />
									</a></section>
								<section>
									<a href="images/5_nonoise_new.png" class="image">
										<img src="images/5_nonoise_new.png" alt="" />
									</a></section>
								<section>
									<a href="images/6_nonoise_new.png" class="image">
										<img src="images/6_nonoise_new.png" alt="" />
									</a></section>
								<section>
									<a href="images/7_nonoise_new.png" class="image">
										<img src="images/7_nonoise_new.png" alt="" />
									</a></section>
								<section>
									<a href="images/8_nonoise_new.png" class="image">
										<img src="images/8_nonoise_new.png" alt="" />
									</a></section>
					
							</div>

	

							<h3>The DDPPO agents trajectories with zero pos. 
								The green path is the ideal path with SPL=1; the blue path is a real agent path.</h3>
							
							<div class="items style1 medium onscroll-fade-in">
								<section>
				
									<a href="images/_0_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_0_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
								<section>
					
									<a href="images/_1_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_1_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
								<section>
								
									<a href="images/_2_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_2_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
								<section>
							
									<a href="images/_3_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_3_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
								<section>
								
									<a href="images/_4_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_4_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
								<section>
							
									<a href="images/_5_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_5_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
								<section>
									
									<a href="images/_6_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_6_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
								<section>
								
									<a href="images/_7_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_7_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
								<section>
								
									<a href="images/_8_dfvo_ddppo_nonoise.png" class="image">
										<img src="images/_8_dfvo_ddppo_nonoise.png" alt="" />
									</a></section>
					
							</div>

							<h3>DDPPO results with DF-VO pos. The blue line is the ground truth trajectory. 
								The red line is the DF-VO trajectory that passed to the DDPPO.</h3>
							
							<div class="items style1 medium onscroll-fade-in">
								<section>
								
									<a href="images/ddppo_rtabmap_0.png" class="image">
										<img src="images/ddppo_rtabmap_0.png" alt="" />
									</a></section>
								<section>
									
									<a href="images/ddppo_rtabmap_1.png" class="image">
										<img src="images/ddppo_rtabmap_1.png" alt="" />
									</a></section>
								<section>
									
									<a href="images/ddppo_rtabmap_2.png" class="image">
										<img src="images/ddppo_rtabmap_2.png" alt="" />
									</a></section>
								<section>
							
									<a href="images/ddppo_rtabmap_3.png" class="image">
										<img src="images/ddppo_rtabmap_3.png" alt="" />
									</a></section>
								<section>
								
									<a href="images/ddppo_rtabmap_4.png" class="image">
										<img src="images/ddppo_rtabmap_4.png" alt="" />
									</a></section>
								<section>
								
									<a href="images/ddppo_rtabmap_5.png" class="image">
										<img src="images/ddppo_rtabmap_5.png" alt="" />
									</a></section>
								<section>
									
									<a href="images/ddppo_rtabmap_6.png" class="image">
										<img src="images/ddppo_rtabmap_6.png" alt="" />
									</a></section>
								<section>
								
									<a href="images/ddppo_rtabmap_7.png" class="image">
										<img src="images/ddppo_rtabmap_7.png" alt="" />
									</a></section>
								<section>
								
									<a href="images/ddppo_rtabmap_8.png" class="image">
										<img src="images/ddppo_rtabmap_8.png" alt="" />
									</a></section>
					
							</div>

							<h3>DDPPO results with RTAB-MAP pos. The red line is the ground truth trajectory. 
								The green line is the RTAB-MAP trajectory that passed to the DDPPO.</h3>
														

						<div class="index align-left">
						<h3>Result table (SPL)</h3>
						<div class="table-wrapper">

							<table>
								<thead>
									<tr>
										<th> </th>
										<th>Zero pos</th>
										<th>Ground truth pos</th>
										<th>RTAB-MAP pos</th>
										<th>DF-VO pos</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td>Action and sensor noise</td>
										<td>0.81</td>
										<td>0.58</td>
										<td>0.90</td>
										<td>0.16</td>
									</tr>
									<tr>
										<td>Sensor noise</td>
										<td>0.10</td>
										<td>0.62</td>
										<td>0.11</td>
										<td>0.20</td>
									</tr>
									<tr>
										<td>Without noise</td>
										<td>0.13</td>
										<td>0.72</td>
										<td>0.40</td>
										<td>0.27</td>
									</tr>
				
								</tbody>

							</table>
						</div>
						</div>

					</div>
				</section>


					<!-- Six -->
				<section class="wrapper style1 align-center">
					<div class="inner">
						<h2>Conclusion</h2>
						<p>Extensive work has been done to study and test modules for the RL agent in the Habitat environment. We trained the bunch of 
							state of the art solutions for navigation and building maps on the premises and developed a solution for the point goal task. 
							Focusing on the article DF-VO and DDPPO, we built a combination of these algorithms for the realistic noise conditions in 
							the new Habitat environment. DF-VO was used to determine the position of the agent, which allowed us not to use ground truth 
							coordinates from the environment, relying only on the RGB-D sensor. DDPPO was used to control the agent, relying on the 
							reconstructed coordinates, and showed an excellent ability to adapt to all noises and imperfections of the environment. 
							In the future, we plan to improve the overall performance and transfer the policy from a simulator to a real-world robot.</p>

						</div>
					</section>		


				<!-- Footer -->
					<footer class="wrapper style1 align-center">
						<div class="inner">
							
							<p>&copy; Learning embodied agents to navigate. Design: <a href="http://rairi.ru/structure/71-ids.html">Intelligent dynamical systems and cognitive research center</a>.</p>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>