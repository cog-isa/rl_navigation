{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /home/data /habitat-api/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /habitat-api /home/habitat-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./configs/default2.py /habitat-api/habitat/config/default.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizer\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/48/49fd393348a4dcb796e901732ebab32d7a37e826fa35b72702eeea2e2f77/tokenizer-2.0.3-py2.py3-none-any.whl (107kB)\n",
      "\u001b[K     |################################| 112kB 896kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: stable-baselines in /opt/conda/envs/habitat/lib/python3.6/site-packages (2.9.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/habitat/lib/python3.6/site-packages (from stable-baselines) (0.25.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/habitat/lib/python3.6/site-packages (from stable-baselines) (0.14.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/habitat/lib/python3.6/site-packages (from stable-baselines) (4.1.2.30)\n",
      "Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from stable-baselines) (0.10.9)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/habitat/lib/python3.6/site-packages (from stable-baselines) (1.18.1)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from stable-baselines) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/habitat/lib/python3.6/site-packages (from stable-baselines) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/habitat/lib/python3.6/site-packages (from stable-baselines) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from pandas->stable-baselines) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from pandas->stable-baselines) (2019.3)\n",
      "Requirement already satisfied: requests>=2.0 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (2.22.0)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (1.4.10)\n",
      "Requirement already satisfied: six in /opt/conda/envs/habitat/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (1.14.0)\n",
      "Requirement already satisfied: PyOpenGL; extra == \"atari\" in /opt/conda/envs/habitat/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (3.1.5)\n",
      "Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /opt/conda/envs/habitat/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (0.2.6)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in /opt/conda/envs/habitat/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (7.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from matplotlib->stable-baselines) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from matplotlib->stable-baselines) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from matplotlib->stable-baselines) (2.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable-baselines) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable-baselines) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable-baselines) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/habitat/lib/python3.6/site-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable-baselines) (3.0.4)\n",
      "Requirement already satisfied: future in /opt/conda/envs/habitat/lib/python3.6/site-packages (from pyglet>=1.2.0->gym[atari,classic_control]>=0.10.9->stable-baselines) (0.18.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/habitat/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines) (44.0.0.post20200106)\n",
      "Installing collected packages: tokenizer\n",
      "Successfully installed tokenizer-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizer stable-baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/envs/habitat/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Unexpected end of /proc/mounts line `overlay / overlay rw,relatime,lowerdir=/var/lib/docker/overlay2/l/MY6DXW44K7ZTBFMCD7YFS3LAEC:/var/lib/docker/overlay2/l/QCAFV65KQYDN2KKBTSQ4F3EI4L:/var/lib/docker/overlay2/l/GTDXNH4NQUUUYONTYOPVQIJ5O7:/var/lib/docker/overlay2/l/PHSRAMM7MOOWBDFXI4AD7LVNZY:/var/lib/docker/overlay2/l/YLKYDPNLPYM7DVIWZVIO4SXGDQ:/var/lib/docker/overlay2/l/PSWXDRFAAA7Z3OQGXDXKKVP744:/var/lib/docker/overlay2/l/DGJ2NIPE247PB7XFDI75MC4KYV:/var/lib/docker/overlay2/l/5SA4ACNGYQGPADKZKJYIX732MH:/var/lib/docker/overlay2/l/QQNA2E27VGM6B'\n",
      "Unexpected end of /proc/mounts line `Q72YKGASHBJMM:/var/lib/docker/overlay2/l/MD6IOF3T5XG5O2OAJH7RTBNOVH:/var/lib/docker/overlay2/l/3CPL2VPIUC5BXZ3QKRRZP5BOK5:/var/lib/docker/overlay2/l/G5EYV3J2UFPEHYU2UOZS4H7TOL:/var/lib/docker/overlay2/l/MLMVTBTTLNNSYCMGQOK77ZSL7F:/var/lib/docker/overlay2/l/5KCL7C46JTHPTM3S7FDSYM2AFB:/var/lib/docker/overlay2/l/KLLLRZEF5TLLXIZJK5L5IJA7YC:/var/lib/docker/overlay2/l/JCRCF42THCQ53QHO6MVE2FFTF3:/var/lib/docker/overlay2/l/KNMCHTONHCYFEEO6E7P4ZTI6PZ:/var/lib/docker/overlay2/l/OH5QXS555UL5SRZFJ5HKZ22DQG:/var/lib/do'\n",
      "Unexpected end of /proc/mounts line `cker/overlay2/l/7LWVBKIKXO4HBUYGCOLTDVZDYD:/var/lib/docker/overlay2/l/3EXU7XPTWV2O3C7RM2Z4DLYHWW:/var/lib/docker/overlay2/l/LRUPM5TMIXNCBRYTNHERIMCYJ4:/var/lib/docker/overlay2/l/QO3FRCRAZG2B2WOVUYGK6EO7UC:/var/lib/docker/overlay2/l/7XSXU4CBNYBS757CY2NZVEZN45:/var/lib/docker/overlay2/l/JZBKT53IML2DTC7Y2D3L7SCLBL:/var/lib/docker/overlay2/l/3GF3W6AMCJKMZEW34IDC2RNEEF:/var/lib/docker/overlay2/l/IP3BQ7QG5ZU7CTVZATUTUIT4NV:/var/lib/docker/overlay2/l/7X7UAVJNWRIW7LFEPDCIHVXQ75:/var/lib/docker/overlay2/l/BR5DHY5OY'\n",
      "Unexpected end of /proc/mounts line `GBL6OY3VSESXDCAZI:/var/lib/docker/overlay2/l/X3CJSZ45VPBV5ZJTTC56EMZCVX:/var/lib/docker/overlay2/l/ESVVWIVW532ZCLLSUNP4HCAM2W:/var/lib/docker/overlay2/l/JIC3Q2GWD5UBOMLUES6LBV75F7:/var/lib/docker/overlay2/l/PMKZ2QCPKUUQ2JGJ637RDTD66I:/var/lib/docker/overlay2/l/BAHQPIE4WQQNTRS6S7WRS53TVK:/var/lib/docker/overlay2/l/WPIGKGJT7FBJEYESUCHC4NM5CO:/var/lib/docker/overlay2/l/XCZ275KR7IHMK2ZE462Q4YBTSS:/var/lib/docker/overlay2/l/OSOD72GKJIHKQAC6KCK37SFH3O:/var/lib/docker/overlay2/l/JZ6AM4NT55XG7LK2AK5BDPARBI:/var/li'\n",
      "Unexpected end of /proc/mounts line `b/docker/overlay2/l/3N24K3UQLHOPC4RBZXRQXN6MZR:/var/lib/docker/overlay2/l/NKVWC7MOXZ2ZLS6IKEAGXB7F5L:/var/lib/docker/overlay2/l/F2CZPGXXNPDMT364YGS44EYBSK:/var/lib/docker/overlay2/l/LILI7LBWCM6Z5LDTM6HBL4OTKI:/var/lib/docker/overlay2/l/KWGCDXPCJAUPVJHIQPDCVWWXH3:/var/lib/docker/overlay2/l/SPM4F5MUVIII7LDIM7C7WC53QM:/var/lib/docker/overlay2/l/YBFOH5SOFXHQ6HEWJ46QEB3QFH:/var/lib/docker/overlay2/l/NSYZTAQVPQTZP4IVSX6WYY2LUN:/var/lib/docker/overlay2/l/IUKDUO6QJIUN5P4JDBA7MJUIQV:/var/lib/docker/overlay2/l/JTVLD'\n",
      "--------------------------------------------------------------------------\n",
      "[[53954,1],0]: A high-performance Open MPI point-to-point messaging module\n",
      "was unable to find any relevant network interfaces:\n",
      "\n",
      "Module: OpenFabrics (openib)\n",
      "  Host: cds2\n",
      "\n",
      "Another transport will be used instead, although this may result in\n",
      "lower performance.\n",
      "--------------------------------------------------------------------------\n",
      "2020-01-27 14:14:49,037 Initializing dataset PointNav-v1\n",
      "2020-01-27 14:17:23,861 initializing sim Sim-v0\n",
      "2020-01-27 14:17:28,690 Initializing task Nav-v0\n",
      "Destination, distance: 3.946293, theta(radians): 2.90\n",
      "No protocol specified\n",
      ": cannot connect to X server :12.0\n"
     ]
    }
   ],
   "source": [
    "! python rl_env_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n",
      "\n",
      "2020-01-26 09:52:20,361 Initializing dataset PointNav-v1\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"rl_env_block_agent.py\", line 91, in <module>\n",
      "    main()\n",
      "  File \"rl_env_block_agent.py\", line 23, in main\n",
      "    env = environments.NavRLEnv(config) #LocalPolicy\n",
      "  File \"/home/MY_FOLDER/environment/environments.py\", line 14, in __init__\n",
      "    super().__init__(config, dataset)\n",
      "  File \"/habitat-api/habitat/core/env.py\", line 300, in __init__\n",
      "    self._env = Env(config, dataset)\n",
      "  File \"/habitat-api/habitat/core/env.py\", line 74, in __init__\n",
      "    id_dataset=config.DATASET.TYPE, config=config.DATASET\n",
      "  File \"/habitat-api/habitat/datasets/registration.py\", line 19, in make_dataset\n",
      "    return _dataset(**kwargs)\n",
      "  File \"/habitat-api/habitat/datasets/pointnav/pointnav_dataset.py\", line 99, in __init__\n",
      "    self.from_json(f.read(), scenes_dir=config.SCENES_DIR)\n",
      "  File \"/habitat-api/habitat/datasets/pointnav/pointnav_dataset.py\", line 120, in from_json\n",
      "    episode.goals[g_index] = NavigationGoal(**goal)\n",
      "  File \"<attrs generated init habitat.tasks.nav.nav.NavigationGoal>\", line 1, in __init__\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! python rl_env_block_agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -r ./com /opt/conda/envs/habitat/lib/python3.6/site-packages/stable_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp  ./com/tf_util.py /opt/conda/envs/habitat/lib/python3.6/site-packages/stable_baselines/common/tf_util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r /opt/conda/envs/habitat/lib/python3.6/site-packages/stable_baselines/common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  acer   common  gail       ppo1\t results_plotter.py  trpo_mpi\r\n",
      "__pycache__  acktr  ddpg    her        ppo2\t sac\r\n",
      "a2c\t     bench  deepq   logger.py  py.typed  td3\r\n"
     ]
    }
   ],
   "source": [
    "! ls /opt/conda/envs/habitat/lib/python3.6/site-packages/stable_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import collections\r\n",
      "import functools\r\n",
      "import multiprocessing\r\n",
      "from typing import Set\r\n",
      "\r\n",
      "import numpy as np\r\n",
      "import tensorflow as tf\r\n",
      "\r\n",
      "\r\n",
      "def is_image(tensor):\r\n",
      "    \"\"\"\r\n",
      "    Check if a tensor has the shape of\r\n",
      "    a valid image for tensorboard logging.\r\n",
      "    Valid image: RGB, RGBD, GrayScale\r\n",
      "\r\n",
      "    :param tensor: (np.ndarray or tf.placeholder)\r\n",
      "    :return: (bool)\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    return len(tensor.shape) == 3 and tensor.shape[-1] in [1, 3, 4]\r\n",
      "\r\n",
      "\r\n",
      "# ================================================================\r\n",
      "# Mathematical utils\r\n",
      "# ================================================================\r\n",
      "\r\n",
      "def huber_loss(tensor, delta=1.0):\r\n",
      "    \"\"\"\r\n",
      "    Reference: https://en.wikipedia.org/wiki/Huber_loss\r\n",
      "\r\n",
      "    :param tensor: (TensorFlow Tensor) the input value\r\n",
      "    :param delta: (float) Huber loss delta value\r\n",
      "    :return: (TensorFlow Tensor) Huber loss output\r\n",
      "    \"\"\"\r\n",
      "    return tf.where(\r\n",
      "        tf.abs(tensor) < delta,\r\n",
      "        tf.square(tensor) * 0.5,\r\n",
      "        delta * (tf.abs(tensor) - 0.5 * delta)\r\n",
      "    )\r\n",
      "\r\n",
      "\r\n",
      "# ================================================================\r\n",
      "# Global session\r\n",
      "# ================================================================\r\n",
      "\r\n",
      "def make_session(num_cpu=None, make_default=False, graph=None):\r\n",
      "    \"\"\"\r\n",
      "    Returns a session that will use <num_cpu> CPU's only\r\n",
      "\r\n",
      "    :param num_cpu: (int) number of CPUs to use for TensorFlow\r\n",
      "    :param make_default: (bool) if this should return an InteractiveSession or a normal Session\r\n",
      "    :param graph: (TensorFlow Graph) the graph of the session\r\n",
      "    :return: (TensorFlow session)\r\n",
      "    \"\"\"\r\n",
      "    if num_cpu is None:\r\n",
      "        num_cpu = int(os.getenv('RCALL_NUM_CPU', multiprocessing.cpu_count()))\r\n",
      "    tf_config = tf.compat.v1.ConfigProto(\r\n",
      "        allow_soft_placement=True,\r\n",
      "        inter_op_parallelism_threads=num_cpu,\r\n",
      "        intra_op_parallelism_threads=num_cpu)\r\n",
      "    # Prevent tensorflow from taking all the gpu memory\r\n",
      "    tf_config.gpu_options.allow_growth = True\r\n",
      "    if make_default:\r\n",
      "        return tf.compat.v1.InteractiveSession(config=tf_config, graph=graph)\r\n",
      "    else:\r\n",
      "        return tf.compat.v1.Session(config=tf_config, graph=graph)\r\n",
      "\r\n",
      "\r\n",
      "def single_threaded_session(make_default=False, graph=None):\r\n",
      "    \"\"\"\r\n",
      "    Returns a session which will only use a single CPU\r\n",
      "\r\n",
      "    :param make_default: (bool) if this should return an InteractiveSession or a normal Session\r\n",
      "    :param graph: (TensorFlow Graph) the graph of the session\r\n",
      "    :return: (TensorFlow session)\r\n",
      "    \"\"\"\r\n",
      "    return make_session(num_cpu=1, make_default=make_default, graph=graph)\r\n",
      "\r\n",
      "\r\n",
      "def in_session(func):\r\n",
      "    \"\"\"\r\n",
      "    Wraps a function so that it is in a TensorFlow Session\r\n",
      "\r\n",
      "    :param func: (function) the function to wrap\r\n",
      "    :return: (function)\r\n",
      "    \"\"\"\r\n",
      "\r\n",
      "    @functools.wraps(func)\r\n",
      "    def newfunc(*args, **kwargs):\r\n",
      "        with tf.Session():\r\n",
      "            func(*args, **kwargs)\r\n",
      "\r\n",
      "    return newfunc\r\n",
      "\r\n",
      "\r\n",
      "ALREADY_INITIALIZED = set()  # type: Set[tf.Variable]\r\n",
      "\r\n",
      "\r\n",
      "def initialize(sess=None):\r\n",
      "    \"\"\"\r\n",
      "    Initialize all the uninitialized variables in the global scope.\r\n",
      "\r\n",
      "    :param sess: (TensorFlow Session)\r\n",
      "    \"\"\"\r\n",
      "    if sess is None:\r\n",
      "        sess = tf.get_default_session()\r\n",
      "    new_variables = set(tf.global_variables()) - ALREADY_INITIALIZED\r\n",
      "    sess.run(tf.variables_initializer(new_variables))\r\n",
      "    ALREADY_INITIALIZED.update(new_variables)\r\n",
      "\r\n",
      "\r\n",
      "# ================================================================\r\n",
      "# Theano-like Function\r\n",
      "# ================================================================\r\n",
      "\r\n",
      "def function(inputs, outputs, updates=None, givens=None):\r\n",
      "    \"\"\"\r\n",
      "    Take a bunch of tensorflow placeholders and expressions\r\n",
      "    computed based on those placeholders and produces f(inputs) -> outputs. Function f takes\r\n",
      "    values to be fed to the input's placeholders and produces the values of the expressions\r\n",
      "    in outputs. Just like a Theano function.\r\n",
      "\r\n",
      "    Input values can be passed in the same order as inputs or can be provided as kwargs based\r\n",
      "    on placeholder name (passed to constructor or accessible via placeholder.op.name).\r\n",
      "\r\n",
      "    Example:\r\n",
      "       >>> x = tf.placeholder(tf.int32, (), name=\"x\")\r\n",
      "       >>> y = tf.placeholder(tf.int32, (), name=\"y\")\r\n",
      "       >>> z = 3 * x + 2 * y\r\n",
      "       >>> lin = function([x, y], z, givens={y: 0})\r\n",
      "       >>> with single_threaded_session():\r\n",
      "       >>>     initialize()\r\n",
      "       >>>     assert lin(2) == 6\r\n",
      "       >>>     assert lin(x=3) == 9\r\n",
      "       >>>     assert lin(2, 2) == 10\r\n",
      "\r\n",
      "    :param inputs: (TensorFlow Tensor or Object with make_feed_dict) list of input arguments\r\n",
      "    :param outputs: (TensorFlow Tensor) list of outputs or a single output to be returned from function. Returned\r\n",
      "        value will also have the same shape.\r\n",
      "    :param updates: ([tf.Operation] or tf.Operation)\r\n",
      "        list of update functions or single update function that will be run whenever\r\n",
      "        the function is called. The return is ignored.\r\n",
      "    :param givens: (dict) the values known for the output\r\n",
      "    \"\"\"\r\n",
      "    if isinstance(outputs, list):\r\n",
      "        return _Function(inputs, outputs, updates, givens=givens)\r\n",
      "    elif isinstance(outputs, (dict, collections.OrderedDict)):\r\n",
      "        func = _Function(inputs, outputs.values(), updates, givens=givens)\r\n",
      "        return lambda *args, **kwargs: type(outputs)(zip(outputs.keys(), func(*args, **kwargs)))\r\n",
      "    else:\r\n",
      "        func = _Function(inputs, [outputs], updates, givens=givens)\r\n",
      "        return lambda *args, **kwargs: func(*args, **kwargs)[0]\r\n",
      "\r\n",
      "\r\n",
      "class _Function(object):\r\n",
      "    def __init__(self, inputs, outputs, updates, givens):\r\n",
      "        \"\"\"\r\n",
      "        Theano like function\r\n",
      "\r\n",
      "        :param inputs: (TensorFlow Tensor or Object with make_feed_dict) list of input arguments\r\n",
      "        :param outputs: (TensorFlow Tensor) list of outputs or a single output to be returned from function. Returned\r\n",
      "            value will also have the same shape.\r\n",
      "        :param updates: ([tf.Operation] or tf.Operation)\r\n",
      "        list of update functions or single update function that will be run whenever\r\n",
      "        the function is called. The return is ignored.\r\n",
      "        :param givens: (dict) the values known for the output\r\n",
      "        \"\"\"\r\n",
      "        for inpt in inputs:\r\n",
      "            if not hasattr(inpt, 'make_feed_dict') and not (isinstance(inpt, tf.Tensor)and len(inpt.op.inputs) == 0):\r\n",
      "                assert False, \"inputs should all be placeholders, constants, or have a make_feed_dict method\"\r\n",
      "        self.inputs = inputs\r\n",
      "        updates = updates or []\r\n",
      "        self.update_group = tf.group(*updates)\r\n",
      "        self.outputs_update = list(outputs) + [self.update_group]\r\n",
      "        self.givens = {} if givens is None else givens\r\n",
      "\r\n",
      "    @classmethod\r\n",
      "    def _feed_input(cls, feed_dict, inpt, value):\r\n",
      "        if hasattr(inpt, 'make_feed_dict'):\r\n",
      "            feed_dict.update(inpt.make_feed_dict(value))\r\n",
      "        else:\r\n",
      "            feed_dict[inpt] = value\r\n",
      "\r\n",
      "    def __call__(self, *args, sess=None, **kwargs):\r\n",
      "        assert len(args) <= len(self.inputs), \"Too many arguments provided\"\r\n",
      "        if sess is None:\r\n",
      "            sess = tf.get_default_session()\r\n",
      "        feed_dict = {}\r\n",
      "        # Update the args\r\n",
      "        for inpt, value in zip(self.inputs, args):\r\n",
      "            self._feed_input(feed_dict, inpt, value)\r\n",
      "        # Update feed dict with givens.\r\n",
      "        for inpt in self.givens:\r\n",
      "            feed_dict[inpt] = feed_dict.get(inpt, self.givens[inpt])\r\n",
      "        results = sess.run(self.outputs_update, feed_dict=feed_dict, **kwargs)[:-1]\r\n",
      "        return results\r\n",
      "\r\n",
      "\r\n",
      "# ================================================================\r\n",
      "# Flat vectors\r\n",
      "# ================================================================\r\n",
      "\r\n",
      "def var_shape(tensor):\r\n",
      "    \"\"\"\r\n",
      "    get TensorFlow Tensor shape\r\n",
      "\r\n",
      "    :param tensor: (TensorFlow Tensor) the input tensor\r\n",
      "    :return: ([int]) the shape\r\n",
      "    \"\"\"\r\n",
      "    out = tensor.get_shape().as_list()\r\n",
      "    assert all(isinstance(a, int) for a in out), \\\r\n",
      "        \"shape function assumes that shape is fully known\"\r\n",
      "    return out\r\n",
      "\r\n",
      "\r\n",
      "def numel(tensor):\r\n",
      "    \"\"\"\r\n",
      "    get TensorFlow Tensor's number of elements\r\n",
      "\r\n",
      "    :param tensor: (TensorFlow Tensor) the input tensor\r\n",
      "    :return: (int) the number of elements\r\n",
      "    \"\"\"\r\n",
      "    return intprod(var_shape(tensor))\r\n",
      "\r\n",
      "\r\n",
      "def intprod(tensor):\r\n",
      "    \"\"\"\r\n",
      "    calculates the product of all the elements in a list\r\n",
      "\r\n",
      "    :param tensor: ([Number]) the list of elements\r\n",
      "    :return: (int) the product truncated\r\n",
      "    \"\"\"\r\n",
      "    return int(np.prod(tensor))\r\n",
      "\r\n",
      "\r\n",
      "def flatgrad(loss, var_list, clip_norm=None):\r\n",
      "    \"\"\"\r\n",
      "    calculates the gradient and flattens it\r\n",
      "\r\n",
      "    :param loss: (float) the loss value\r\n",
      "    :param var_list: ([TensorFlow Tensor]) the variables\r\n",
      "    :param clip_norm: (float) clip the gradients (disabled if None)\r\n",
      "    :return: ([TensorFlow Tensor]) flattened gradient\r\n",
      "    \"\"\"\r\n",
      "    grads = tf.gradients(loss, var_list)\r\n",
      "    if clip_norm is not None:\r\n",
      "        grads = [tf.clip_by_norm(grad, clip_norm=clip_norm) for grad in grads]\r\n",
      "    return tf.concat(axis=0, values=[\r\n",
      "        tf.reshape(grad if grad is not None else tf.zeros_like(v), [numel(v)])\r\n",
      "        for (v, grad) in zip(var_list, grads)\r\n",
      "    ])\r\n",
      "\r\n",
      "\r\n",
      "class SetFromFlat(object):\r\n",
      "    def __init__(self, var_list, dtype=tf.float32, sess=None):\r\n",
      "        \"\"\"\r\n",
      "        Set the parameters from a flat vector\r\n",
      "\r\n",
      "        :param var_list: ([TensorFlow Tensor]) the variables\r\n",
      "        :param dtype: (type) the type for the placeholder\r\n",
      "        :param sess: (TensorFlow Session)\r\n",
      "        \"\"\"\r\n",
      "        shapes = list(map(var_shape, var_list))\r\n",
      "        total_size = np.sum([intprod(shape) for shape in shapes])\r\n",
      "\r\n",
      "        self.theta = theta = tf.placeholder(dtype, [total_size])\r\n",
      "        start = 0\r\n",
      "        assigns = []\r\n",
      "        for (shape, _var) in zip(shapes, var_list):\r\n",
      "            size = intprod(shape)\r\n",
      "            assigns.append(tf.assign(_var, tf.reshape(theta[start:start + size], shape)))\r\n",
      "            start += size\r\n",
      "        self.operation = tf.group(*assigns)\r\n",
      "        self.sess = sess\r\n",
      "\r\n",
      "    def __call__(self, theta):\r\n",
      "        if self.sess is None:\r\n",
      "            return tf.get_default_session().run(self.operation, feed_dict={self.theta: theta})\r\n",
      "        else:\r\n",
      "            return self.sess.run(self.operation, feed_dict={self.theta: theta})\r\n",
      "\r\n",
      "\r\n",
      "class GetFlat(object):\r\n",
      "    def __init__(self, var_list, sess=None):\r\n",
      "        \"\"\"\r\n",
      "        Get the parameters as a flat vector\r\n",
      "\r\n",
      "        :param var_list: ([TensorFlow Tensor]) the variables\r\n",
      "        :param sess: (TensorFlow Session)\r\n",
      "        \"\"\"\r\n",
      "        self.operation = tf.concat(axis=0, values=[tf.reshape(v, [numel(v)]) for v in var_list])\r\n",
      "        self.sess = sess\r\n",
      "\r\n",
      "    def __call__(self):\r\n",
      "        if self.sess is None:\r\n",
      "            return tf.get_default_session().run(self.operation)\r\n",
      "        else:\r\n",
      "            return self.sess.run(self.operation)\r\n",
      "\r\n",
      "\r\n",
      "# ================================================================\r\n",
      "# retrieving variables\r\n",
      "# ================================================================\r\n",
      "\r\n",
      "def get_trainable_vars(name):\r\n",
      "    \"\"\"\r\n",
      "    returns the trainable variables\r\n",
      "\r\n",
      "    :param name: (str) the scope\r\n",
      "    :return: ([TensorFlow Variable])\r\n",
      "    \"\"\"\r\n",
      "    return tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=name)\r\n",
      "\r\n",
      "\r\n",
      "def get_globals_vars(name):\r\n",
      "    \"\"\"\r\n",
      "    returns the trainable variables\r\n",
      "\r\n",
      "    :param name: (str) the scope\r\n",
      "    :return: ([TensorFlow Variable])\r\n",
      "    \"\"\"\r\n",
      "    return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=name)\r\n",
      "\r\n",
      "\r\n",
      "def outer_scope_getter(scope, new_scope=\"\"):\r\n",
      "    \"\"\"\r\n",
      "    remove a scope layer for the getter\r\n",
      "\r\n",
      "    :param scope: (str) the layer to remove\r\n",
      "    :param new_scope: (str) optional replacement name\r\n",
      "    :return: (function (function, str, ``*args``, ``**kwargs``): Tensorflow Tensor)\r\n",
      "    \"\"\"\r\n",
      "    def _getter(getter, name, *args, **kwargs):\r\n",
      "        name = name.replace(scope + \"/\", new_scope, 1)\r\n",
      "        val = getter(name, *args, **kwargs)\r\n",
      "        return val\r\n",
      "    return _getter\r\n"
     ]
    }
   ],
   "source": [
    "! cat /opt/conda/envs/habitat/lib/python3.6/site-packages/stable_baselines/common/tf_util.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure_1.png\t\t    environment\r\n",
      "LP_PPO_model.zip\t    rl_env_block_agent.py\r\n",
      "LP_PPO_model_mlp.zip\t    rl_env_slam_with_local_policy.py\r\n",
      "LocalPolicyPPO_train.ipynb  rl_env_test.ipynb\r\n",
      "README.md\t\t    rl_env_test.py\r\n",
      "agent test.ipynb\t    tensorboard\r\n",
      "agents\t\t\t    test python files notebook.ipynb\r\n",
      "block_agent_test.ipynb\t    test_slam.py\r\n",
      "common\t\t\t    train.log\r\n",
      "configs\t\t\t    vector_env_test.py\r\n",
      "data\r\n"
     ]
    }
   ],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.zeros([255, 255, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imshow(\"test\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im)\n",
    "plt.plot\n",
    "print('hello')\n",
    "input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
