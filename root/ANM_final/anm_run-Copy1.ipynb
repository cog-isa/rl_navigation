{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-67eb103c9f58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhabitat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRLEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectorEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_local_map_boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhabitat_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_env_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCircle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~root/ANM_final/vectorenv.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhabitat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointnav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointnav_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPointNavDatasetV1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# from pointnav_env import Pointnav_Env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexploration_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExploration_Env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiple_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~root/ANM_final/exploration_env.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhabitat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_builder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMapBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmm_planner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFMMPlanner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'env'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import habitat\n",
    "import math\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import skimage\n",
    "import skfmm\n",
    "\n",
    "import gym\n",
    "import logging\n",
    "from arguments import get_args\n",
    "from pointnav_env import Pointnav_Env\n",
    "from utils.storage import GlobalRolloutStorage, FIFOMemory\n",
    "from utils.optimization import get_optimizer\n",
    "from model import RL_Policy, Local_IL_Policy, Neural_SLAM_Module\n",
    "from habitat.tasks.nav.shortest_path_follower import ShortestPathFollower\n",
    "from habitat.datasets.pointnav.pointnav_dataset import PointNavDatasetV1\n",
    "from habitat_baselines.common.tensorboard_utils import TensorboardWriter\n",
    "from util import AgentPositionSensor\n",
    "from utils.fmm_planner import FMMPlanner\n",
    "\n",
    "from ppo import PPO\n",
    "import utils.pose as pu\n",
    "\n",
    "import sys\n",
    "import matplotlib\n",
    "\n",
    "if sys.platform == 'darwin':\n",
    "    matplotlib.use(\"tkagg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from typing import Type, Union\n",
    "from habitat import Config, Env, RLEnv, make_dataset\n",
    "from vectorenv import VectorEnv, get_local_map_boundaries\n",
    "from habitat_baselines.common.environments import get_env_class\n",
    "from matplotlib.patches import Circle\n",
    "from arguments import multiple_config, init_config\n",
    "%matplotlib inline\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argumnts = ''\n",
    "args = get_args(argumnts)\n",
    "args.num_processes = 2\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "config = init_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"{}models/{}/\".format(args.dump_location, args.exp_name)\n",
    "dump_dir = \"{}dump/{}/\".format(args.dump_location, args.exp_name)\n",
    "if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "if not os.path.exists(\"{}/images/\".format(dump_dir)):\n",
    "    os.makedirs(\"{}/images/\".format(dump_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_map_and_pose():\n",
    "    full_map.fill_(0.)\n",
    "    full_pose.fill_(0.)\n",
    "    full_pose[:, :2] = args.map_size_cm / 100.0 / 2.0\n",
    "\n",
    "    locs = full_pose.cpu().numpy()\n",
    "    planner_pose_inputs[:, :3] = locs\n",
    "    for e in range(num_scenes):\n",
    "        r, c = locs[e, 1], locs[e, 0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        full_map[e, 2:, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.0\n",
    "\n",
    "        lmb[e] = get_local_map_boundaries((loc_r, loc_c),\n",
    "                                          (local_w, local_h),\n",
    "                                          (full_w, full_h), args)\n",
    "\n",
    "        planner_pose_inputs[e, 3:] = lmb[e]\n",
    "        origins[e] = [lmb[e][2] * args.map_resolution / 100.0,\n",
    "                      lmb[e][0] * args.map_resolution / 100.0, 0.]\n",
    "\n",
    "    for e in range(num_scenes):\n",
    "        local_map[e] = full_map[e, :, lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]]\n",
    "        local_pose[e] = full_pose[e] - \\\n",
    "                        torch.from_numpy(origins[e]).to(device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw():\n",
    "    circ = Circle(((one_env.trux+12)/args.map_size_cm*48000,(one_env.truy+12)/args.map_size_cm*48000),3,color='white')\n",
    "    circ2 = Circle(((one_env.trux+12)/args.map_size_cm*48000,(one_env.truy+12)/args.map_size_cm*48000),3,color='white')\n",
    "    circ3 = Circle(((one_env.goalx+12)/args.map_size_cm*48000,(one_env.goaly+12)/args.map_size_cm*48000),3,color='red')\n",
    "    circ4 = Circle(((one_env.goalx+12)/args.map_size_cm*48000,(one_env.goaly+12)/args.map_size_cm*48000),3,color='red')\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    ax = f.add_subplot(231)\n",
    "    ax2 = f.add_subplot(232)\n",
    "    ax3 = f.add_subplot(233)\n",
    "    ax.set_aspect('equal')\n",
    "    ax2.set_aspect('equal')\n",
    "    ax3.set_aspect('equal')\n",
    "    ax.add_patch(circ)\n",
    "    ax2.add_patch(circ2)\n",
    "    ax.add_patch(circ3)\n",
    "    ax2.add_patch(circ4)\n",
    "    ax.imshow(one_env.map)\n",
    "    ax.set_title('map')\n",
    "    ax2.imshow(one_env.explored_map)\n",
    "    ax2.set_title('explored_map ')\n",
    "    ax3.imshow(np.transpose(obs['rgb'], (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_scenes = args.num_processes\n",
    "num_episodes = int(args.num_episodes)\n",
    "device = args.device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "policy_loss = 0\n",
    "\n",
    "best_cost = 100000\n",
    "costs = deque(maxlen=1000)\n",
    "exp_costs = deque(maxlen=1000)\n",
    "pose_costs = deque(maxlen=1000)\n",
    "\n",
    "g_masks = torch.ones(num_scenes).float().to(device)\n",
    "l_masks = torch.zeros(num_scenes).float().to(device)\n",
    "\n",
    "best_local_loss = np.inf\n",
    "best_g_reward = -np.inf\n",
    "\n",
    "if args.eval:\n",
    "    traj_lengths = args.max_episode_length // args.num_local_steps\n",
    "    explored_area_log = np.zeros((num_scenes, num_episodes, traj_lengths))\n",
    "    explored_ratio_log = np.zeros((num_scenes, num_episodes, traj_lengths))\n",
    "\n",
    "g_episode_rewards = deque(maxlen=1000)\n",
    "\n",
    "l_action_losses = deque(maxlen=1000)\n",
    "\n",
    "g_value_losses = deque(maxlen=1000)\n",
    "g_action_losses = deque(maxlen=1000)\n",
    "g_dist_entropies = deque(maxlen=1000)\n",
    "\n",
    "per_step_g_rewards = deque(maxlen=1000)\n",
    "\n",
    "g_process_rewards = np.zeros((num_scenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_full():\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    circ = Circle((local_pose[0][0]/args.map_size_cm*48000,local_pose[0][1]/args.map_size_cm*48000),3,color='red')\n",
    "    \n",
    "    circ2 = Circle((one_env.start_240_240[0],one_env.start_240_240[1]),1,color='red')\n",
    "    circ5 = Circle((one_env.goal_240_240[0],one_env.goal_240_240[1]),3,color='white')\n",
    "    circ6 = Circle((one_env.stg[0],one_env.stg[1]),1,color='green')\n",
    "    \n",
    "    circ3 = Circle((trux[0]-120-(lmb[0,2]-120),truy[0]-120-(lmb[0,0]-120)),3,color='red')\n",
    "    circ4 = Circle((goalx[0]-120-(lmb[0,2]-120),goaly[0]-120-(lmb[0,0]-120)),3,color='white')\n",
    "    circ7 = Circle((one_env.stg[0],one_env.stg[1]),3,color='green')\n",
    "    \n",
    "    circ8 = Circle((trux[0],truy[0]),3,color='red')\n",
    "    circ9 = Circle((goalx[0],goaly[0]),3,color='white')\n",
    "    circ111 = Circle((one_env.local_goal_x_y[0],one_env.local_goal_x_y[1]),3,color='green')\n",
    "    circ22 = Circle((one_env.goal_to_planer[0]-one_env.local_map_frame[2]+1,one_env.goal_to_planer[1]-one_env.local_map_frame[0]+1),3,color='white')\n",
    "    circ33 = Circle((one_env.start_240_240[0]-one_env.local_map_frame[2]+1,one_env.start_240_240[1]-one_env.local_map_frame[0]+1),3,color='red')\n",
    "    circ10 = Circle((trux[0],truy[0]),3,color='red')\n",
    "    circ11 = Circle((goalx[0],goaly[0]),3,color='green')\n",
    "\n",
    "    ax = f.add_subplot(231)\n",
    "    ax2 = f.add_subplot(232)\n",
    "    ax3 = f.add_subplot(233)\n",
    "    ax4 = f.add_subplot(234)\n",
    "    ax5 = f.add_subplot(235)\n",
    "    ax6 = f.add_subplot(236)\n",
    "    ax.imshow(global_input[0,0,:,:].cpu())\n",
    "    ax.add_patch(circ)\n",
    "    ax2.imshow(one_env.map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]])\n",
    "    ax2.add_patch(circ2)\n",
    "    ax2.add_patch(circ5)\n",
    "    ax2.add_patch(circ6)\n",
    "    ax3.imshow(obs_rgb.cpu()[0][1])\n",
    "    ax4.imshow(one_env.explored_map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]])\n",
    "    ax4.add_patch(circ3)\n",
    "    ax4.add_patch(circ4)\n",
    "    ax4.add_patch(circ7)\n",
    "    ax5.imshow(one_env.traversible)\n",
    "    ax5.add_patch(circ111)\n",
    "    ax5.add_patch(circ22)\n",
    "    ax5.add_patch(circ33)\n",
    "    #ax6.imshow(one_env.explorable_map)\n",
    "    #ax6.add_patch(circ10)\n",
    "    #ax6.add_patch(circ11)\n",
    "    \n",
    "    f.canvas.draw()\n",
    "    \n",
    "    f.savefig('./img/{}.png'.format(10000+step))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_class = get_env_class(\"Pointnav_Env\")\n",
    "dataset = make_dataset(config.DATASET.TYPE, config=config.DATASET)\n",
    "one_env = env_class(argss=args, rank=range(1),\n",
    "                          config_env=config, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_processes = 1\n",
    "num_scenes = 1\n",
    "device = args.device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "l_observation_space = gym.spaces.Box(0, 255,\n",
    "                                     (3,\n",
    "                                      args.frame_width,\n",
    "                                      args.frame_width), dtype='uint8')\n",
    "l_hidden_size = args.local_hidden_size\n",
    "# slam\n",
    "nslam_module = Neural_SLAM_Module(args).to(device)\n",
    "# Local policy\n",
    "l_policy = Local_IL_Policy(l_observation_space.shape, one_env.action_space.n,\n",
    "                           recurrent=args.use_recurrent_local,\n",
    "                           hidden_size=l_hidden_size,\n",
    "                           deterministic=args.use_deterministic_local).to(device)\n",
    "#state_dict = torch.load('./model_best.slam',\n",
    "#                            map_location=lambda storage, loc: storage)\n",
    "#nslam_module.load_state_dict(state_dict)\n",
    "#state_dict = torch.load('./model_best.local',\n",
    "#                            map_location=lambda storage, loc: storage)\n",
    "#l_policy.load_state_dict(state_dict)\n",
    "local_optimizer = get_optimizer(l_policy.parameters(),\n",
    "                                args.local_optimizer)\n",
    "slam_optimizer = get_optimizer(nslam_module.parameters(),\n",
    "                               args.slam_optimizer)\n",
    "slam_memory = FIFOMemory(args.slam_memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = args.device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "map_size = args.map_size_cm // args.map_resolution\n",
    "full_w, full_h = map_size, map_size\n",
    "local_w, local_h = int(full_w / args.global_downscaling), \\\n",
    "                   int(full_h / args.global_downscaling)\n",
    "g_masks = torch.ones(num_scenes).float().to(device)\n",
    "l_masks = torch.zeros(num_scenes).float().to(device)\n",
    "full_map = torch.zeros(1, 4, full_w, full_h).float().to(device)\n",
    "local_map = torch.zeros(1, 4, local_w, local_h).float().to(device)\n",
    "full_pose = torch.zeros(1, 3).float().to(device)\n",
    "local_pose = torch.zeros(1, 3).float().to(device)\n",
    "global_input = torch.zeros(1, 8, local_w, local_h)\n",
    "global_orientation = torch.zeros(1, 1).long()\n",
    "planner_pose_inputs = np.zeros((1, 7))\n",
    "lmb = np.zeros((1, 4)).astype(int)\n",
    "origins = np.zeros((1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /root/ANM_CLEAN/img/*\n",
    "obs, info = one_env.reset()\n",
    "step = 0\n",
    "init_map_and_pose()\n",
    "\n",
    "#follower = ShortestPathFollower(one_env.habitat_env.sim, 0.36, False)\n",
    "\n",
    "poses = torch.from_numpy(np.asarray(\n",
    "    [info['sensor_pose']])).float().to(device)\n",
    "obs_rgb = torch.from_numpy(np.expand_dims(obs['rgb'], axis=0)).float().to(device)\n",
    "\n",
    "_, _, local_map[:, 0, :, :], local_map[:, 1, :, :], _, local_pose = \\\n",
    "    nslam_module(obs_rgb, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                 local_map[:, 1, :, :], local_pose)\n",
    "\n",
    "locs = local_pose.cpu().numpy()\n",
    "global_input = torch.zeros(1, 8, local_w, local_h)\n",
    "global_orientation = torch.zeros(1, 1).long()\n",
    "r, c = locs[0, 1], locs[0, 0]\n",
    "loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                    int(c * 100.0 / args.map_resolution)]\n",
    "local_map[0, 2:, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.\n",
    "global_orientation[0] = int((locs[0, 2] + 180.0) / 5.)\n",
    "global_input[:, 0:4, :, :] = local_map.detach()\n",
    "global_input[:, 4:, :, :] = nn.MaxPool2d(args.global_downscaling)(full_map)\n",
    "goalx,goaly = ((one_env.goalx)+12)/args.map_size_cm*48000, ((one_env.goaly)+12)/args.map_size_cm*48000\n",
    "global_goals = [[int(goalx),int(goaly)]] \n",
    "\n",
    "planner_inputs = [{} for e in range(num_scenes)]\n",
    "for e, p_input in enumerate(planner_inputs):\n",
    "    p_input['goal'] = global_goals[e]\n",
    "    p_input['map_pred'] = global_input[e, 0, :, :].detach().cpu().numpy()\n",
    "    p_input['exp_pred'] = global_input[e, 1, :, :].detach().cpu().numpy()\n",
    "    p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "\n",
    "# Output stores local goals as well as the the ground-truth action\n",
    "#output = envs.get_short_term_goal(planner_inputs)\n",
    "\n",
    "last_obs = obs_rgb.detach()\n",
    "local_rec_states = torch.zeros(1, l_hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = one_env.reset()\n",
    "step = 0\n",
    "init_map_and_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,10))\n",
    "ax = f.add_subplot(231)\n",
    "ax2 = f.add_subplot(232)\n",
    "ax3 = f.add_subplot(233)\n",
    "ax.imshow(global_input[0,0,:,:].cpu())\n",
    "ax2.imshow(one_env.map[120:360,120:360])#nn.MaxPool2d(args.global_downscaling)(torch.from_numpy(one_env.map).unsqueeze_(0))[0])\n",
    "ax3.imshow(obs_rgb.cpu()[0][1])\n",
    "print(global_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = [120,50]\n",
    "goal = [200,200]\n",
    "planning_window = [0, 400, 0, 400]\n",
    "grid = planner_inputs[0]['map_pred']\n",
    "explored = planner_inputs[0]['exp_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_env.start_240_240 = start\n",
    "one_env.goal_240_240 = goal\n",
    "# Get short-term goal\n",
    "print(grid.shape,start,goal,planning_window,' SHAPE_MAP START GOAL PLAN_WIND')\n",
    "stg = one_env._get_stg(grid, explored, start, np.copy(goal), planning_window)\n",
    "\n",
    "dist_to_goal = pu.get_l2_distance(goal[0], start[0], goal[1], start[1])*5./100.\n",
    "\n",
    "(stg_x, stg_y) = stg\n",
    "one_env.stg = [stg_x, stg_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,10))\n",
    "circ2 = Circle((one_env.start_240_240[0],one_env.start_240_240[1]),1,color='red')\n",
    "circ5 = Circle((one_env.goal_240_240[0],one_env.goal_240_240[1]),3,color='white')\n",
    "circ6 = Circle((one_env.stg[0],one_env.stg[1]),1,color='green')\n",
    "circ111 = Circle((one_env.local_goal_x_y[0],one_env.local_goal_x_y[1]),3,color='green')\n",
    "circ22 = Circle((one_env.goal_to_planer[0]-one_env.local_map_frame[2]+1,one_env.goal_to_planer[1]-one_env.local_map_frame[0]+1),3,color='white')\n",
    "circ33 = Circle((one_env.start_240_240[0]-one_env.local_map_frame[2]+1,one_env.start_240_240[1]-one_env.local_map_frame[0]+1),3,color='red')\n",
    "\n",
    "ax2 = f.add_subplot(231)\n",
    "ax5 = f.add_subplot(232)\n",
    "ax2.imshow(one_env.map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]])\n",
    "ax2.add_patch(circ2)\n",
    "ax2.add_patch(circ5)\n",
    "ax2.add_patch(circ6)\n",
    "\n",
    "ax5.imshow(one_env.traversible)\n",
    "ax5.add_patch(circ111)\n",
    "ax5.add_patch(circ22)\n",
    "ax5.add_patch(circ33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_steps = 0\n",
    "start = time.time()\n",
    "for iii in range(50):\n",
    "    \n",
    " #   obs, info = one_env.reset()\n",
    " #   step = 0\n",
    " #   init_map_and_pose()\n",
    "    total_num_steps+=1\n",
    "    \n",
    "    last_obs = obs_rgb.detach()\n",
    "    \n",
    "    output = one_env.get_short_term_goal(planner_inputs[0])\n",
    "    \n",
    "    local_masks = l_masks\n",
    "    local_goals = torch.from_numpy(output[:-1]).to(device).long()\n",
    "    \n",
    "\n",
    "    local_rec_states = local_rec_states.detach_()\n",
    "    \n",
    "    \n",
    "\n",
    "    #start = one_env.start_240_240\n",
    "    goal = one_env.goal_240_240\n",
    "    #dist_to_goal = pu.get_l2_distance(goal[0], start[0], goal[1], start[1])*5./100.\n",
    "    #print(int(output[2]),output[0],output[1],' Fol_action,action,angle,dist_goal')\n",
    "\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    obs, reward, done, info = one_env.step(action=int(output[2]))\n",
    "    \n",
    "    \n",
    "\n",
    "    obs_rgb = torch.from_numpy(np.expand_dims(obs['rgb'], axis=0)).float().to(device)\n",
    "    trux,truy,goalx,goaly = [(one_env.trux+12)/args.map_size_cm*48000], [(one_env.truy+12)/args.map_size_cm*48000], [(one_env.goalx+12)/args.map_size_cm*48000], [(one_env.goaly+12)/args.map_size_cm*48000] \n",
    "    global_goals = [[int(goalx[i]),int(goaly[i])] for i in range(len(goalx))]\n",
    "    \n",
    "    if int(output[2])==0:\n",
    "        print('RESTART')\n",
    "        last_obs=obs_rgb.detach()\n",
    "        obs, info = one_env.reset()\n",
    "        init_map_and_pose()\n",
    "        local_rec_states = torch.zeros(1, l_hidden_size).to(device)\n",
    "        \n",
    "    for env_idx in range(1):\n",
    "        env_obs = obs_rgb[env_idx].to(\"cpu\")\n",
    "        env_poses = torch.from_numpy(np.asarray(\n",
    "            info['sensor_pose']\n",
    "        )).float().to(\"cpu\")\n",
    "        env_gt_fp_projs = torch.from_numpy(np.asarray(\n",
    "            info['fp_proj']\n",
    "        )).unsqueeze(0).float().to(\"cpu\")\n",
    "        env_gt_fp_explored = torch.from_numpy(np.asarray(\n",
    "            info['fp_explored']\n",
    "        )).unsqueeze(0).float().to(\"cpu\")\n",
    "        env_gt_pose_err = torch.from_numpy(np.asarray(\n",
    "            info['pose_err']\n",
    "        )).float().to(\"cpu\")\n",
    "        slam_memory.push(\n",
    "            (last_obs[0].cpu(), env_obs, env_poses),\n",
    "            (env_gt_fp_projs, env_gt_fp_explored, env_gt_pose_err))    \n",
    "\n",
    "    l_masks = torch.FloatTensor([0 if done else 1]).to(device)\n",
    "    g_masks *= l_masks\n",
    "    poses = torch.from_numpy(np.asarray(\n",
    "                    [info['sensor_pose']])).float().to(device)\n",
    "\n",
    "    _, _, local_map[:, 0, :, :], local_map[:, 1, :, :], _, local_pose = \\\n",
    "            nslam_module(last_obs, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                         local_map[:, 1, :, :], local_pose, build_maps=True)\n",
    "    locs = local_pose.cpu().numpy()\n",
    "    planner_pose_inputs[:, :3] = locs + origins\n",
    "    local_map[:, 2, :, :].fill_(0.)  # Resetting current location channel\n",
    "    for e in range(num_scenes):\n",
    "        r, c = locs[e, 1], locs[e, 0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        local_map[e, 2:, loc_r - 2:loc_r + 3, loc_c - 2:loc_c + 3] = 1.\n",
    "    # ------------------------------------------------------------------\n",
    "    for e in range(1):\n",
    "        full_map[0,:, lmb[0, 0]:lmb[0, 1], lmb[0, 2]:lmb[0, 3]] = \\\n",
    "            local_map[0]\n",
    "        full_pose[e] = local_pose[e] + \\\n",
    "                       torch.from_numpy(origins[e]).to(device).float()\n",
    "        locs = full_pose[e].cpu().numpy()\n",
    "        r, c = locs[1], locs[0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        lmb[e] = get_local_map_boundaries((loc_r, loc_c),\n",
    "                                          (local_w, local_h),\n",
    "                                          (full_w, full_h), args)\n",
    "\n",
    "        planner_pose_inputs[e, 3:] = lmb[e]\n",
    "        origins[e] = [lmb[e][2] * args.map_resolution / 100.0,\n",
    "                      lmb[e][0] * args.map_resolution / 100.0, 0.]\n",
    "\n",
    "        local_map[e] = full_map[e, :,\n",
    "                       lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]]\n",
    "        local_pose[e] = full_pose[e] - \\\n",
    "                        torch.from_numpy(origins[e]).to(device).float()\n",
    "    locs = local_pose.cpu().numpy()\n",
    "    for e in range(num_scenes):\n",
    "        global_orientation[e] = int((locs[e, 2] + 180.0) / 5.)\n",
    "    global_input[:, 0:4, :, :] = local_map\n",
    "    global_input[:, 4:, :, :] = \\\n",
    "        nn.MaxPool2d(args.global_downscaling)(full_map)\n",
    "\n",
    "    # Get short term goal\n",
    "    planner_inputs = [{} for e in range(num_scenes)]\n",
    "    for e, p_input in enumerate(planner_inputs):\n",
    "        p_input['map_pred'] = one_env.map[lmb[0,0]:lmb[0,1],lmb[0,2]:lmb[0,3]]#local_map[e, 0, :, :].cpu().numpy()\n",
    "        p_input['exp_pred'] = one_env.explored_map[lmb[0,0]:lmb[0,1],lmb[0,2]:lmb[0,3]]#local_map[e, 1, :, :].cpu().numpy()\n",
    "        p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "        p_input['goal'] = global_goals[e]\n",
    "\n",
    "    step+=1\n",
    "    \n",
    "  #  kartinka = one_env.draw_full() \n",
    "\n",
    "  #  explored_map,envs_map = one_env.explored_map, one_env.map\n",
    "\n",
    "    draw_full()\n",
    "    \n",
    "    ### TRAINING\n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    if args.train_slam and len(slam_memory) > args.slam_batch_size:\n",
    "        for _ in range(args.slam_iterations):\n",
    "            inputs, outputs = slam_memory.sample(args.slam_batch_size)\n",
    "            b_obs_last, b_obs, b_poses = inputs\n",
    "            gt_fp_projs, gt_fp_explored, gt_pose_err = outputs\n",
    "\n",
    "            b_obs = b_obs.to(device)\n",
    "            b_obs_last = b_obs_last.to(device)\n",
    "            b_poses = b_poses.to(device)\n",
    "\n",
    "            gt_fp_projs = gt_fp_projs.to(device)\n",
    "            gt_fp_explored = gt_fp_explored.to(device)\n",
    "            gt_pose_err = gt_pose_err.to(device)\n",
    "\n",
    "            b_proj_pred, b_fp_exp_pred, _, _, b_pose_err_pred, _ = \\\n",
    "                nslam_module(b_obs_last, b_obs, b_poses,\n",
    "                             None, None, None,\n",
    "                             build_maps=False)\n",
    "            loss = 0\n",
    "            if args.proj_loss_coeff > 0:\n",
    "                proj_loss = F.binary_cross_entropy(b_proj_pred,\n",
    "                                                   gt_fp_projs)\n",
    "                costs.append(proj_loss.item())\n",
    "                loss += args.proj_loss_coeff * proj_loss\n",
    "\n",
    "            if args.exp_loss_coeff > 0:\n",
    "                exp_loss = F.binary_cross_entropy(b_fp_exp_pred,\n",
    "                                                  gt_fp_explored)\n",
    "                exp_costs.append(exp_loss.item())\n",
    "                loss += args.exp_loss_coeff * exp_loss\n",
    "\n",
    "            if args.pose_loss_coeff > 0:\n",
    "                pose_loss = torch.nn.MSELoss()(b_pose_err_pred,\n",
    "                                               gt_pose_err)\n",
    "                pose_costs.append(args.pose_loss_coeff *\n",
    "                                  pose_loss.item())\n",
    "                loss += args.pose_loss_coeff * pose_loss\n",
    "\n",
    "            if args.train_slam:\n",
    "                slam_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                slam_optimizer.step()\n",
    "\n",
    "            del b_obs_last, b_obs, b_poses\n",
    "            del gt_fp_projs, gt_fp_explored, gt_pose_err\n",
    "            del b_proj_pred, b_fp_exp_pred, b_pose_err_pred\n",
    "          \n",
    "    # Finish Training\n",
    "    torch.set_grad_enabled(False)\n",
    "    if total_num_steps % args.log_interval == 0:\n",
    "        end = time.time()\n",
    "        time_elapsed = time.gmtime(end - start)\n",
    "        log = \" \".join([\n",
    "            \"Time: {0:0=2d}d\".format(time_elapsed.tm_mday - 1),\n",
    "            \"{},\".format(time.strftime(\"%Hh %Mm %Ss\", time_elapsed)),\n",
    "            \"num timesteps {},\".format(total_num_steps *\n",
    "                                       num_scenes),\n",
    "            \"FPS {},\".format(int(total_num_steps * num_scenes \\\n",
    "                                 / (end - start)))\n",
    "        ])\n",
    "\n",
    "        log += \"\\n\\tRewards:\"\n",
    "\n",
    "\n",
    "        log += \"\\n\\tLosses:\"\n",
    "\n",
    "\n",
    "        if args.train_slam:\n",
    "            log += \" \".join([\n",
    "                \" SLAM Loss proj/exp/pose:\"\n",
    "                \"{:.4f}/{:.4f}/{:.4f}\".format(\n",
    "                    np.mean(costs),\n",
    "                    np.mean(exp_costs),\n",
    "                    np.mean(pose_costs))\n",
    "            ])\n",
    "\n",
    "        print(log)\n",
    "        logging.info(log)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(one_env.local_goal_x_y)\n",
    "print(one_env.goal_to_planer)\n",
    "print(one_env.start_240_240)\n",
    "print(one_env.goal_240_240)\n",
    "print(one_env.stg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -framerate 1 -pattern_type glob -i '/root/ANM_final/img/*.png' -c:v libx264 -r 120 -pix_fmt yuv420p /root/ANM_final/out.mp4 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pred = one_env.map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]]\n",
    "exp_pred = one_env.explored_map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]]\n",
    "grid = np.rint(map_pred)\n",
    "explored = np.rint(exp_pred)\n",
    "start_x, start_y, start_o, gx1, gx2, gy1, gy2 = planner_pose_inputs[0]\n",
    "gx1, gx2, gy1, gy2 = int(gx1), int(gx2), int(gy1), int(gy2)\n",
    "planning_window = [gx1, gx2, gy1, gy2]\n",
    "    # Get last loc ground truth pose\n",
    "last_start_x, last_start_y = one_env.last_loc_gt[0], one_env.last_loc_gt[1]\n",
    "r, c = last_start_y, last_start_x\n",
    "last_start = [int(r * 100.0/args.map_resolution- gx1),\n",
    "              int(c * 100.0/args.map_resolution - gy1)]\n",
    "last_start = pu.threshold_poses(last_start, one_env.visited_gt.shape)\n",
    "# Get curr loc\n",
    "curr_loc = [start_x, start_y, start_o]\n",
    "r, c = start_y, start_x\n",
    "start = [int(r * 100.0/args.map_resolution - gx1),\n",
    "         int(c * 100.0/args.map_resolution - gy1)]\n",
    "start = pu.threshold_poses(start, grid.shape)\n",
    "#visited = np.copy(one_env.visited)\n",
    "one_env.visited[gx1:gx2, gy1:gy2][start[0]-2:start[0]+3,\n",
    "                                       start[1]-2:start[1]+3] = 1\n",
    "steps = 25\n",
    "#visited_vis = np.copy(one_env.visited_vis)\n",
    "for i in range(steps):\n",
    "    x = int(last_start[0] + (start[0] - last_start[0]) * (i+1) / steps)\n",
    "    y = int(last_start[1] + (start[1] - last_start[1]) * (i+1) / steps)\n",
    "    one_env.visited_vis[gx1:gx2, gy1:gy2][x, y] = 1\n",
    "# Get goal\n",
    "goal = np.copy(planner_inputs[0]['goal'])\n",
    "goal[0]= goal[0]-gy1\n",
    "goal[1]= goal[1]-gx1\n",
    "print(goal)\n",
    "goal = pu.threshold_poses(goal, grid.shape)    \n",
    "stg = one_env._get_stg(grid, explored, start, np.copy(goal), planning_window)\n",
    "gt_action = one_env._get_gt_action(1 - one_env.explorable_map, start,\n",
    "                                            [int(stg[0]), int(stg[1])],\n",
    "                                            planning_window, start_o)\n",
    "(stg_x, stg_y) = stg\n",
    "relative_dist = pu.get_l2_distance(stg_x, start[0], stg_y, start[1])\n",
    "relative_dist = relative_dist*5./100.\n",
    "angle_st_goal = math.degrees(math.atan2(stg_y - start[0],\n",
    "                                        stg_x - start[1]))\n",
    "angle_agent = (start_o)%360.0\n",
    "if angle_agent > 180:\n",
    "    angle_agent -= 360\n",
    "\n",
    "relative_angle = (angle_agent - angle_st_goal)%360.0\n",
    "if relative_angle > 180:\n",
    "    relative_angle -= 360\n",
    "print(stg,relative_dist,angle_st_goal,relative_angle,gt_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_env.explorable_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,10))\n",
    "circ = Circle((local_pose[0][0]/args.map_size_cm*48000,local_pose[0][1]/args.map_size_cm*48000),3,color='red')\n",
    "circ2 = Circle((trux[0]-120-(lmb[0,2]-120),truy[0]-120-(lmb[0,0]-120)),3,color='red')\n",
    "circ5 = Circle((goalx[0]-120-(lmb[0,2]-120),goaly[0]-120-(lmb[0,0]-120)),3,color='white')\n",
    "circ3 = Circle((trux[0],truy[0]),3,color='red')\n",
    "circ4 = Circle((goalx[0],goaly[0]),3,color='white')\n",
    "circ6 = Circle((stg[0],stg[1]),3,color='green')\n",
    "ax = f.add_subplot(241)\n",
    "ax2 = f.add_subplot(242)\n",
    "ax3 = f.add_subplot(243)\n",
    "ax4 = f.add_subplot(244)\n",
    "ax.imshow(global_input[0,0,:,:].cpu())\n",
    "ax.add_patch(circ)\n",
    "ax2.imshow(one_env.map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]])#nn.MaxPool2d(args.global_downscaling)(torch.from_numpy(one_env.map).unsqueeze_(0))[0])\n",
    "ax2.add_patch(circ2)\n",
    "ax2.add_patch(circ5)\n",
    "ax2.add_patch(circ6)\n",
    "ax3.imshow(one_env.explored_map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]])\n",
    "ax4.imshow(one_env.map)\n",
    "ax4.add_patch(circ3)\n",
    "ax4.add_patch(circ4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(goalx,goaly)\n",
    "print(goalx[0]-120-(lmb[0,2]-120),goaly[0]-120-(lmb[0,0]-120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_obs = obs_rgb.detach()\n",
    "local_masks = l_masks\n",
    "#local_goals = output[:, :-1].to(device).long()\n",
    "\n",
    "map_pred = one_env.map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]]\n",
    "exp_pred = one_env.explored_map[lmb[0,0]:lmb[0, 1],lmb[0, 2]:lmb[0, 3]]\n",
    "grid = np.rint(map_pred)\n",
    "explored = np.rint(exp_pred)\n",
    "start_x, start_y, start_o, gx1, gx2, gy1, gy2 = planner_pose_inputs[0]\n",
    "gx1, gx2, gy1, gy2 = int(gx1), int(gx2), int(gy1), int(gy2)\n",
    "planning_window = [gx1, gx2, gy1, gy2]\n",
    "    # Get last loc ground truth pose\n",
    "last_start_x, last_start_y = one_env.last_loc_gt[0], one_env.last_loc_gt[1]\n",
    "r, c = last_start_y, last_start_x\n",
    "last_start = [int(r * 100.0/args.map_resolution- gx1),\n",
    "              int(c * 100.0/args.map_resolution - gy1)]\n",
    "last_start = pu.threshold_poses(last_start, one_env.visited_gt.shape)\n",
    "# Get curr loc\n",
    "curr_loc = [start_x, start_y, start_o]\n",
    "r, c = start_y, start_x\n",
    "start = [int(r * 100.0/args.map_resolution - gx1),\n",
    "         int(c * 100.0/args.map_resolution - gy1)]\n",
    "start = pu.threshold_poses(start, grid.shape)\n",
    "#visited = np.copy(one_env.visited)\n",
    "one_env.visited[gx1:gx2, gy1:gy2][start[0]-2:start[0]+3,\n",
    "                                  start[1]-2:start[1]+3] = 1\n",
    "steps = 25\n",
    "#visited_vis = np.copy(one_env.visited_vis)\n",
    "for i in range(steps):\n",
    "    x = int(last_start[0] + (start[0] - last_start[0]) * (i+1) / steps)\n",
    "    y = int(last_start[1] + (start[1] - last_start[1]) * (i+1) / steps)\n",
    "    one_env.visited_vis[gx1:gx2, gy1:gy2][x, y] = 1\n",
    "# Get goal\n",
    "goal = np.copy(planner_inputs[0]['goal'])\n",
    "goal[0]= goal[0]-gy1\n",
    "goal[1]= goal[1]-gx1\n",
    "goal = pu.threshold_poses(goal, grid.shape)   \n",
    "print(start,goal,planning_window)\n",
    "#stg = one_env._get_stg(grid, explored, start, np.copy(goal), planning_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[gx1, gx2, gy1, gy2] = planning_window\n",
    "goale = np.copy(goal[:])\n",
    "\n",
    "print(start,goale,planning_window)   \n",
    "x1 = min(start[0], goale[0])\n",
    "x2 = max(start[0], goale[0])\n",
    "y1 = min(start[1], goale[1])\n",
    "y2 = max(start[1], goale[1])\n",
    "\n",
    "dist = pu.get_l2_distance(goale[0], start[0], goale[1], start[1])\n",
    "buf = max(20., dist)\n",
    "x1 = max(1, int(x1 - buf))\n",
    "x2 = min(grid.shape[0]-1, int(x2 + buf))\n",
    "y1 = max(1, int(y1 - buf))\n",
    "y2 = min(grid.shape[1]-1, int(y2 + buf))\n",
    "\n",
    "rows = explored.sum(1)\n",
    "rows[rows>0] = 1\n",
    "ex1 = np.argmax(rows)\n",
    "ex2 = len(rows) - np.argmax(np.flip(rows))\n",
    "\n",
    "cols = explored.sum(0)\n",
    "cols[cols>0] = 1\n",
    "ey1 = np.argmax(cols)\n",
    "ey2 = len(cols) - np.argmax(np.flip(cols))\n",
    "\n",
    "ex1 = min(int(start[0]) - 2, ex1)\n",
    "ex2 = max(int(start[0]) + 2, ex2)\n",
    "ey1 = min(int(start[1]) - 2, ey1)\n",
    "ey2 = max(int(start[1]) + 2, ey2)\n",
    "\n",
    "x1 = max(x1, ex1)\n",
    "x2 = min(x2, ex2)\n",
    "y1 = max(y1, ey1)\n",
    "y2 = min(y2, ey2)\n",
    "print(x1,y1,x2,y2,' X!Y!')\n",
    "traversible = skimage.morphology.binary_dilation(grid[x1:x2, y1:y2],one_env.selem) != True\n",
    "#traversible[one_env.collison_map[gx1:gx2, gy1:gy2][x1:x2, y1:y2] == 1] = 0\n",
    "traversible[one_env.visited[gx1:gx2, gy1:gy2][x1:x2, y1:y2] == 1] = 1\n",
    "traversible[int(start[0]-x1)-1:int(start[0]-x1)+2,\n",
    "                    int(start[1]-y1)-1:int(start[1]-y1)+2] = 1\n",
    "print(goale[0],goale[1],x1,x2,y1,y2,' GOAL X12!Y12!')\n",
    "if goale[0]-2 > y1 and goale[0]+3 < y2\\\n",
    "    and goale[1]-2 > x1 and goale[1]+3 < x2:\n",
    "    traversible[int(goale[0]-y1)-2:int(goale[0]-y1)+3,\n",
    "            int(goale[1]-x1)-2:int(goale[1]-x1)+3] = 1\n",
    "else:\n",
    "    goale[0] = min(max(y1, goale[0]), y2)\n",
    "    goale[1] = min(max(x1, goale[1]), x2)\n",
    "print(goale,' GOAL INIT')    \n",
    "def add_boundary(mat):\n",
    "    h, w = mat.shape\n",
    "    new_mat = np.ones((h+2,w+2))\n",
    "    new_mat[1:h+1,1:w+1] = mat\n",
    "    return new_mat\n",
    "\n",
    "#plt.imshow(traversible)\n",
    "f = plt.figure(figsize=(15,10))\n",
    "\n",
    "traversible = add_boundary(traversible)  \n",
    "print(goale[0]-y1+1,goale[1]-x1+1, ' given goal')\n",
    "\n",
    "planner = FMMPlanner(traversible, 360//one_env.dt)\n",
    "\n",
    "reachable = planner.set_goal([goale[0]-y1+1,goale[1]-x1+1])\n",
    "stg_x, stg_y =  start[0] - y1 + 1,start[1] - x1 + 1\n",
    "\n",
    "for i in range(one_env.args.short_goal_dist):\n",
    "    print([stg_x, stg_y], ' given start')\n",
    "    stg_x, stg_y, replan = planner.get_short_term_goal([stg_y, stg_x])\n",
    "    print([stg_y, stg_x],' short res goal')\n",
    "    circ111 = Circle((stg_y,stg_x),3,color='green')\n",
    "if replan:\n",
    "    stg_x, stg_y = start[0], start[1]\n",
    "else:\n",
    "    stg_x, stg_y = stg_y + x1 - 1, stg_x + y1 - 1\n",
    "print([stg_x, stg_y])  \n",
    "\n",
    "print(start[0]-y1+1,start[1]-x1+1,' start')\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "circ22 = Circle((goale[0]-y1+1,goale[1]-x1+1),3,color='white')\n",
    "circ33 = Circle((start[0]-y1+1,start[1]-x1+1),3,color='red')\n",
    "ax = f.add_subplot(241)\n",
    "ax.imshow(traversible)\n",
    "ax.add_patch(circ111)\n",
    "ax.add_patch(circ22)\n",
    "ax.add_patch(circ33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(sx, sy, scale, step_size):\n",
    "    size = int(step_size // scale) * 2 + 1\n",
    "    mask = np.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if ((i + 0.5) - (size // 2 + sx)) ** 2 + ((j + 0.5) - (size // 2 + sy)) ** 2 <= \\\n",
    "                    step_size ** 2:\n",
    "                mask[i, j] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_dist(sx, sy, scale, step_size):\n",
    "    size = int(step_size // scale) * 2 + 1\n",
    "    mask = np.zeros((size, size)) + 1e-10\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if ((i + 0.5) - (size // 2 + sx)) ** 2 + ((j + 0.5) - (size // 2 + sy)) ** 2 <= \\\n",
    "                    step_size ** 2:\n",
    "                mask[i, j] = max(5, (((i + 0.5) - (size // 2 + sx)) ** 2 +\n",
    "                                     ((j + 0.5) - (size // 2 + sy)) ** 2) ** 0.5)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.copy(np.array([start[1] - x1 + 1,start[0] - y1 + 1]))\n",
    "print(state)\n",
    "scale = planner.scale * 1.\n",
    "state = [x / scale for x in state]\n",
    "\n",
    "planner.du = 5\n",
    "planner.step_size = 5\n",
    "dx, dy = state[0] - int(state[0]), state[1] - int(state[1])\n",
    "mask = get_mask(dx, dy, scale, planner.step_size)\n",
    "dist_mask = get_dist(dx, dy, scale, planner.step_size)\n",
    "\n",
    "state = [int(x) for x in state]\n",
    "\n",
    "\n",
    "\n",
    "dist = np.pad(planner.fmm_dist, planner.du,\n",
    "              'constant', constant_values=planner.fmm_dist.shape[0] ** 2)\n",
    "subset = dist[state[0]:state[0] + 2 * planner.du + 1,\n",
    "         state[1]:state[1] + 2 * planner.du + 1]\n",
    "\n",
    "\n",
    "assert subset.shape[0] == 2 * planner.du + 1 and \\\n",
    "       subset.shape[1] == 2 * planner.du + 1, \\\n",
    "    \"Planning error: unexpected subset shape {}\".format(subset.shape)\n",
    "\n",
    "subset *= mask\n",
    "subset += (1 - mask) * planner.fmm_dist.shape[0] ** 2\n",
    "subset -= subset[planner.du, planner.du]\n",
    "ratio1 = subset / dist_mask\n",
    "subset[ratio1 < -1.5] = 1\n",
    "\n",
    "\n",
    "trav = np.pad(planner.traversible, planner.du,\n",
    "                      'constant', constant_values=0)\n",
    "                      \n",
    "\n",
    "subset_trav = trav[state[0]:state[0] + 2 * planner.du + 1,\n",
    "              state[1]:state[1] + 2 * planner.du + 1]\n",
    "#\"\"\"             \n",
    "traversible_ma = np.ma.masked_values(subset_trav * 1, 0)\n",
    "\n",
    "goal_x, goal_y = planner.du+5, planner.du+5\n",
    "traversible_ma[goal_y, goal_x] = 0\n",
    "dd = skfmm.distance(traversible_ma, dx=1)\n",
    "\n",
    "dd_mask = np.invert(np.isnan(np.ma.filled(dd, np.nan)))\n",
    "\n",
    "dd = np.ma.filled(dd, np.max(dd) + 1)\n",
    " \n",
    "subset_fmm_dist = dd\n",
    "\n",
    "\n",
    "subset_fmm_dist[subset_fmm_dist < 4] = 4.\n",
    "subset = subset / subset_fmm_dist\n",
    "subset[subset < -1.5] = 1\n",
    "(stg_x, stg_y) = np.unravel_index(np.argmin(subset), subset.shape)\n",
    "print((stg_x + state[0] - planner.du) * scale + 0.5, \\\n",
    "               (stg_y + state[1] - planner.du) * scale + 0.5)\n",
    "#\"\"\"               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(planner.fmm_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traversible = skimage.morphology.binary_dilation(grid[x1:x2, y1:y2],one_env.selem) != True\n",
    "traversible[one_env.collison_map[gx1:gx2, gy1:gy2][x1:x2, y1:y2] == 1] = 0\n",
    "traversible[one_env.visited[gx1:gx2, gy1:gy2][x1:x2, y1:y2] == 1] = 1\n",
    "traversible[int(start[0]-x1)-1:int(start[0]-x1)+2,\n",
    "                    int(start[1]-y1)-1:int(start[1]-y1)+2] = 1\n",
    "plt.imshow(traversible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(one_env.visited[gx1:gx2, gy1:gy2][y1:y2, x1:x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output[2].numpy().astype(int))\n",
    "#print(short_goal)\n",
    "f = plt.figure(figsize=(15,10))\n",
    "ax = f.add_subplot(131)\n",
    "ax2 = f.add_subplot(132)\n",
    "ax3 = f.add_subplot(133)\n",
    "circ = Circle((trux[0],truy[0]),3,color='white')\n",
    "circ2 = Circle((goalx[0],goaly[0]),3,color='red')\n",
    "#circ3 = Circle((short_goal[0],short_goal[1]),3,color='green')\n",
    "circ4 = Circle((trux[0],truy[0]),3,color='white')\n",
    "circ5 = Circle((goalx[0],goaly[0]),3,color='red')\n",
    "#circ6 = Circle((short_goal[0],short_goal[1]),3,color='green')\n",
    "ax.imshow(local_map[0][0].cpu())\n",
    "ax2.imshow(obs['rgb'][0])\n",
    "ax3.imshow(nn.MaxPool2d(args.global_downscaling)(torch.from_numpy(envs_map).unsqueeze_(0))[0])\n",
    "ax.add_patch(circ)\n",
    "ax.add_patch(circ2)\n",
    "#ax.add_patch(circ3)\n",
    "ax3.add_patch(circ4)\n",
    "ax3.add_patch(circ5)\n",
    "#ax3.add_patch(circ6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = one_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    obs, reward, done, info = one_env.step(action=2)\n",
    "draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pred = one_env.map\n",
    "exp_pred = one_env.explored_map\n",
    "grid = np.rint(map_pred)\n",
    "explored = np.rint(exp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, reward, done, info = one_env.step(action=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    best_action = follower.get_next_action(one_env.habitat_env.current_episode.goals[0].position)\n",
    "    if best_action==0 or best_action==None:\n",
    "        print('DONE')\n",
    "        break\n",
    "    obs, reward, done, info = one_env.step(action=best_action)\n",
    "    print(reward)\n",
    "    print(best_action)\n",
    "draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test multiple env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_map_and_pose(done):\n",
    "    full_map[[done]].fill_(0.)\n",
    "    full_pose[[done]].fill_(0.)\n",
    "    full_pose[done, :2] = args.map_size_cm / 100.0 / 2.0\n",
    "\n",
    "    locs = full_pose.cpu().numpy()\n",
    "    planner_pose_inputs[done, :3] = locs[done]\n",
    "    for e in done:\n",
    "        r, c = locs[e, 1], locs[e, 0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        full_map[e, 2:, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.0\n",
    "\n",
    "        lmb[e] = get_local_map_boundaries((loc_r, loc_c),\n",
    "                                          (local_w, local_h),\n",
    "                                          (full_w, full_h), args)\n",
    "\n",
    "        planner_pose_inputs[e, 3:] = lmb[e]\n",
    "        origins[e] = [lmb[e][2] * args.map_resolution / 100.0,\n",
    "                      lmb[e][0] * args.map_resolution / 100.0, 0.]\n",
    "\n",
    "    for e in done:\n",
    "        local_map[e] = full_map[e, :, lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]]\n",
    "        local_pose[e] = full_pose[e] - \\\n",
    "                        torch.from_numpy(origins[e]).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = VectorEnv(\n",
    "    env_fn_args=tuple(\n",
    "        tuple(zip(args_list, env_configs,\n",
    "            range(args.num_processes)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = args.device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "l_observation_space = gym.spaces.Box(0, 255,\n",
    "                                     (3,\n",
    "                                      args.frame_width,\n",
    "                                      args.frame_width), dtype='uint8')\n",
    "l_hidden_size = args.local_hidden_size\n",
    "# slam\n",
    "nslam_module = Neural_SLAM_Module(args).to(device)\n",
    "# Local policy\n",
    "l_policy = Local_IL_Policy(l_observation_space.shape, envs.action_spaces[0].n,\n",
    "                           recurrent=args.use_recurrent_local,\n",
    "                           hidden_size=l_hidden_size,\n",
    "                           deterministic=args.use_deterministic_local).to(device)\n",
    "state_dict = torch.load('./periodic_608.slam',\n",
    "                            map_location=lambda storage, loc: storage)\n",
    "nslam_module.load_state_dict(state_dict)\n",
    "state_dict = torch.load('./periodic_608.local',\n",
    "                            map_location=lambda storage, loc: storage)\n",
    "l_policy.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_scenes = args.num_processes\n",
    "map_size = args.map_size_cm // args.map_resolution\n",
    "full_w, full_h = map_size, map_size\n",
    "local_w, local_h = int(full_w / args.global_downscaling), \\\n",
    "                   int(full_h / args.global_downscaling)\n",
    "    # Initializing full and local map\n",
    "full_map = torch.zeros(num_scenes, 4, full_w, full_h).float().to(device)\n",
    "local_map = torch.zeros(num_scenes, 4, local_w, local_h).float().to(device)\n",
    "    # Initial full and local pose\n",
    "full_pose = torch.zeros(num_scenes, 3).float().to(device)\n",
    "local_pose = torch.zeros(num_scenes, 3).float().to(device)\n",
    "    # Origin of local map\n",
    "origins = np.zeros((num_scenes, 3))\n",
    "    # Local Map Boundaries\n",
    "lmb = np.zeros((num_scenes, 4)).astype(int)\n",
    "planner_pose_inputs = np.zeros((num_scenes, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, infos = envs.reset()\n",
    "done = [True for i in range(num_scenes)]\n",
    "dones = [i for ii,i in enumerate(range(num_scenes)) if done[ii]]\n",
    "init_map_and_pose(dones)\n",
    "poses = torch.from_numpy(np.asarray(\n",
    "    [infos[env_idx]['sensor_pose'] for env_idx\n",
    "     in range(num_scenes)])).float().to(device)\n",
    "obs_rgb = torch.from_numpy(np.array([i['rgb'] for i in obs])).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, local_map[:, 0, :, :], local_map[:, 1, :, :], _, local_pose = \\\n",
    "    nslam_module(obs_rgb, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                 local_map[:, 1, :, :], local_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Global policy input\n",
    "locs = local_pose.cpu().numpy()\n",
    "global_input = torch.zeros(num_scenes, 8, local_w, local_h)\n",
    "global_orientation = torch.zeros(num_scenes, 1).long()\n",
    "\n",
    "for e in range(num_scenes):\n",
    "    r, c = locs[e, 1], locs[e, 0]\n",
    "    loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                    int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "    local_map[e, 2:, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.\n",
    "    global_orientation[e] = int((locs[e, 2] + 180.0) / 5.)\n",
    "\n",
    "global_input[:, 0:4, :, :] = local_map.detach()\n",
    "global_input[:, 4:, :, :] = nn.MaxPool2d(args.global_downscaling)(full_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_SPACE_COMMAND = ['trux','truy','goalx','goaly']\n",
    "for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "    for write_fn in envs._connection_write_fns:\n",
    "        write_fn((command, None))\n",
    "    OBSERVATION_SPACE_COMMAND[i] = [(read_fn()+12)/args.map_size_cm*48000 for read_fn in envs._connection_read_fns]\n",
    "trux,truy,goalx,goaly = OBSERVATION_SPACE_COMMAND\n",
    "global_goals = [[int(goalx[i]),int(goaly[i])] for i in range(len(goalx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_SPACE_COMMAND = ['explored_map','map']\n",
    "for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "    for write_fn in envs._connection_write_fns:\n",
    "        write_fn((command, None))\n",
    "    OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns]\n",
    "explored_map,envs_map = OBSERVATION_SPACE_COMMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute planner inputs\n",
    "planner_inputs = [{} for e in range(num_scenes)]\n",
    "for e, p_input in enumerate(planner_inputs):\n",
    "    p_input['goal'] = global_goals[e]\n",
    "    p_input['map_pred'] = envs_map[e][lmb[e,0]:lmb[e,1],lmb[e,2]:lmb[e,3]]#global_input[e, 0, :, :].detach().cpu().numpy()\n",
    "    p_input['exp_pred'] = explored_map[e][lmb[e,0]:lmb[e,1],lmb[e,2]:lmb[e,3]]#global_input[e, 1, :, :].detach().cpu().numpy()\n",
    "    p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "local_rec_states = torch.zeros(num_scenes, l_hidden_size).to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,10))\n",
    "ax = f.add_subplot(131)\n",
    "ax2 = f.add_subplot(132)\n",
    "ax3 = f.add_subplot(133)\n",
    "circ = Circle((trux[0],truy[0]),3,color='black')\n",
    "circ2 = Circle((goalx[0],goaly[0]),3,color='red')\n",
    "#circ3 = Circle((short_goal[0][0],short_goal[0][1]),3,color='white')\n",
    "circ4 = Circle((trux[0]*2,truy[0]*2),3,color='black')\n",
    "circ5 = Circle((goalx[0]*2,goaly[0]*2),3,color='red')\n",
    "ax.imshow(local_map[0][0].cpu())\n",
    "ax2.imshow(obs[0]['rgb'][0])\n",
    "ax3.imshow(planner_inputs[0]['map_pred'])\n",
    "ax.add_patch(circ)\n",
    "ax.add_patch(circ2)\n",
    "#ax.add_patch(circ3)\n",
    "ax3.add_patch(circ4)\n",
    "ax3.add_patch(circ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_SPACE_COMMAND = ['start_240_240','goal_240_240']\n",
    "for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "    for write_fn in envs._connection_write_fns:\n",
    "        write_fn((command, None))\n",
    "    OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns] \n",
    "start = OBSERVATION_SPACE_COMMAND[0]\n",
    "goal = OBSERVATION_SPACE_COMMAND[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = [0.]\n",
    "spls = [0.]\n",
    "for i in range(10):\n",
    "    #l_action =[3,3,3,3]\n",
    "    output = envs.get_short_term_goal(planner_inputs)\n",
    "    l_action=output[:,2].astype(int)\n",
    "    last_obs = obs_rgb.detach()\n",
    "    \n",
    "    \n",
    "    for n in [ii for ii,i in enumerate(l_action) if l_action[ii]==0]:\n",
    "        full_map[n] = torch.zeros(1, 4, full_w, full_h).float().to(device)\n",
    "        local_map[n] = torch.zeros(1, 4, local_w, local_h).float().to(device)\n",
    "        full_pose[n] = torch.zeros(1, 3).float().to(device)\n",
    "        local_pose[n] = torch.zeros(1, 3).float().to(device)\n",
    "    \n",
    "    obs, rew, done, infos = envs.step(l_action)\n",
    "    \n",
    "    OBSERVATION_SPACE_COMMAND = ['start_240_240','goal_240_240']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns] \n",
    "    start = OBSERVATION_SPACE_COMMAND[0]\n",
    "    goal = OBSERVATION_SPACE_COMMAND[1]\n",
    "    \n",
    "    dones = [i for ii,i in enumerate(range(num_scenes)) if done[ii]]\n",
    "    if len(dones)>0:\n",
    "                \n",
    "        init_map_and_pose(dones)\n",
    "        success += [i['success'] for ii,i in enumerate(infos) if ii in dones]\n",
    "        spls += [i['spl'] for ii,i in enumerate(infos) if ii in dones]\n",
    "        print(np.mean(success),np.mean(spls))\n",
    "        \n",
    "        poses = torch.from_numpy(np.asarray(\n",
    "                    [infos[env_idx]['sensor_pose'] for env_idx\n",
    "                     in range(num_scenes)])).float().to(device)\n",
    "        obs_rgb = torch.from_numpy(np.array([i['rgb'] for i in obs])).float().to(device)\n",
    "\n",
    "        local_map_restart = local_map.clone()\n",
    "        local_pose_restart = local_pose.clone()\n",
    "\n",
    "        _, _, local_map_restart[:, 0, :, :], local_map_restart[:, 1, :, :], _, local_pose_restart = \\\n",
    "            nslam_module(obs_rgb, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                         local_map[:, 1, :, :], local_pose)\n",
    "\n",
    "\n",
    "        locs = local_pose_restart.cpu().numpy()\n",
    "\n",
    "        for e in dones:\n",
    "            r, c = locs[e, 1], locs[e, 0]\n",
    "            loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                            int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "            local_map_restart[e, 2:, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.\n",
    "            global_orientation[e] = int((locs[e, 2] + 180.0) / 5.)\n",
    "        global_input[dones, 0:4, :, :] = local_map_restart[dones].detach().cpu()\n",
    "        global_input[dones, 4:, :, :] = nn.MaxPool2d(args.global_downscaling)(full_map[dones]).cpu()\n",
    "        OBSERVATION_SPACE_COMMAND = ['trux','truy','goalx','goaly']\n",
    "        for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "            for write_fn in envs._connection_write_fns:\n",
    "                write_fn((command, None))\n",
    "            OBSERVATION_SPACE_COMMAND[i] = [(read_fn()+12)/args.map_size_cm*48000 for read_fn in envs._connection_read_fns]\n",
    "        trux,truy,goalx,goaly = OBSERVATION_SPACE_COMMAND\n",
    "        global_goals = [[int(goalx[i]),int(goaly[i])] for i in range(len(goalx))]\n",
    "\n",
    "\n",
    "        #planner_inputs = [{} for e in dones]\n",
    "        for e, p_input in enumerate(planner_inputs):\n",
    "            if e in dones:\n",
    "                p_input['goal'] = global_goals[e]\n",
    "                p_input['map_pred'] = global_input[e, 0, :, :].detach().cpu().numpy()\n",
    "                p_input['exp_pred'] = global_input[e, 1, :, :].detach().cpu().numpy()\n",
    "                p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "\n",
    "\n",
    "    #       last_obs = obs_rgb.detach()\n",
    "        local_rec_states[dones] = torch.zeros(len(dones), l_hidden_size).to(device)\n",
    "        \n",
    "        \n",
    "    obs_rgb = torch.from_numpy(np.array([i['rgb'] for i in obs])).float().to(device)\n",
    "    OBSERVATION_SPACE_COMMAND = ['trux','truy','goalx','goaly']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [(read_fn()+12)/args.map_size_cm*48000 for read_fn in envs._connection_read_fns]\n",
    "    trux,truy,goalx,goaly = OBSERVATION_SPACE_COMMAND\n",
    "    global_goals = [[int(goalx[i]),int(goaly[i])] for i in range(len(goalx))]\n",
    "    l_masks = torch.FloatTensor([0 if x else 1 for x in done]).to(device)\n",
    "    poses = torch.from_numpy(np.asarray(\n",
    "                    [infos[env_idx]['sensor_pose'] for env_idx\n",
    "                     in range(num_scenes)])).float().to(device)\n",
    "\n",
    "    _, _, local_map[:, 0, :, :], local_map[:, 1, :, :], _, local_pose = \\\n",
    "            nslam_module(last_obs, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                         local_map[:, 1, :, :], local_pose, build_maps=True)\n",
    "    locs = local_pose.cpu().numpy()\n",
    "    planner_pose_inputs[:, :3] = locs + origins\n",
    "    local_map[:, 2, :, :].fill_(0.)  # Resetting current location channel\n",
    "    for e in range(num_scenes):\n",
    "        r, c = locs[e, 1], locs[e, 0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        local_map[e, 2:, loc_r - 2:loc_r + 3, loc_c - 2:loc_c + 3] = 1.\n",
    "    # ------------------------------------------------------------------\n",
    "    #\"\"\"\n",
    "    for e in range(num_scenes):\n",
    "        full_map[e, :, lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]] = \\\n",
    "            local_map[e]\n",
    "        full_pose[e] = local_pose[e] + \\\n",
    "                       torch.from_numpy(origins[e]).to(device).float()\n",
    "        locs = full_pose[e].cpu().numpy()\n",
    "        r, c = locs[1], locs[0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        lmb[e] = get_local_map_boundaries((loc_r, loc_c),\n",
    "                                          (local_w, local_h),\n",
    "                                          (full_w, full_h), args)\n",
    "\n",
    "        planner_pose_inputs[e, 3:] = lmb[e]\n",
    "        origins[e] = [lmb[e][2] * args.map_resolution / 100.0,\n",
    "                      lmb[e][0] * args.map_resolution / 100.0, 0.]\n",
    "\n",
    "        local_map[e] = full_map[e, :,\n",
    "                       lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]]\n",
    "        local_pose[e] = full_pose[e] - \\\n",
    "                        torch.from_numpy(origins[e]).to(device).float()\n",
    "    locs = local_pose.cpu().numpy()\n",
    "    for e in range(num_scenes):\n",
    "        global_orientation[e] = int((locs[e, 2] + 180.0) / 5.)\n",
    "    global_input[:, 0:4, :, :] = local_map\n",
    "    global_input[:, 4:, :, :] = \\\n",
    "        nn.MaxPool2d(args.global_downscaling)(full_map)\n",
    "    #\"\"\"    \n",
    "\n",
    "    # Get short term goal\n",
    "    planner_inputs = [{} for e in range(num_scenes)]\n",
    "    for e, p_input in enumerate(planner_inputs):\n",
    "        p_input['map_pred'] = envs_map[e][lmb[e,0]:lmb[e,1],lmb[e,2]:lmb[e,3]]#local_map[e, 0, :, :].cpu().numpy()\n",
    "        p_input['exp_pred'] = explored_map[e][lmb[e,0]:lmb[e,1],lmb[e,2]:lmb[e,3]]#local_map[e, 1, :, :].cpu().numpy()\n",
    "        p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "        p_input['goal'] = global_goals[e]\n",
    "\n",
    "\n",
    "    OBSERVATION_SPACE_COMMAND = ['explored_map','map']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns]\n",
    "    explored_map,envs_map = OBSERVATION_SPACE_COMMAND\n",
    "\n",
    "    print(output[:,2].astype(int))\n",
    "    print(output[:,1])\n",
    "    f = plt.figure(figsize=(15,10))\n",
    "    ax = f.add_subplot(231)\n",
    "    ax2 = f.add_subplot(232)\n",
    "    ax3 = f.add_subplot(233)\n",
    "    circ = Circle((start[0][0],start[0][1]),3,color='white')\n",
    "    circ2 = Circle((goal[0][0],goal[0][1]),3,color='red')\n",
    "    #circ3 = Circle((short_goal[0][0],short_goal[0][1]),3,color='green')\n",
    "    circ4 = Circle((start[0][0],start[0][1]),3,color='white')\n",
    "    circ5 = Circle((goal[0][0],goal[0][1]),3,color='red')\n",
    "    #circ6 = Circle((short_goal[0][0],short_goal[0][1]),3,color='green')\n",
    "    ax.imshow(local_map[0][0].cpu())\n",
    "    ax2.imshow(obs[0]['rgb'][0])\n",
    "    ax3.imshow(envs_map[0][lmb[0,0]:lmb[0,1],lmb[0,2]:lmb[0,3]])\n",
    "    ax.add_patch(circ)\n",
    "    ax.add_patch(circ2)\n",
    "    #ax.add_patch(circ3)\n",
    "    ax3.add_patch(circ4)\n",
    "    ax3.add_patch(circ5)\n",
    "    #ax3.add_patch(circ6)\n",
    "\n",
    "    ax1 = f.add_subplot(234)\n",
    "    ax21 = f.add_subplot(235)\n",
    "    ax31 = f.add_subplot(236)\n",
    "    circ1 = Circle((start[1][0],start[1][1]),3,color='white')\n",
    "    circ21 = Circle((goal[1][0],goal[1][1]),3,color='red')\n",
    "    #circ3 = Circle((short_goal[0][0],short_goal[0][1]),3,color='green')\n",
    "    circ41 = Circle((start[1][0],start[1][1]),3,color='white')\n",
    "    circ51 = Circle((goal[1][0],goal[1][1]),3,color='red')\n",
    "    #circ6 = Circle((short_goal[0][0],short_goal[0][1]),3,color='green')\n",
    "    ax1.imshow(local_map[1][1].cpu())\n",
    "    ax21.imshow(obs[1]['rgb'][0])\n",
    "    ax31.imshow(envs_map[1][lmb[1,0]:lmb[1,1],lmb[1,2]:lmb[1,3]])\n",
    "    ax1.add_patch(circ1)\n",
    "    ax1.add_patch(circ21)\n",
    "    #ax.add_patch(circ3)\n",
    "    ax31.add_patch(circ41)\n",
    "    ax31.add_patch(circ51)\n",
    "    #ax31.add_patch(circ6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_SPACE_COMMAND = ['stg']\n",
    "for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "    for write_fn in envs._connection_write_fns:\n",
    "        write_fn((command, None))\n",
    "    OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns]\n",
    "stg = OBSERVATION_SPACE_COMMAND[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_map_and_pose(done):\n",
    "    full_map[[done]]*=0.#.fill_(0.)\n",
    "    full_pose[[done]]*=0.#.fill_(0.)\n",
    "    full_pose[done, :2] = args.map_size_cm / 100.0 / 2.0\n",
    "\n",
    "    locs = full_pose.cpu().numpy()\n",
    "    planner_pose_inputs[done, :3] = locs[done]\n",
    "    for e in done:\n",
    "        r, c = locs[e, 1], locs[e, 0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        full_map[e, 2:, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.0\n",
    "\n",
    "        lmb[e] = get_local_map_boundaries((loc_r, loc_c),\n",
    "                                          (local_w, local_h),\n",
    "                                          (full_w, full_h), args)\n",
    "\n",
    "        planner_pose_inputs[e, 3:] = lmb[e]\n",
    "        origins[e] = [lmb[e][2] * args.map_resolution / 100.0,\n",
    "                      lmb[e][0] * args.map_resolution / 100.0, 0.]\n",
    "\n",
    "    for e in done:\n",
    "        local_map[e] = full_map[e, :, lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]]\n",
    "        local_pose[e] = full_pose[e] - \\\n",
    "                        torch.from_numpy(origins[e]).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = VectorEnv(\n",
    "    env_fn_args=tuple(\n",
    "        tuple(zip(args_list, env_configs,\n",
    "            range(args.num_processes)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = args.device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "l_observation_space = gym.spaces.Box(0, 255,\n",
    "                                     (3,\n",
    "                                      args.frame_width,\n",
    "                                      args.frame_width), dtype='uint8')\n",
    "l_hidden_size = args.local_hidden_size\n",
    "# slam\n",
    "nslam_module = Neural_SLAM_Module(args).to(device)\n",
    "# Local policy\n",
    "l_policy = Local_IL_Policy(l_observation_space.shape, envs.action_spaces[0].n,\n",
    "                           recurrent=args.use_recurrent_local,\n",
    "                           hidden_size=l_hidden_size,\n",
    "                           deterministic=args.use_deterministic_local).to(device)\n",
    "state_dict = torch.load('./periodic_12479.slam',\n",
    "                            map_location=lambda storage, loc: storage)\n",
    "nslam_module.load_state_dict(state_dict)\n",
    "state_dict = torch.load('./periodic_12479.local',\n",
    "                            map_location=lambda storage, loc: storage)\n",
    "l_policy.load_state_dict(state_dict)\n",
    "local_optimizer = get_optimizer(l_policy.parameters(),\n",
    "                                args.local_optimizer)\n",
    "slam_optimizer = get_optimizer(nslam_module.parameters(),\n",
    "                               args.slam_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_scenes = args.num_processes\n",
    "num_episodes = int(args.num_episodes)\n",
    "device = args.device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
    "policy_loss = 0\n",
    "\n",
    "best_cost = 100000\n",
    "costs = deque(maxlen=1000)\n",
    "exp_costs = deque(maxlen=1000)\n",
    "pose_costs = deque(maxlen=1000)\n",
    "\n",
    "g_masks = torch.ones(num_scenes).float().to(device)\n",
    "l_masks = torch.zeros(num_scenes).float().to(device)\n",
    "\n",
    "best_local_loss = np.inf\n",
    "best_g_reward = -np.inf\n",
    "\n",
    "if args.eval:\n",
    "    traj_lengths = args.max_episode_length // args.num_local_steps\n",
    "    explored_area_log = np.zeros((num_scenes, num_episodes, traj_lengths))\n",
    "    explored_ratio_log = np.zeros((num_scenes, num_episodes, traj_lengths))\n",
    "\n",
    "g_episode_rewards = deque(maxlen=1000)\n",
    "\n",
    "l_action_losses = deque(maxlen=1000)\n",
    "\n",
    "g_value_losses = deque(maxlen=1000)\n",
    "g_action_losses = deque(maxlen=1000)\n",
    "g_dist_entropies = deque(maxlen=1000)\n",
    "\n",
    "per_step_g_rewards = deque(maxlen=1000)\n",
    "\n",
    "g_process_rewards = np.zeros((num_scenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "map_size = args.map_size_cm // args.map_resolution\n",
    "full_w, full_h = map_size, map_size\n",
    "local_w, local_h = int(full_w / args.global_downscaling), \\\n",
    "                   int(full_h / args.global_downscaling)\n",
    "\n",
    "# Initializing full and local map\n",
    "full_map = torch.zeros(num_scenes, 4, full_w, full_h).float().to(device)\n",
    "local_map = torch.zeros(num_scenes, 4, local_w, local_h).float().to(device)\n",
    "\n",
    "# Initial full and local pose\n",
    "full_pose = torch.zeros(num_scenes, 3).float().to(device)\n",
    "local_pose = torch.zeros(num_scenes, 3).float().to(device)\n",
    "\n",
    "full_map.fill_(0.)\n",
    "full_pose.fill_(0.)\n",
    "\n",
    "# Origin of local map\n",
    "origins = np.zeros((num_scenes, 3))\n",
    "\n",
    "# Local Map Boundaries\n",
    "lmb = np.zeros((num_scenes, 4)).astype(int)\n",
    "planner_pose_inputs = np.zeros((num_scenes, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, infos = envs.reset()\n",
    "done = [True for i in range(num_scenes)]\n",
    "dones = [i for ii,i in enumerate(range(num_scenes)) if done[ii]]\n",
    "init_map_and_pose(dones)\n",
    "poses = torch.from_numpy(np.asarray(\n",
    "    [infos[env_idx]['sensor_pose'] for env_idx\n",
    "     in range(num_scenes)])).float().to(device)\n",
    "obs_rgb = torch.from_numpy(np.array([i['rgb'] for i in obs])).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global policy observation space\n",
    "g_observation_space = gym.spaces.Box(0, 1,\n",
    "                                     (8,\n",
    "                                      local_w,\n",
    "                                      local_h), dtype='uint8')\n",
    "# Global policy action space\n",
    "g_action_space = gym.spaces.Box(low=0.0, high=1.0,\n",
    "                                shape=(2,), dtype=np.float32)\n",
    "# Local policy observation space\n",
    "l_observation_space = gym.spaces.Box(0, 255,\n",
    "                                     (3,\n",
    "                                      args.frame_width,\n",
    "                                      args.frame_width), dtype='uint8')\n",
    "# Local and Global policy recurrent layer sizes\n",
    "l_hidden_size = args.local_hidden_size\n",
    "g_hidden_size = args.global_hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slam_memory = FIFOMemory(args.slam_memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict map from frame 1:\n",
    "poses = torch.from_numpy(np.asarray(\n",
    "    [infos[env_idx]['sensor_pose'] for env_idx\n",
    "     in range(num_scenes)])\n",
    ").float().to(device)\n",
    "\n",
    "obs_rgb = torch.from_numpy(np.array([i['rgb'] for i in obs])).float().to(device)\n",
    "_, _, local_map[:, 0, :, :], local_map[:, 1, :, :], _, local_pose = \\\n",
    "    nslam_module(obs_rgb, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                 local_map[:, 1, :, :], local_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Global policy input\n",
    "locs = local_pose.cpu().numpy()\n",
    "global_input = torch.zeros(num_scenes, 8, local_w, local_h)\n",
    "global_orientation = torch.zeros(num_scenes, 1).long()\n",
    "\n",
    "for e in range(num_scenes):\n",
    "    r, c = locs[e, 1], locs[e, 0]\n",
    "    loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                    int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "    local_map[e, 2:, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.\n",
    "    global_orientation[e] = int((locs[e, 2] + 180.0) / 5.)\n",
    "\n",
    "global_input[:, 0:4, :, :] = local_map.detach()\n",
    "global_input[:, 4:, :, :] = nn.MaxPool2d(args.global_downscaling)(full_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_SPACE_COMMAND = ['explored_map','map']\n",
    "for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "    for write_fn in envs._connection_write_fns:\n",
    "        write_fn((command, None))\n",
    "    OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns]\n",
    "explored_map,envs_map = OBSERVATION_SPACE_COMMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVATION_SPACE_COMMAND = ['trux','truy','goalx','goaly']\n",
    "for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "    for write_fn in envs._connection_write_fns:\n",
    "        write_fn((command, None))\n",
    "    OBSERVATION_SPACE_COMMAND[i] = [(read_fn()+12)/args.map_size_cm*48000 for read_fn in envs._connection_read_fns]\n",
    "trux,truy,goalx,goaly = OBSERVATION_SPACE_COMMAND\n",
    "global_goals = [[int(goalx[i]),int(goaly[i])] for i in range(len(goalx))]\n",
    "OBSERVATION_SPACE_COMMAND = ['start_240_240','goal_240_240']\n",
    "for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "    for write_fn in envs._connection_write_fns:\n",
    "        write_fn((command, None))\n",
    "    OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns] \n",
    "start = OBSERVATION_SPACE_COMMAND[0]\n",
    "goal = OBSERVATION_SPACE_COMMAND[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute planner inputs\n",
    "planner_inputs = [{} for e in range(num_scenes)]\n",
    "for e, p_input in enumerate(planner_inputs):\n",
    "    p_input['goal'] = global_goals[e]\n",
    "    p_input['map_pred'] = global_input[e, 0, :, :].detach().cpu().numpy()\n",
    "    p_input['exp_pred'] = global_input[e, 1, :, :].detach().cpu().numpy()\n",
    "    p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "    \n",
    "local_rec_states = torch.zeros(num_scenes, l_hidden_size).to(device) \n",
    "total_num_steps = -1\n",
    "g_reward = 0\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "writer = TensorboardWriter('./tb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "    if type(h) == Variable:\n",
    "        return Variable(h.data)\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "step = 0\n",
    "start = time.time()\n",
    "list_suc = []\n",
    "list_spl = []\n",
    "for ep_num in range(num_episodes*args.max_episode_length):\n",
    "    step+=1\n",
    "    total_num_steps += 1\n",
    "    g_step = (step // args.num_local_steps) % args.num_global_steps\n",
    "    eval_g_step = step // args.num_local_steps + 1\n",
    "    l_step = step % args.num_local_steps\n",
    "    \n",
    "    \n",
    "    last_obs = obs_rgb.detach()\n",
    "    output = envs.get_short_term_goal(planner_inputs)\n",
    "    l_action=output[:,2].astype(int)\n",
    "    \n",
    "    local_masks = l_masks\n",
    "    local_goals = torch.from_numpy(output[:, :-1]).to(device).long()\n",
    "    if args.train_local:\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "    action, action_prob, local_rec_states = l_policy(\n",
    "            obs_rgb,\n",
    "            local_rec_states,\n",
    "            local_masks,\n",
    "            extras=local_goals)\n",
    "    \n",
    "   # if args.train_local:\n",
    "    action_target = torch.from_numpy(np.array(l_action)).long().to(device)\n",
    "    policy_loss += nn.CrossEntropyLoss()(action_prob, action_target)\n",
    "    torch.set_grad_enabled(False)\n",
    "            \n",
    "    # ------------------------------------------------------------------\n",
    "    # Train Local Policy\n",
    "  #  if (l_step + 1) % args.local_policy_update_freq == 0 \\\n",
    "  #          and args.train_local:\n",
    "    local_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    local_optimizer.step()\n",
    "    l_action_losses.append(policy_loss.item())\n",
    "    policy_loss = 0\n",
    "    local_rec_states = local_rec_states.detach_()\n",
    "    # ------------------------------------------------------------------      \n",
    "    \n",
    "    obs, rew, done, infos = envs.step(l_action)\n",
    "     \n",
    "    \n",
    "        \n",
    "    obs_rgb = torch.from_numpy(np.array([i['rgb'] for i in obs])).float().to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    OBSERVATION_SPACE_COMMAND = ['trux','truy','goalx','goaly']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [(read_fn()+12)/args.map_size_cm*48000 for read_fn in envs._connection_read_fns]\n",
    "    trux,truy,goalx,goaly = OBSERVATION_SPACE_COMMAND\n",
    "    global_goals = [[int(goalx[i]),int(goaly[i])] for i in range(len(goalx))]   \n",
    "    \n",
    "    l_masks = torch.FloatTensor([0 if x else 1 for x in done]).to(device)\n",
    "    g_masks *= l_masks\n",
    "    \n",
    "    for ii,i in enumerate(l_action):\n",
    "        if i==0:\n",
    "            last_obs[ii]=obs_rgb[ii].detach()\n",
    "            \n",
    "    dones = [i for ii,i in enumerate(range(num_scenes)) if done[ii]]\n",
    "    if len(dones)>0:    \n",
    "        print(dones)\n",
    "        init_map_and_pose(dones)\n",
    "        local_rec_states[dones] = local_rec_states[dones]*0        \n",
    "    \n",
    "    # Neural SLAM Module\n",
    "    if args.train_slam:\n",
    "        # Add frames to memory\n",
    "        for env_idx in range(num_scenes):\n",
    "            env_obs = obs_rgb[env_idx].to(\"cpu\")\n",
    "            env_poses = torch.from_numpy(np.asarray(\n",
    "                infos[env_idx]['sensor_pose']\n",
    "            )).float().to(\"cpu\")\n",
    "            env_gt_fp_projs = torch.from_numpy(np.asarray(\n",
    "                infos[env_idx]['fp_proj']\n",
    "            )).unsqueeze(0).float().to(\"cpu\")\n",
    "            env_gt_fp_explored = torch.from_numpy(np.asarray(\n",
    "                infos[env_idx]['fp_explored']\n",
    "            )).unsqueeze(0).float().to(\"cpu\")\n",
    "            env_gt_pose_err = torch.from_numpy(np.asarray(\n",
    "                infos[env_idx]['pose_err']\n",
    "            )).float().to(\"cpu\")\n",
    "            slam_memory.push(\n",
    "                (last_obs[env_idx].cpu(), env_obs, env_poses),\n",
    "                (env_gt_fp_projs, env_gt_fp_explored, env_gt_pose_err))\n",
    "    \n",
    "    \n",
    "    \n",
    "    poses = torch.from_numpy(np.asarray(\n",
    "            [infos[env_idx]['sensor_pose'] for env_idx\n",
    "             in range(num_scenes)])).float().to(device)\n",
    "\n",
    "    _, _, local_map[:, 0, :, :], local_map[:, 1, :, :], _, local_pose = \\\n",
    "            nslam_module(last_obs, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                         local_map[:, 1, :, :], local_pose, build_maps=True)\n",
    "\n",
    "    locs = local_pose.cpu().numpy()\n",
    "    planner_pose_inputs[:, :3] = locs + origins\n",
    "    local_map[:, 2, :, :].fill_(0.)  # Resetting current location channel\n",
    "    for e in range(num_scenes):\n",
    "        r, c = locs[e, 1], locs[e, 0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        local_map[e, 2:, loc_r - 2:loc_r + 3, loc_c - 2:loc_c + 3] = 1.\n",
    "    # ------------------------------------------------------------------\n",
    "    for e in range(num_scenes):\n",
    "        full_map[e, :, lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]] = \\\n",
    "            local_map[e]\n",
    "        full_pose[e] = local_pose[e] + \\\n",
    "                       torch.from_numpy(origins[e]).to(device).float()\n",
    "\n",
    "        locs = full_pose[e].cpu().numpy()\n",
    "        r, c = locs[1], locs[0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "        lmb[e] = get_local_map_boundaries((loc_r, loc_c),\n",
    "                                          (local_w, local_h),\n",
    "                                          (full_w, full_h), args)\n",
    "        planner_pose_inputs[e, 3:] = lmb[e]\n",
    "        origins[e] = [lmb[e][2] * args.map_resolution / 100.0,\n",
    "                      lmb[e][0] * args.map_resolution / 100.0, 0.]\n",
    "        local_map[e] = full_map[e, :,\n",
    "                       lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]]\n",
    "        local_pose[e] = full_pose[e] - \\\n",
    "                        torch.from_numpy(origins[e]).to(device).float()\n",
    "\n",
    "    locs = local_pose.cpu().numpy()\n",
    "    for e in range(num_scenes):\n",
    "        global_orientation[e] = int((locs[e, 2] + 180.0) / 5.)\n",
    "    global_input[:, 0:4, :, :] = local_map\n",
    "    global_input[:, 4:, :, :] = \\\n",
    "        nn.MaxPool2d(args.global_downscaling)(full_map)\n",
    "\n",
    "    # Get short term goal\n",
    "    planner_inputs = [{} for e in range(num_scenes)]\n",
    "    for e, p_input in enumerate(planner_inputs):\n",
    "        p_input['map_pred'] = envs_map[e][lmb[e,0]:lmb[e,1],lmb[e,2]:lmb[e,3]]#local_map[e, 0, :, :].cpu().numpy()\n",
    "        p_input['exp_pred'] = explored_map[e][lmb[e,0]:lmb[e,1],lmb[e,2]:lmb[e,3]]#local_map[e, 1, :, :].cpu().numpy()\n",
    "        p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "        p_input['goal'] = global_goals[e]\n",
    "        \n",
    "        \n",
    "    OBSERVATION_SPACE_COMMAND = ['explored_map','map']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns]\n",
    "    explored_map,envs_map = OBSERVATION_SPACE_COMMAND\n",
    "    \n",
    "    ### TRAINING\n",
    "    torch.set_grad_enabled(True)\n",
    "    # Train Neural SLAM Module\n",
    "    if args.train_slam and len(slam_memory) > args.slam_batch_size:\n",
    "        for _ in range(args.slam_iterations):\n",
    "            inputs, outputs = slam_memory.sample(args.slam_batch_size)\n",
    "            b_obs_last, b_obs, b_poses = inputs\n",
    "            gt_fp_projs, gt_fp_explored, gt_pose_err = outputs\n",
    "\n",
    "            b_obs = b_obs.to(device)\n",
    "            b_obs_last = b_obs_last.to(device)\n",
    "            b_poses = b_poses.to(device)\n",
    "\n",
    "            gt_fp_projs = gt_fp_projs.to(device)\n",
    "            gt_fp_explored = gt_fp_explored.to(device)\n",
    "            gt_pose_err = gt_pose_err.to(device)\n",
    "\n",
    "            b_proj_pred, b_fp_exp_pred, _, _, b_pose_err_pred, _ = \\\n",
    "                nslam_module(b_obs_last, b_obs, b_poses,\n",
    "                             None, None, None,\n",
    "                             build_maps=False)\n",
    "            loss = 0\n",
    "            if args.proj_loss_coeff > 0:\n",
    "                proj_loss = F.binary_cross_entropy(b_proj_pred,\n",
    "                                                   gt_fp_projs)\n",
    "                costs.append(proj_loss.item())\n",
    "                loss += args.proj_loss_coeff * proj_loss\n",
    "\n",
    "            if args.exp_loss_coeff > 0:\n",
    "                exp_loss = F.binary_cross_entropy(b_fp_exp_pred,\n",
    "                                                  gt_fp_explored)\n",
    "                exp_costs.append(exp_loss.item())\n",
    "                loss += args.exp_loss_coeff * exp_loss\n",
    "\n",
    "            if args.pose_loss_coeff > 0:\n",
    "                pose_loss = torch.nn.MSELoss()(b_pose_err_pred,\n",
    "                                               gt_pose_err)\n",
    "                pose_costs.append(args.pose_loss_coeff *\n",
    "                                  pose_loss.item())\n",
    "                loss += args.pose_loss_coeff * pose_loss\n",
    "\n",
    "            if args.train_slam:\n",
    "                slam_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                slam_optimizer.step()\n",
    "\n",
    "            del b_obs_last, b_obs, b_poses\n",
    "            del gt_fp_projs, gt_fp_explored, gt_pose_err\n",
    "            del b_proj_pred, b_fp_exp_pred, b_pose_err_pred\n",
    "          \n",
    "    # Finish Training\n",
    "    torch.set_grad_enabled(False)\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # ------------------------------------------------------------------      \n",
    "    # Logging\n",
    "    if total_num_steps % args.log_interval == 0:\n",
    "        end = time.time()\n",
    "        time_elapsed = time.gmtime(end - start)\n",
    "        log = \" \".join([\n",
    "            \"Time: {0:0=2d}d\".format(time_elapsed.tm_mday - 1),\n",
    "            \"{},\".format(time.strftime(\"%Hh %Mm %Ss\", time_elapsed)),\n",
    "            \"num timesteps {},\".format(total_num_steps *\n",
    "                                       num_scenes),\n",
    "            \"FPS {},\".format(int(total_num_steps * num_scenes \\\n",
    "                                 / (end - start)))\n",
    "        ])\n",
    "\n",
    "        log += \"\\n\\tRewards:\"\n",
    "\n",
    "        log += \" \".join([\n",
    "            \" Succsess, SPL:\",\n",
    "            \"{:.4f}/{:.4f},\".format(\n",
    "                np.mean(list_suc[-100:]),\n",
    "                np.mean(list_spl[-100:]))\n",
    "        ])\n",
    "\n",
    "        log += \"\\n\\tLosses:\"\n",
    "\n",
    "        if args.train_local and len(l_action_losses) > 0:\n",
    "            log += \" \".join([\n",
    "                \" Local Loss:\",\n",
    "                \"{:.3f},\".format(\n",
    "                    np.mean(l_action_losses))\n",
    "            ])\n",
    "        writer.add_scalar(\n",
    "                        \"Local Loss\",\n",
    "                        np.mean(l_action_losses),\n",
    "                        step)   \n",
    "\n",
    "\n",
    "        if args.train_slam and len(costs) > 0:\n",
    "            log += \" \".join([\n",
    "                \" SLAM Loss proj/exp/pose:\"\n",
    "                \"{:.4f}/{:.4f}/{:.4f}\".format(\n",
    "                    np.mean(costs),\n",
    "                    np.mean(exp_costs),\n",
    "                    np.mean(pose_costs))\n",
    "            ])\n",
    "        writer.add_scalar(\n",
    "                        \"SLAM Loss proj\",\n",
    "                        np.mean(costs),\n",
    "                        step)\n",
    "        writer.add_scalar(\n",
    "                        \"SLAM Loss exp\",\n",
    "                        np.mean(exp_costs),\n",
    "                        step)     \n",
    "\n",
    "        print(log)\n",
    "        logging.info(log)\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Save best models\n",
    "        # Save Neural SLAM Model\n",
    "    if np.mean(costs) < best_cost and not args.eval:\n",
    "        best_cost = np.mean(costs)\n",
    "        torch.save(nslam_module.state_dict(),\n",
    "                   os.path.join(log_dir, \"model_best.slam\"))\n",
    "\n",
    "    # Save Local Policy Model\n",
    "    if np.mean(l_action_losses) <= best_local_loss and not args.eval:\n",
    "        torch.save(l_policy.state_dict(),\n",
    "                   os.path.join(log_dir, \"model_best.local\"))\n",
    "\n",
    "        best_local_loss = np.mean(l_action_losses)\n",
    "\n",
    "    # Save periodic models\n",
    "    if step % 100==0:\n",
    "        #step = total_num_steps * num_scenes\n",
    "        if args.train_slam:\n",
    "            torch.save(nslam_module.state_dict(),\n",
    "                       os.path.join(dump_dir,\n",
    "                                    \"periodic_{}.slam\".format(step)))\n",
    "        if args.train_local:\n",
    "            torch.save(l_policy.state_dict(),\n",
    "                       os.path.join(dump_dir,\n",
    "                                    \"periodic_{}.local\".format(step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "torch.save(nslam_module.state_dict(),\n",
    "                       os.path.join('.',\n",
    "                                    \"periodic_{}.slam\".format(step)))\n",
    "torch.save(l_policy.state_dict(),\n",
    "                       os.path.join('.',\n",
    "                                    \"periodic_{}.local\".format(step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_local_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i['goal'] for i in planner_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(one_env.local_goal_x_y)\n",
    "print(one_env.goal_to_planer)\n",
    "print(one_env.start_240_240)\n",
    "print(one_env.goal_240_240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "f = plt.figure(figsize=(15,10))\n",
    "ax = f.add_subplot(231)\n",
    "ax2 = f.add_subplot(232)\n",
    "ax.imshow(planner_inputs[ind]['map_pred'])\n",
    "ax2.imshow(planner_inputs[ind]['exp_pred'])\n",
    "print(planner_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,10))\n",
    "ax = f.add_subplot(231)\n",
    "ax2 = f.add_subplot(232)\n",
    "circ = Circle((start_ep[0][0],start_ep[0][1]),3,color='red')\n",
    "circ2 = Circle((goal_ep[0][0],goal_ep[0][1]),3,color='white')\n",
    "circ3 = Circle((stg_ep[0][0],stg_ep[0][1]),3,color='green')\n",
    "ax.imshow(local_map[0, 0, :, :].cpu().numpy())\n",
    "ax2.imshow(envs_map[0][lmb[0,0]:lmb[0,1],lmb[0,2]:lmb[0,3]])\n",
    "ax2.add_patch(circ)\n",
    "ax2.add_patch(circ2)\n",
    "ax2.add_patch(circ3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "start = time.time()\n",
    "list_suc = []\n",
    "list_spl = []\n",
    "for ep_num in range(num_episodes*args.max_episode_length):\n",
    "    step+=1\n",
    "    \n",
    "    total_num_steps += 1\n",
    "    g_step = (step // args.num_local_steps) % args.num_global_steps\n",
    "    eval_g_step = step // args.num_local_steps + 1\n",
    "    l_step = step % args.num_local_steps\n",
    "    \n",
    "    last_obs = obs_rgb.detach()\n",
    "    output = envs.get_short_term_goal(planner_inputs)\n",
    "    l_action=output[:,2].astype(int)\n",
    "    \n",
    "    # Local Policy\n",
    "    local_masks = l_masks\n",
    "   \n",
    "    local_goals = torch.from_numpy(output[:, :-1]).to(device).long()\n",
    "    \n",
    "    if args.train_local:\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "    action, action_prob, local_rec_states = l_policy(\n",
    "            obs_rgb,\n",
    "            local_rec_states,\n",
    "            local_masks,\n",
    "            extras=local_goals)\n",
    "    \n",
    "    OBSERVATION_SPACE_COMMAND = ['start_240_240','goal_240_240']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns] \n",
    "    start_ep = OBSERVATION_SPACE_COMMAND[0]\n",
    "    goal_ep = OBSERVATION_SPACE_COMMAND[1]\n",
    "    #print(start_ep)\n",
    "    \n",
    "    if args.train_local:\n",
    "        action_target = torch.from_numpy(np.array(l_action)).long().to(device)\n",
    "        policy_loss += nn.CrossEntropyLoss()(action_prob, action_target)\n",
    "        torch.set_grad_enabled(False)\n",
    "            \n",
    "    # ------------------------------------------------------------------\n",
    "    # Train Local Policy\n",
    "    if (l_step + 1) % args.local_policy_update_freq == 0 \\\n",
    "            and args.train_local:\n",
    "        local_optimizer.zero_grad()\n",
    "        policy_loss.backward(retain_graph=True)\n",
    "        local_optimizer.step()\n",
    "        l_action_losses.append(policy_loss.item())\n",
    "        policy_loss = 0\n",
    "        local_rec_states = local_rec_states.detach_()\n",
    "    # ------------------------------------------------------------------      \n",
    "\n",
    "        \n",
    "    obs, rew, done, infos = envs.step(l_action)\n",
    "\n",
    "    \n",
    "      \n",
    "    for n in [ii for ii,i in enumerate(l_action) if l_action[ii]==0]:\n",
    "        print(n)\n",
    "        full_map[n]*=0 #= torch.zeros(1, 4, full_w, full_h).float().to(device)\n",
    "        local_map[n]*=0 #= torch.zeros(1, 4, local_w, local_h).float().to(device)\n",
    "        full_pose[n]*=0 #= torch.zeros(1, 3).float().to(device)\n",
    "        local_pose[n]*=0 #= torch.zeros(1, 3).float().to(device)\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    suc = [i['success'] if done[ii] else None for ii,i in enumerate(infos)]\n",
    "    for i in suc:\n",
    "        if i is not None:\n",
    "            list_suc.append(i)\n",
    "    spl = [i['spl'] if done[ii] else None for ii,i in enumerate(infos)]\n",
    "    for i in spl:\n",
    "        if i is not None:\n",
    "            list_spl.append(i)\n",
    "    #print(len(list_suc),len(list_spl))\n",
    "    \n",
    "    OBSERVATION_SPACE_COMMAND = ['start_240_240','goal_240_240']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns] \n",
    "    start_pos = OBSERVATION_SPACE_COMMAND[0]\n",
    "    goal_pos = OBSERVATION_SPACE_COMMAND[1]\n",
    "    \n",
    "    \n",
    "    dones = [i for ii,i in enumerate(range(num_scenes)) if done[ii]]\n",
    "    if len(dones)>0:\n",
    "                \n",
    "        init_map_and_pose(dones)\n",
    "       # success += [i['success'] for ii,i in enumerate(infos) if ii in dones]\n",
    "       # spls += [i['spl'] for ii,i in enumerate(infos) if ii in dones]\n",
    "       # print(np.mean(success),np.mean(spls))\n",
    "        \n",
    "        poses = torch.from_numpy(np.asarray(\n",
    "                    [infos[env_idx]['sensor_pose'] for env_idx\n",
    "                     in range(num_scenes)])).float().to(device)\n",
    "        obs_rgb = torch.from_numpy(np.array([i['rgb'] for i in obs])).float().to(device)\n",
    "\n",
    "        local_map_restart = local_map.clone()\n",
    "        local_pose_restart = local_pose.clone()\n",
    "\n",
    "        _, _, local_map_restart[:, 0, :, :], local_map_restart[:, 1, :, :], _, local_pose_restart = \\\n",
    "            nslam_module(obs_rgb, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                         local_map[:, 1, :, :], local_pose)\n",
    "\n",
    "\n",
    "        locs = local_pose_restart.cpu().numpy()\n",
    "\n",
    "        for e in dones:\n",
    "            r, c = locs[e, 1], locs[e, 0]\n",
    "            loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                            int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "            local_map_restart[e, 2:, loc_r - 1:loc_r + 2, loc_c - 1:loc_c + 2] = 1.\n",
    "            global_orientation[e] = int((locs[e, 2] + 180.0) / 5.)\n",
    "        global_input[dones, 0:4, :, :] = local_map_restart[dones].detach().cpu()\n",
    "        global_input[dones, 4:, :, :] = nn.MaxPool2d(args.global_downscaling)(full_map[dones]).cpu()\n",
    "        OBSERVATION_SPACE_COMMAND = ['trux','truy','goalx','goaly']\n",
    "        for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "            for write_fn in envs._connection_write_fns:\n",
    "                write_fn((command, None))\n",
    "            OBSERVATION_SPACE_COMMAND[i] = [(read_fn()+12)/args.map_size_cm*48000 for read_fn in envs._connection_read_fns]\n",
    "        trux,truy,goalx,goaly = OBSERVATION_SPACE_COMMAND\n",
    "        global_goals = [[int(goalx[i]),int(goaly[i])] for i in range(len(goalx))]\n",
    "\n",
    "\n",
    "        #planner_inputs = [{} for e in dones]\n",
    "        for e, p_input in enumerate(planner_inputs):\n",
    "            if e in dones:\n",
    "                p_input['goal'] = global_goals[e]\n",
    "                p_input['map_pred'] = global_input[e, 0, :, :].detach().cpu().numpy()\n",
    "                p_input['exp_pred'] = global_input[e, 1, :, :].detach().cpu().numpy()\n",
    "                p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "\n",
    "        local_rec_states[dones] = local_rec_states[dones]*0\n",
    "    \n",
    "\n",
    "    obs_rgb = torch.from_numpy(np.array([i['rgb'] for i in obs])).float().to(device)\n",
    "    OBSERVATION_SPACE_COMMAND = ['trux','truy','goalx','goaly']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [(read_fn()+12)/args.map_size_cm*48000 for read_fn in envs._connection_read_fns]\n",
    "    trux,truy,goalx,goaly = OBSERVATION_SPACE_COMMAND\n",
    "    global_goals = [[int(goalx[i]),int(goaly[i])] for i in range(len(goalx))]\n",
    "\n",
    "\n",
    "    l_masks = torch.FloatTensor([0 if x else 1\n",
    "                                     for x in done]).to(device)\n",
    "\n",
    "    g_masks *= l_masks\n",
    "    # ------------------------------------------------------------------\n",
    "    # Reinitialize variables when episode ends\n",
    "    #if step == args.max_episode_length - 1:  # Last episode step\n",
    "    #    init_map_and_pose()\n",
    "    #    del last_obs\n",
    "    #    last_obs = obs_rgb.detach()\n",
    "    # ------------------------------------------------------------------\n",
    "    # Neural SLAM Module\n",
    "    if args.train_slam:\n",
    "        # Add frames to memory\n",
    "        for env_idx in range(num_scenes):\n",
    "            env_obs = obs_rgb[env_idx].to(\"cpu\")\n",
    "            env_poses = torch.from_numpy(np.asarray(\n",
    "                infos[env_idx]['sensor_pose']\n",
    "            )).float().to(\"cpu\")\n",
    "            env_gt_fp_projs = torch.from_numpy(np.asarray(\n",
    "                infos[env_idx]['fp_proj']\n",
    "            )).unsqueeze(0).float().to(\"cpu\")\n",
    "            env_gt_fp_explored = torch.from_numpy(np.asarray(\n",
    "                infos[env_idx]['fp_explored']\n",
    "            )).unsqueeze(0).float().to(\"cpu\")\n",
    "            env_gt_pose_err = torch.from_numpy(np.asarray(\n",
    "                infos[env_idx]['pose_err']\n",
    "            )).float().to(\"cpu\")\n",
    "            slam_memory.push(\n",
    "                (last_obs[env_idx].cpu(), env_obs, env_poses),\n",
    "                (env_gt_fp_projs, env_gt_fp_explored, env_gt_pose_err))\n",
    "\n",
    "    poses = torch.from_numpy(np.asarray(\n",
    "            [infos[env_idx]['sensor_pose'] for env_idx\n",
    "             in range(num_scenes)])).float().to(device)\n",
    "\n",
    "    _, _, local_map[:, 0, :, :], local_map[:, 1, :, :], _, local_pose = \\\n",
    "            nslam_module(last_obs, obs_rgb, poses, local_map[:, 0, :, :],\n",
    "                         local_map[:, 1, :, :], local_pose, build_maps=True)\n",
    "\n",
    "    locs = local_pose.cpu().numpy()\n",
    "    planner_pose_inputs[:, :3] = locs + origins\n",
    "    #print(locs)\n",
    "    local_map[:, 2, :, :].fill_(0.)  # Resetting current location channel\n",
    "    for e in range(num_scenes):\n",
    "        r, c = locs[e, 1], locs[e, 0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        local_map[e, 2:, loc_r - 2:loc_r + 3, loc_c - 2:loc_c + 3] = 1.\n",
    "    # ------------------------------------------------------------------\n",
    "    for e in range(num_scenes):\n",
    "        full_map[e, :, lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]] = \\\n",
    "            local_map[e]\n",
    "        full_pose[e] = local_pose[e] + \\\n",
    "                       torch.from_numpy(origins[e]).to(device).float()\n",
    "\n",
    "        locs = full_pose[e].cpu().numpy()\n",
    "        r, c = locs[1], locs[0]\n",
    "        loc_r, loc_c = [int(r * 100.0 / args.map_resolution),\n",
    "                        int(c * 100.0 / args.map_resolution)]\n",
    "\n",
    "        lmb[e] = get_local_map_boundaries((loc_r, loc_c),\n",
    "                                          (local_w, local_h),\n",
    "                                          (full_w, full_h), args)\n",
    "\n",
    "        planner_pose_inputs[e, 3:] = lmb[e]\n",
    "        origins[e] = [lmb[e][2] * args.map_resolution / 100.0,\n",
    "                      lmb[e][0] * args.map_resolution / 100.0, 0.]\n",
    "\n",
    "        local_map[e] = full_map[e, :,\n",
    "                       lmb[e, 0]:lmb[e, 1], lmb[e, 2]:lmb[e, 3]]\n",
    "        local_pose[e] = full_pose[e] - \\\n",
    "                        torch.from_numpy(origins[e]).to(device).float()\n",
    "\n",
    "    locs = local_pose.cpu().numpy()\n",
    "    for e in range(num_scenes):\n",
    "        global_orientation[e] = int((locs[e, 2] + 180.0) / 5.)\n",
    "    global_input[:, 0:4, :, :] = local_map\n",
    "    global_input[:, 4:, :, :] = \\\n",
    "        nn.MaxPool2d(args.global_downscaling)(full_map)\n",
    "\n",
    "    # Get short term goal\n",
    "    planner_inputs = [{} for e in range(num_scenes)]\n",
    "    for e, p_input in enumerate(planner_inputs):\n",
    "        p_input['map_pred'] = envs_map[e][lmb[e,0]:lmb[e,1],lmb[e,2]:lmb[e,3]]#local_map[e, 0, :, :].cpu().numpy()\n",
    "        p_input['exp_pred'] = explored_map[e][lmb[e,0]:lmb[e,1],lmb[e,2]:lmb[e,3]]#local_map[e, 1, :, :].cpu().numpy()\n",
    "        p_input['pose_pred'] = planner_pose_inputs[e]\n",
    "        p_input['goal'] = global_goals[e]\n",
    "        \n",
    "        \n",
    "    OBSERVATION_SPACE_COMMAND = ['explored_map','map']\n",
    "    for i,command in enumerate(OBSERVATION_SPACE_COMMAND):\n",
    "        for write_fn in envs._connection_write_fns:\n",
    "            write_fn((command, None))\n",
    "        OBSERVATION_SPACE_COMMAND[i] = [read_fn() for read_fn in envs._connection_read_fns]\n",
    "    explored_map,envs_map = OBSERVATION_SPACE_COMMAND\n",
    "\n",
    "    ### TRAINING\n",
    "    torch.set_grad_enabled(True)\n",
    "    # ------------------------------------------------------------------\n",
    "    # Train Neural SLAM Module\n",
    "    if args.train_slam and len(slam_memory) > args.slam_batch_size:\n",
    "        for _ in range(args.slam_iterations):\n",
    "            inputs, outputs = slam_memory.sample(args.slam_batch_size)\n",
    "            b_obs_last, b_obs, b_poses = inputs\n",
    "            gt_fp_projs, gt_fp_explored, gt_pose_err = outputs\n",
    "\n",
    "            b_obs = b_obs.to(device)\n",
    "            b_obs_last = b_obs_last.to(device)\n",
    "            b_poses = b_poses.to(device)\n",
    "\n",
    "            gt_fp_projs = gt_fp_projs.to(device)\n",
    "            gt_fp_explored = gt_fp_explored.to(device)\n",
    "            gt_pose_err = gt_pose_err.to(device)\n",
    "\n",
    "            b_proj_pred, b_fp_exp_pred, _, _, b_pose_err_pred, _ = \\\n",
    "                nslam_module(b_obs_last, b_obs, b_poses,\n",
    "                             None, None, None,\n",
    "                             build_maps=False)\n",
    "            loss = 0\n",
    "            if args.proj_loss_coeff > 0:\n",
    "                proj_loss = F.binary_cross_entropy(b_proj_pred,\n",
    "                                                   gt_fp_projs)\n",
    "                costs.append(proj_loss.item())\n",
    "                loss += args.proj_loss_coeff * proj_loss\n",
    "\n",
    "            if args.exp_loss_coeff > 0:\n",
    "                exp_loss = F.binary_cross_entropy(b_fp_exp_pred,\n",
    "                                                  gt_fp_explored)\n",
    "                exp_costs.append(exp_loss.item())\n",
    "                loss += args.exp_loss_coeff * exp_loss\n",
    "\n",
    "            if args.pose_loss_coeff > 0:\n",
    "                pose_loss = torch.nn.MSELoss()(b_pose_err_pred,\n",
    "                                               gt_pose_err)\n",
    "                pose_costs.append(args.pose_loss_coeff *\n",
    "                                  pose_loss.item())\n",
    "                loss += args.pose_loss_coeff * pose_loss\n",
    "\n",
    "            if args.train_slam:\n",
    "                slam_optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                slam_optimizer.step()\n",
    "\n",
    "            del b_obs_last, b_obs, b_poses\n",
    "            del gt_fp_projs, gt_fp_explored, gt_pose_err\n",
    "            del b_proj_pred, b_fp_exp_pred, b_pose_err_pred\n",
    "          \n",
    "    # Finish Training\n",
    "    torch.set_grad_enabled(False)\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Logging\n",
    "    if total_num_steps % args.log_interval == 0:\n",
    "        end = time.time()\n",
    "        time_elapsed = time.gmtime(end - start)\n",
    "        log = \" \".join([\n",
    "            \"Time: {0:0=2d}d\".format(time_elapsed.tm_mday - 1),\n",
    "            \"{},\".format(time.strftime(\"%Hh %Mm %Ss\", time_elapsed)),\n",
    "            \"num timesteps {},\".format(total_num_steps *\n",
    "                                       num_scenes),\n",
    "            \"FPS {},\".format(int(total_num_steps * num_scenes \\\n",
    "                                 / (end - start)))\n",
    "        ])\n",
    "\n",
    "        log += \"\\n\\tRewards:\"\n",
    "\n",
    "        log += \" \".join([\n",
    "            \" Succsess, SPL:\",\n",
    "            \"{:.4f}/{:.4f},\".format(\n",
    "                np.mean(list_suc[-100:]),\n",
    "                np.mean(list_spl[-100:]))\n",
    "        ])\n",
    "\n",
    "        log += \"\\n\\tLosses:\"\n",
    "\n",
    "        if args.train_local and len(l_action_losses) > 0:\n",
    "            log += \" \".join([\n",
    "                \" Local Loss:\",\n",
    "                \"{:.3f},\".format(\n",
    "                    np.mean(l_action_losses))\n",
    "            ])\n",
    "\n",
    "\n",
    "        if args.train_slam and len(costs) > 0:\n",
    "            log += \" \".join([\n",
    "                \" SLAM Loss proj/exp/pose:\"\n",
    "                \"{:.4f}/{:.4f}/{:.4f}\".format(\n",
    "                    np.mean(costs),\n",
    "                    np.mean(exp_costs),\n",
    "                    np.mean(pose_costs))\n",
    "            ])\n",
    "\n",
    "        print(log)\n",
    "        logging.info(log)\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Save best models\n",
    "    if (total_num_steps * num_scenes) % args.save_interval < \\\n",
    "            num_scenes:\n",
    "\n",
    "        # Save Neural SLAM Model\n",
    "        if len(costs) >= 1000 and np.mean(costs) < best_cost \\\n",
    "                and not args.eval:\n",
    "            best_cost = np.mean(costs)\n",
    "            torch.save(nslam_module.state_dict(),\n",
    "                       os.path.join(log_dir, \"model_best.slam\"))\n",
    "\n",
    "        # Save Local Policy Model\n",
    "        if len(l_action_losses) >= 100 and \\\n",
    "                (np.mean(l_action_losses) <= best_local_loss) \\\n",
    "                and not args.eval:\n",
    "            torch.save(l_policy.state_dict(),\n",
    "                       os.path.join(log_dir, \"model_best.local\"))\n",
    "\n",
    "            best_local_loss = np.mean(l_action_losses)\n",
    "\n",
    "    # Save periodic models\n",
    "    if (total_num_steps * num_scenes) % args.save_periodic < \\\n",
    "            num_scenes:\n",
    "        step = total_num_steps * num_scenes\n",
    "        if args.train_slam:\n",
    "            torch.save(nslam_module.state_dict(),\n",
    "                       os.path.join(dump_dir,\n",
    "                                    \"periodic_{}.slam\".format(step)))\n",
    "        if args.train_local:\n",
    "            torch.save(l_policy.state_dict(),\n",
    "                       os.path.join(dump_dir,\n",
    "                                    \"periodic_{}.local\".format(step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nslam_module.state_dict(),\n",
    "                           os.path.join('./',\n",
    "                                        \"periodic_{}.slam\".format(step)))\n",
    "torch.save(l_policy.state_dict(),\n",
    "                           os.path.join('./',\n",
    "                                        \"periodic_{}.local\".format(step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(np.array([1.1,2.2])).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
